<html>
<head><meta charset="utf-8"><title>[isabelle] Numbers reported in &quot;Timing&quot; panel · Mirror: Isabelle Users Mailing List · Zulip Chat Archive</title></head>
<h2>Stream: <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/index.html">Mirror: Isabelle Users Mailing List</a></h2>
<h3>Topic: <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html">[isabelle] Numbers reported in &quot;Timing&quot; panel</a></h3>

<hr>

<base href="https://isabelle.zulipchat.com/">

<head><link href="http://isabelle.systems/zulip-archive/style.css" rel="stylesheet"></head>

<a name="207044524"></a>
<h4><a href="https://isabelle.zulipchat.com/#narrow/stream/247541-Mirror%3A%20Isabelle%20Users%20Mailing%20List/topic/%5Bisabelle%5D%20Numbers%20reported%20in%20%22Timing%22%20panel/near/207044524" class="zl"><img src="http://isabelle.systems/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Email Gateway <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html#207044524">(Aug 15 2020 at 23:20)</a>:</h4>
<p>From: "Eugene W. Stark" &lt;<a href="mailto:isabelle-users@starkeffect.com">isabelle-users@starkeffect.com</a>&gt;<br>
There is something that I have noticed that makes optimizing the processing time of Isabelle theories more difficult:<br>
The timings reported in the "Timings" panel are highly variable, especially under near-thrashing conditions.<br>
An inference that can be performed in a few tens of ms can, under conditions of severe memory stress, be reported as<br>
taking many minutes.  This makes optimization difficult, as the timing results are not repeatable.</p>
<p>I would like the timing numbers to only reflect actual computation time expended, not incidental delays that are<br>
dependent on the memory conditions in which the particular inference is run.  It does not match my current goals to<br>
spend time trying to read the source code to try to figure out why this occurs, but I am hoping that someone who already<br>
understands the timing instrumentation code would be able to make simple modifications to make the results repeatable<br>
and ultimately more useful.</p>
<p>Thanks.</p>



<a name="208550221"></a>
<h4><a href="https://isabelle.zulipchat.com/#narrow/stream/247541-Mirror%3A%20Isabelle%20Users%20Mailing%20List/topic/%5Bisabelle%5D%20Numbers%20reported%20in%20%22Timing%22%20panel/near/208550221" class="zl"><img src="http://isabelle.systems/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Email Gateway <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html#208550221">(Aug 31 2020 at 12:30)</a>:</h4>
<p>From: Makarius &lt;<a href="mailto:makarius@sketis.net">makarius@sketis.net</a>&gt;<br>
I read from this observation that big Isabelle applications become more and<br>
more memory-bound: having too little heap space requires rather expensive<br>
operations for garbage-collection and sharing of live data.</p>
<p>David Matthews, the grand master behind Poly/ML, has recently provided more<br>
facilities for runtime statistics of memory management. I have already<br>
integrated some of this into the Isabelle/jEdit monitoring facilities (for the<br>
next release, presumably in Feb-2021). This confirms the impression that<br>
overall heap usage is now more relevant than individual timing.</p>
<p>How much memory do you actually have on your machine?</p>
<p>For non-trivial applications 16 GB are already standard, and 32-64 GB are not<br>
uncommon for really big things.</p>
<p>Makarius</p>



<a name="208566951"></a>
<h4><a href="https://isabelle.zulipchat.com/#narrow/stream/247541-Mirror%3A%20Isabelle%20Users%20Mailing%20List/topic/%5Bisabelle%5D%20Numbers%20reported%20in%20%22Timing%22%20panel/near/208566951" class="zl"><img src="http://isabelle.systems/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Email Gateway <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html#208566951">(Aug 31 2020 at 14:49)</a>:</h4>
<p>From: "Eugene W. Stark" &lt;<a href="mailto:isabelle-users@starkeffect.com">isabelle-users@starkeffect.com</a>&gt;<br>
I have 24GB.</p>
<p>I understand what you are saying, but I am asking for the timing numbers not to be confounded by non-CPU overhead.<br>
That way, even if I am running with a few extra browser tabs open I will see the same timing results and will still<br>
know whether what I am doing is optimizing something or making pointless changes.</p>
<p>Thank you.</p>



<a name="208569407"></a>
<h4><a href="https://isabelle.zulipchat.com/#narrow/stream/247541-Mirror%3A%20Isabelle%20Users%20Mailing%20List/topic/%5Bisabelle%5D%20Numbers%20reported%20in%20%22Timing%22%20panel/near/208569407" class="zl"><img src="http://isabelle.systems/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Email Gateway <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html#208569407">(Aug 31 2020 at 15:04)</a>:</h4>
<p>From: Makarius &lt;<a href="mailto:makarius@sketis.net">makarius@sketis.net</a>&gt;<br>
On 31/08/2020 16:48, Eugene W. Stark wrote:</p>
<blockquote>
<p>I understand what you are saying, but I am asking for the timing numbers not to be confounded by non-CPU overhead.<br>
That way, even if I am running with a few extra browser tabs open I will see the same timing results and will still<br>
know whether what I am doing is optimizing something or making pointless changes.</p>
</blockquote>
<p>Isabelle as an application of symbolic logic mainly allocates tree data<br>
structures in memory, while gargabe collection deallocates them later on on.<br>
Thus it is inherently hard to isolate the "non-CPU overhead": it is the main<br>
part of the program.</p>
<blockquote>
<p>I have 24GB.</p>
</blockquote>
<p>That it not much for the size of your typical applications on AFP.</p>
<p>Do you see a chance to double the memory on that hardware?</p>
<p>I have 32GB on my development machine, and don't do really big Isabelle<br>
applications.</p>
<p>Makarius</p>



<a name="208590877"></a>
<h4><a href="https://isabelle.zulipchat.com/#narrow/stream/247541-Mirror%3A%20Isabelle%20Users%20Mailing%20List/topic/%5Bisabelle%5D%20Numbers%20reported%20in%20%22Timing%22%20panel/near/208590877" class="zl"><img src="http://isabelle.systems/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Email Gateway <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html#208590877">(Aug 31 2020 at 17:38)</a>:</h4>
<p>From: "Eugene W. Stark" &lt;<a href="mailto:isabelle-users@starkeffect.com">isabelle-users@starkeffect.com</a>&gt;<br>
I could increase to 32GB on this hardware if I throw away some of the existing memory.<br>
But that is certainly not my point.</p>
<p>An operating system (such as Linux, which is what I am using) provides system calls (cf getrusage(2),<br>
clock_gettime(2)) that an application can use to measure resource consumption in various ways:</p>
<p>CPU time used in user mode<br>
    CPU time used in kernel mode<br>
    Wall clock time</p>
<p>For Isabelle (using JEdit), CPU time is consumed by Java (to run JEdit) and CPU time is consumed by<br>
Poly/ML (to do inferences).  The CPU time spent by Java, while potentially significant, has to do with<br>
the manipulation of the annotated syntax tree of the theories being edited, depends primarily on the<br>
size of that document and its annotations (not on the complexity of proof steps) and is not of interest<br>
to me here.  In any case, I assume that this time is not intended to be included in the figures reported<br>
in the "Timings" panel and the values one sees if one CTRL-hovers over "by", "apply", etc.</p>
<p>I would expect that the times shown in the "Timings" panel are intended to reflect the actual CPU time<br>
spent by ML in user mode.  CPU time spent in user mode by ML may be partitioned into time running ML code<br>
and time spent doing garbage collection.  It does not include time spent with the CPU idle waiting for paging,<br>
or CPU time spent running other unrelated processes.  It probably also ought not to include CPU time spent<br>
in kernel mode.  As the page fault rate of the ML process increases to the point of saturating the paging<br>
devices, the wall clock time taken to accomplish a particular task will increase dramatically.<br>
The CPU time spent in system mode will also increase, though this will typically not be that significant.<br>
In addition, once the heap size reaches its maximum value (as a result of actual hardware limitation or<br>
artificial software limits placed on the ML process) the fraction of live data in the heap will become larger<br>
and larger and consequently the garbage collector will consume more and more CPU time to perform the same<br>
underlying computational task.  However, as far as I know, the ML implementation accounts separately for<br>
CPU time used in garbage collection versus CPU time used to run ML code, so it is not necessarily the<br>
case that garbage collection time should be a significant component of the "Timings" numbers.</p>
<p>But you know all that.  Let me try again to make what I believe is a very simple point:  Empirical<br>
observation shows that figures reported under "Timings" <em>do not</em> reflect only time spent by ML running<br>
ML code in user mode: depending on the system conditions under which a task is run, they apparently also<br>
include either CPU time spent in garbage collection, wall clock time spent waiting for paging,<br>
or a combination of the two.  This is not desirable because it makes the timings not repeatable.<br>
The timings would be more useful if they would more or less reflect the amount of user CPU time spent<br>
in user mode to run ML code to accomplish a particular computational task.  These numbers ought to agree<br>
closely with the amount of wall clock time it would take to accomplish that same task on a system in which<br>
RAM size is large enough that there is an insignificant page fault rate, and on which there is no<br>
competition for CPU with unrelated applications.  Under those conditions, one can expect the "Timings"<br>
numbers to be repeatable across separate runs, and that optimizations that reduce the numbers reported<br>
under "Timings" will reflect actual improvements in wall clock time when the task is run under conditions<br>
where memory limitations are not significant.</p>
<p>Well, that is the point I am trying to make.  Perhaps you are trying to say that one ought to be optimizing<br>
memory consumption rather than CPU consumption.  Well that would certainly be a valid point, but to do that<br>
that would require a "Memory usage" panel that reports the amount of allocation performed in conjunction with<br>
each basic proof step.  I would expect this to be a more complex instrumentation task than recording CPU<br>
usage associated with each basic proof step.  Since there is likely to be a tradeoff between memory utilization<br>
and CPU consumption, it is not clear to me at the moment that this is primarily what one wants to do.</p>



<a name="208670245"></a>
<h4><a href="https://isabelle.zulipchat.com/#narrow/stream/247541-Mirror%3A%20Isabelle%20Users%20Mailing%20List/topic/%5Bisabelle%5D%20Numbers%20reported%20in%20%22Timing%22%20panel/near/208670245" class="zl"><img src="http://isabelle.systems/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Email Gateway <a href="http://isabelle.systems/zulip-archive/stream/247541-Mirror:-Isabelle-Users-Mailing-List/topic/.5Bisabelle.5D.20Numbers.20reported.20in.20.22Timing.22.20panel.html#208670245">(Sep 01 2020 at 10:44)</a>:</h4>
<p>From: Makarius &lt;<a href="mailto:makarius@sketis.net">makarius@sketis.net</a>&gt;<br>
The Timing panel works with elapsed time. See also the general explanations in<br>
section 6.1 of the "jedit" manual (Documentation panel).</p>
<p>If you want repeatable results for a single proof command, you can approximate<br>
it like this:</p>
<p>* Use sufficient physical memory to avoid use of virtual memory by the<br>
underlying OS (no disk thrashing while timing).</p>
<p>* Avoid non-trivial applications running in parallel.</p>
<p>* Disable Isabelle/ML multithreading by using system option threads=1 (e.g.<br>
via the Isabelle/jEdit menu Plugins / Plugin Options / Isabelle / General /<br>
Threads.</p>
<p>* Use a well-defined initial state of the ML heap to minimize subsequent<br>
garbage collection, e.g. via</p>
<p>ML "ML_Heap.share_common_data ()"</p>
<p>The latter is rather drastic: it is only required for substantial ML heap<br>
usage, as in your own AFP/Bicategory<br>
<a href="https://isabelle.sketis.net/devel/build_status/AFP_64bit_8_threads/index.html#session_Bicategory">https://isabelle.sketis.net/devel/build_status/AFP_64bit_8_threads/index.html#session_Bicategory</a></p>
<p>Makarius</p>



<hr><p>Last updated: Jul 15 2022 at 23:21 UTC</p>
</html>