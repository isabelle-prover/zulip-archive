[
    {
        "content": "<p><strong>From:</strong> \"\\\"Bisping, Benjamin\\\"\" &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive theorem proving is the future of mathematics and verification. (I'm sure many on this mailing list know this situation.) I intend to build some arguments around Terence Tao getting ten-thousands of people to watch him use Lean+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will employ Isabelle/HOL for the demonstration, I strongly anticipate questions in the direction of how to hook it up with GitHub Copilot.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"cyyR7j2ChCI\" href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\"><img src=\"https://uploads.zulipusercontent.net/0e5c80efbd7c87269bd3e04884f14b4765b18460/68747470733a2f2f692e7974696d672e636f6d2f76692f63797952376a32436843492f6d7164656661756c742e6a7067\"></a></div><p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the incompatibilities introduced by Microsoft on one side and the Isabelle/Codium package on the other side.* This is a pity because, in principle, this year's LLM coding assistants appear to finally be quite decent at finding Isabelle proofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can solve tricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT promts) and JEdit is too clunky to be proposed in my “sales pitch” for ITPs. And if there's no easy automation for writing proofs in Isabelle, but there is in Lean, I already know how 100 % of the listeners will decide which of the two systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on LLM-supported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium <a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> . The 2025 message on the topic to this mailing list went unanswered <a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a> .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code, which otherwise would at least be some answer. <a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>",
        "id": 562548851,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765224287
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 08/12/2025 21:04, \"Bisping, Benjamin\" (via cl-isabelle-users Mailing List) <br>\nwrote:</p>\n<blockquote>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT <br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for ITPs. <br>\nAnd if there's no easy automation for writing proofs in Isabelle, but there is <br>\nin Lean, I already know how 100 % of the listeners will decide which of the <br>\ntwo systems to look into.</p>\n</blockquote>\n<p>Oh dear, better use Lean then.</p>\n<p>Side-remark: The tool of choice for proof automation is called \"Sledgehammer\".</p>\n<p>Makarius</p>",
        "id": 562549256,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765224465
    },
    {
        "content": "<p><strong>From:</strong> Dominic Mulligan &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;</p>\n<p>Dear Benjamin,</p>\n<p>You may find the I/Q plugin interesting.  It exposes Isabelle as an MCP server to LLMs and allows the agent to interactively edit files, query proof states, and so on.</p>\n<p>The code is available here: <a href=\"https://github.com/awslabs/autocorrode\">https://github.com/awslabs/autocorrode</a></p>\n<p>It’s mainly been tested with Amazon’s Kiro CLI agent (formerly called Q CLI), but I believe at least one other person has used it in “anger” with another agent.</p>\n<p>Thanks,<br>\nDominic</p>\n<blockquote>\n<p>On 8 Dec 2025, at 20:04, Bisping, Benjamin (via cl-isabelle-users Mailing List) &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt; wrote:</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive theorem proving is the future of mathematics and verification. (I'm sure many on this mailing list know this situation.) I intend to build some arguments around Terence Tao getting ten-thousands of people to watch him use Lean+Copilot this year &lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will employ Isabelle/HOL for the demonstration, I strongly anticipate questions in the direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the incompatibilities introduced by Microsoft on one side and the Isabelle/Codium package on the other side.* This is a pity because, in principle, this year's LLM coding assistants appear to finally be quite decent at finding Isabelle proofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can solve tricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT promts) and JEdit is too clunky to be proposed in my “sales pitch” for ITPs. And if there's no easy automation for writing proofs in Isabelle, but there is in Lean, I already know how 100 % of the listeners will decide which of the two systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on LLM-supported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium <a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> . The 2025 message on the topic to this mailing list went unanswered <a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a> .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code, which otherwise would at least be some answer. <a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>\n</blockquote>",
        "id": 562549921,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765224738
    },
    {
        "content": "<p><strong>From:</strong> Wolfram Kahl &lt;<a href=\"mailto:kahl@cas.mcmaster.ca\">kahl@cas.mcmaster.ca</a>&gt;</p>\n<p>On Mon, Dec 08, 2025 at 09:07:26PM +0100, Makarius wrote:</p>\n<blockquote>\n<p>Side-remark: The tool of choice for proof automation is called <br>\n\"Sledgehammer\".</p>\n</blockquote>\n<p>Does that SOUND elegant and/or sophisticated to you?</p>\n<p>Perhaps a marketing problem...  ;-)</p>\n<p>Wolfram</p>",
        "id": 562550489,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765224998
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 08/12/2025 21:16, Wolfram Kahl wrote:</p>\n<blockquote>\n<p>On Mon, Dec 08, 2025 at 09:07:26PM +0100, Makarius wrote:</p>\n<blockquote>\n<p>Side-remark: The tool of choice for proof automation is called<br>\n\"Sledgehammer\".</p>\n</blockquote>\n<p>Does that SOUND elegant and/or sophisticated to you?</p>\n</blockquote>\n<p>Yes. It has become a well-established name in the ITP community. There are <br>\nalso many other \"Hammer\" projects, but not that successful.</p>\n<blockquote>\n<p>Perhaps a marketing problem...  ;-)<br>\nWho cares about marketing? I don't.</p>\n</blockquote>\n<p>Makarius</p>",
        "id": 562551010,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765225194
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>There is a DARPA program called PROVERS where I know some people are trying<br>\nto come with such a feature for Isabelle. You may want to reach out to<br>\nperformers of DARPA PROVERS. I believe that the Stanford University team<br>\nare cooking something for Isabelle.</p>\n<p>Although, computer scientists have to take a minute and remember that<br>\nundecidable problems such as finding proofs in HOL or finding invariants or<br>\neven writing a complete specification cannot be automated. This is what we<br>\nlearned in 3rd semester of CS class, specifically under theory of<br>\ncomputation, more specifically under computability theory.</p>\n<p>The best solution figured are ITPs themselves, where we have humans in the<br>\nloop to create computer assisted abstractions combined with symbolic AI<br>\ntools (i.e., automated reasoning via for example natural deduction)to<br>\nincrease automations.</p>\n<p>LLMs are the biggest imposters I have ever seen. They cannot be trusted to<br>\neven handle deterministic and repetitive processes. Let alone trusting them<br>\nto do reasoning.</p>\n<p>My 2 cents.</p>\n<p>Yakoub.</p>\n<p>On Mon, Dec 8, 2025 at 1:07 PM Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>\n<blockquote>\n<p>On 08/12/2025 21:04, \"Bisping, Benjamin\" (via cl-isabelle-users Mailing<br>\nList)<br>\nwrote:</p>\n<blockquote>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of<br>\nthe<br>\ntwo systems to look into.</p>\n</blockquote>\n<p>Oh dear, better use Lean then.</p>\n<p>Side-remark: The tool of choice for proof automation is called<br>\n\"Sledgehammer\".</p>\n<p>Makarius</p>\n</blockquote>",
        "id": 562551203,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765225274
    },
    {
        "content": "<p><strong>From:</strong> Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;</p>\n<p>It is quite hard to beat the simple combination of the structured Isar language and sledgehammer. First, just try sledgehammer. If it fails, think of an intermediate formula and try using sledgehammer to close both gaps. If not, continue with more intermediate formulas. Many straightforward proofs can be found that way.</p>\n<p>Larry<br>\nOn 8 Dec 2025 at 20:21 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;, wrote:</p>\n<p>The best solution figured are ITPs themselves, where we have humans in the loop to create computer assisted abstractions combined with symbolic AI tools (i.e., automated reasoning via for example natural deduction)to increase automations.</p>",
        "id": 562554705,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765226563
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>… and because the word AI is making the trend these days. Sledgehammer is<br>\nyour symbolic AI tool. And humans with their brain cells brings<br>\ntheir neurons. And so the interaction between a human and an ITP such as<br>\nIsabelle gives you the most powerful neuro symbolic AI tool.</p>\n<p>On Mon, Dec 8, 2025 at 1:42 PM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>It is quite hard to beat the simple combination of the structured Isar<br>\nlanguage and sledgehammer. First, just try sledgehammer. If it fails, think<br>\nof an intermediate formula and try using sledgehammer to close both gaps.<br>\nIf not, continue with more intermediate formulas. Many straightforward<br>\nproofs can be found that way.</p>\n<p>Larry<br>\nOn 8 Dec 2025 at 20:21 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;,<br>\nwrote:</p>\n<p>The best solution figured are ITPs themselves, where we have humans in the<br>\nloop to create computer assisted abstractions combined with symbolic AI<br>\ntools (i.e., automated reasoning via for example natural deduction)to<br>\nincrease automations.</p>\n</blockquote>",
        "id": 562558956,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765228321
    },
    {
        "content": "<p><strong>From:</strong> Kevin Kappelmann &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;</p>\n<p>Hi Ben,</p>\n<p>You can use Isabelle/VSCode (i.e. use <code>isabelle vscode</code> instead of <code>isabelle jedit</code>) and then install any extension you like from the open-vsx marketplace [1], e.g. continue [2], which can be connected to GPT-5.1 (I believe).</p>\n<p>Best wishes,</p>\n<p>Kevin</p>\n<p>[1] <a href=\"https://open-vsx.org/\">https://open-vsx.org/</a><br>\n[2] <a href=\"https://open-vsx.org/extension/Continue/continue\">https://open-vsx.org/extension/Continue/continue</a></p>\n<p>On 8 December 2025 21:04:32 CET, \"Bisping, Benjamin\" &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive theorem proving is the future of mathematics and verification. (I'm sure many on this mailing list know this situation.) I intend to build some arguments around Terence Tao getting ten-thousands of people to watch him use Lean+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will employ Isabelle/HOL for the demonstration, I strongly anticipate questions in the direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the incompatibilities introduced by Microsoft on one side and the Isabelle/Codium package on the other side.* This is a pity because, in principle, this year's LLM coding assistants appear to finally be quite decent at finding Isabelle proofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can solve tricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT promts) and JEdit is too clunky to be proposed in my “sales pitch” for ITPs. And if there's no easy automation for writing proofs in Isabelle, but there is in Lean, I already know how 100 % of the listeners will decide which of the two systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on LLM-supported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium <a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> . The 2025 message on the topic to this mailing list went unanswered <a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a> .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code, which otherwise would at least be some answer. <a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>\n</blockquote>",
        "id": 562559747,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765228635
    },
    {
        "content": "<p><strong>From:</strong> Changyang Zeng &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;</p>\n<p>Glad to see that some of us are building agents with Isabelle, I am just<br>\nwondering what kind of software or hardware people tend to use Isabelle to<br>\nprove?</p>\n<p>Thanks,<br>\nChangyang</p>\n<p>On Mon, Dec 8, 2025 at 2:05 PM Mete Polat &lt;<a href=\"mailto:metepolat2000@gmail.com\">metepolat2000@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Currently building an agentic IDE at <a href=\"http://omergence.dev\">omergence.dev</a> with Isabelle in the<br>\nbackend and GitHub Copilot built in. Hit me up if you have any questions or<br>\nare interested.</p>\n<p>On Mon, Dec 8, 2025, 12:04 \"Bisping, Benjamin\" &lt;<br>\n<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that<br>\ninteractive theorem proving is the future of mathematics and verification.<br>\n(I'm sure many on this mailing list know this situation.) I intend to build<br>\nsome arguments around Terence Tao getting ten-thousands of people to<br>\nwatch him use Lean+Copilot this year<br>\n&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will employ<br>\nIsabelle/HOL for the demonstration, I strongly anticipate questions in the<br>\ndirection of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to<br>\nthe incompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium package on the other side.* This is a pity because, in<br>\nprinciple, this year's LLM coding assistants appear to finally be quite<br>\ndecent at finding Isabelle proofs. If I open Isabelle/HOL theories in VS<br>\nCode, GPT-5.1-Codex can solve tricky stuff, for instance, find fitting<br>\ninduction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT promts) and JEdit is too clunky to be proposed in my “sales pitch”<br>\nfor ITPs. And if there's no easy automation for writing proofs in Isabelle,<br>\nbut there is in Lean, I already know how 100 % of the listeners will decide<br>\nwhich of the two systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-supported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium<br>\n<a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> .<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich otherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>\n</blockquote>\n</blockquote>",
        "id": 562567420,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765231880
    },
    {
        "content": "<p><strong>From:</strong> Mete Polat &lt;<a href=\"mailto:metepolat2000@gmail.com\">metepolat2000@gmail.com</a>&gt;</p>\n<p>Currently building an agentic IDE at <a href=\"http://omergence.dev\">omergence.dev</a> with Isabelle in the<br>\nbackend and GitHub Copilot built in. Hit me up if you have any questions or<br>\nare interested.</p>\n<p>On Mon, Dec 8, 2025, 12:04 \"Bisping, Benjamin\" &lt;<br>\n<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure<br>\nmany on this mailing list know this situation.) I intend to build some<br>\narguments around Terence Tao getting ten-thousands of people to watch him<br>\nuse Lean+Copilot this year &lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;.<br>\nAs I will employ Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in the direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium package on the other side.* This is a pity because, in<br>\nprinciple, this year's LLM coding assistants appear to finally be quite<br>\ndecent at finding Isabelle proofs. If I open Isabelle/HOL theories in VS<br>\nCode, GPT-5.1-Codex can solve tricky stuff, for instance, find fitting<br>\ninduction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs. And if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is in Lean, I already know how 100 % of the listeners will decide<br>\nwhich of the two systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-supported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium<br>\n<a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> .<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich otherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>\n</blockquote>",
        "id": 562569476,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765232885
    },
    {
        "content": "<p><strong>From:</strong> Jonathan Julián Huerta y Munive &lt;<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt;</p>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the future<br>\nto adhere to Isabelle standards. However, for the demonstration purposes<br>\nyou mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems in<br>\nIsabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the manual<br>\nparts at the end of the video.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"Uq7I5sGaHo0\" href=\"https://youtu.be/Uq7I5sGaHo0\"><img src=\"https://uploads.zulipusercontent.net/bf013da806a8d3abf8b775ac2f36c6dc7c386e1b/68747470733a2f2f692e7974696d672e636f6d2f76692f5571374935734761486f302f6d7164656661756c742e6a7067\"></a></div><p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for Isabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure<br>\nmany<br>\non this mailing list know this situation.) I intend to build some arguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate questions<br>\nin<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding Isabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can solve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of the<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich<br>\notherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<p>-- </p>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning</p>",
        "id": 562747605,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765300578
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>It would be great if someone holding a position at academia does a study<br>\nspecifically on ITPs. Comparing the amount of energy needed for<br>\nSledgehammer to generate a proof. And the amount of energy consumed to<br>\ntrain  GPT agents and prompting them to generate the same proof. And study<br>\nthe impact of energy consumption from prompting and training GPT agents on<br>\nsocieties, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<br>\n<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the future<br>\nto adhere to Isabelle standards. However, for the demonstration purposes<br>\nyou mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems in<br>\nIsabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the manual<br>\nparts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for<br>\nIsabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure<br>\nmany<br>\non this mailing list know this situation.) I intend to build some<br>\narguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I<br>\nwill<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding<br>\nIsabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can<br>\nsolve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of<br>\nthe<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich<br>\notherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<blockquote>\n<p>--</p>\n</blockquote>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning<br>\n</p>\n</blockquote>",
        "id": 562848387,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765335734
    },
    {
        "content": "<p><strong>From:</strong> Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;</p>\n<p>Sledgehammer run easily on a laptop and its energy consumption is essentially zero compared with the amount of energy consumed to train GPT agents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;, wrote:<br>\nIt would be great if someone holding a position at academia does a study specifically on ITPs. Comparing the amount of energy needed for Sledgehammer to generate a proof. And the amount of energy consumed to train  GPT agents and prompting them to generate the same proof. And study the impact of energy consumption from prompting and training GPT agents on societies, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;jonjulian23@gmail.com&lt;mailto:<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt;&gt; wrote:<br>\nHi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace Transformers.<br>\nIt is very much in a prototypical state and will be upgraded in the future to adhere to Isabelle standards. However, for the demonstration purposes you mention, it should suffice. For instance, here is a video&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems in Isabelle. The result is still interactive theorem proving, but the DeepIsaHOL project has support&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the manual parts at the end of the video.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"Uq7I5sGaHo0\" href=\"https://youtu.be/Uq7I5sGaHo0\"><img src=\"https://uploads.zulipusercontent.net/bf013da806a8d3abf8b775ac2f36c6dc7c386e1b/68747470733a2f2f692e7974696d672e636f6d2f76692f5571374935734761486f302f6d7164656661756c742e6a7067\"></a></div><p>Best wishes,<br>\nJonathan</p>\n<hr>\n<p>Message-ID: &lt;3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de&lt;mailto:<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;benjamin.bisping@tu-berlin.de&lt;mailto:<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for Isabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure many<br>\non this mailing list know this situation.) I intend to build some arguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate questions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"cyyR7j2ChCI\" href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\"><img src=\"https://uploads.zulipusercontent.net/0e5c80efbd7c87269bd3e04884f14b4765b18460/68747470733a2f2f692e7974696d672e636f6d2f76692f63797952376a32436843492f6d7164656661756c742e6a7067\"></a></div><p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the<br>\nincompatibilities introduced by Microsoft on one side and the Isabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this year's<br>\nLLM coding assistants appear to finally be quite decent at finding Isabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can solve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for ITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but there is<br>\nin Lean, I already know how 100 % of the listeners will decide which of the<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on LLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium<br>\n<a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> .<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a> .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code, which<br>\notherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>\n<p>--</p>\n<p>Jonathan Julian Huerta y Munive</p>\n<p>Researcher on formal methods and automated reasoning</p>",
        "id": 562899038,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765356472
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>That was exactly my point, Larry.</p>\n<p>Someone needs to put the light on these GPT agents with data as evidence.<br>\nSledgehammer used to give me an Isabelle proof with less energy and less<br>\ntime for quite complicated statements. Most of the time when the statement<br>\nis complicated the GPT agents will consume more energy and more time<br>\nwithout even generating a proof. And because GPT agents are good liars they<br>\nstill generate something and call it “ a profile of a proof”.</p>\n<p>Not only that, when I prompt them to translate some spec written in natural<br>\nlanguage to Isabelle/HOL, even if they generate something that works it is<br>\nalways looking clunky, not generic, can be better her and there. Namely, it<br>\nadds an unnecessary layer of distraction and time wasting for users.</p>\n<p>Maybe those GPT agents are good for certain tasks, but definitely not for<br>\nprogramming let alone reasoning.</p>\n<p>On Wed, Dec 10, 2025 at 1:47 AM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Sledgehammer run easily on a laptop and its energy consumption is<br>\nessentially zero compared with the amount of energy consumed to train GPT<br>\nagents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;,<br>\nwrote:</p>\n<p>It would be great if someone holding a position at academia does a study<br>\nspecifically on ITPs. Comparing the amount of energy needed for<br>\nSledgehammer to generate a proof. And the amount of energy consumed to<br>\ntrain  GPT agents and prompting them to generate the same proof. And study<br>\nthe impact of energy consumption from prompting and training GPT agents on<br>\nsocieties, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<br>\n<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the<br>\nfuture to adhere to Isabelle standards. However, for the demonstration<br>\npurposes you mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems<br>\nin Isabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the<br>\nmanual parts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a></p>\n<blockquote>\n<p>Date: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for<br>\nIsabelle?</p>\n</blockquote>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that<br>\ninteractive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure<br>\nmany<br>\non this mailing list know this situation.) I intend to build some<br>\narguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I<br>\nwill<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to<br>\nthe<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding<br>\nIsabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can<br>\nsolve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of<br>\nthe<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich<br>\notherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<blockquote>\n<p>--</p>\n</blockquote>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning</p>\n</blockquote>\n</blockquote>",
        "id": 562963711,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765375680
    },
    {
        "content": "<p><strong>From:</strong> Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;</p>\n<p>Useful to know. I find them good for finding things in our libraries (both lemmas and obscure syntax). They also generate pretend proofs.</p>\n<p>Larry</p>\n<blockquote>\n<p>On 10 Dec 2025, at 14:07, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt; wrote:</p>\n<p>Not only that, when I prompt them to translate some spec written in natural language to Isabelle/HOL, even if they generate something that works it is always looking clunky, not generic, can be better her and there. Namely, it adds an unnecessary layer of distraction and time wasting for users. <br>\n</p>\n</blockquote>",
        "id": 563007558,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765386505
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>I agree. Using them “carefully” as an advanced search engine can be<br>\nhelpful. Especially now we have a huge AFP repository and not all the users<br>\nare aware of it nor they setup it when they download Isabelle main<br>\ndistribution.</p>\n<p>My answers are based on the assumption coming from this thread which is<br>\npeople are using them to find proofs in HOL!</p>\n<p>Best wishes,<br>\nYakoub.<br>\nOn Wed, Dec 10, 2025 at 10:08 AM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Useful to know. I find them good for finding things in our libraries (both<br>\nlemmas and obscure syntax). They also generate pretend proofs.</p>\n<p>Larry</p>\n<blockquote>\n<p>On 10 Dec 2025, at 14:07, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt; wrote:</p>\n<p>Not only that, when I prompt them to translate some spec written in<br>\nnatural language to Isabelle/HOL, even if they generate something that<br>\nworks it is always looking clunky, not generic, can be better her and<br>\nthere. Namely, it adds an unnecessary layer of distraction and time wasting<br>\nfor users.<br>\n</p>\n</blockquote>\n</blockquote>",
        "id": 563010314,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765387284
    },
    {
        "content": "<p><strong>From:</strong> Josef Urban &lt;<a href=\"mailto:josef.urban@gmail.com\">josef.urban@gmail.com</a>&gt;</p>\n<p>I said recently in a talk that the ATP and hammer algorithms were<br>\n\"generative AI\" long before LLMs appeared [1]. For someone using a hammer<br>\n(or an efficient tactical prover like TacticToe/Tactician) routinely to get<br>\ncorrect proofs, \"Chatgpt as a prover\" felt like an expensive joke when it<br>\nfirst appeared. (I have started to call Chatgpt a \"gateway drug to ML\" :).</p>\n<p>I would hope the \"magic of scaling up\" hype is mostly over and even the<br>\nLLM/DL community has recently (e.g. with the Deepseek paper) acknowledged<br>\nthat efficient search/reasoning and combinations of algorithms matter a lot<br>\n(cf \"agentic AI\" as the next emerging buzzword).</p>\n<p>Projects like Jonathan's should allow people in academia to eventually<br>\nrigorously evaluate which (combinations of) algorithms and architectures<br>\nwork better than others. There has been plenty of decent and<br>\ninteresting/innovative work done continuously by the AITP community in this<br>\ndirection (e.g. [2,3] pointing to nice non-Transformer architectures).<br>\nHopefully, some of the \"super excited\" mathematicians will eventually<br>\nrealize that AI/TP is also a science ;-).</p>\n<p>Josef</p>\n<p>[1] <a href=\"https://github.com/JUrban/LMvsATP\">https://github.com/JUrban/LMvsATP</a><br>\n[2] <a href=\"https://arxiv.org/abs/2401.02949\">https://arxiv.org/abs/2401.02949</a><br>\n[3] <a href=\"https://arxiv.org/abs/2503.07792\">https://arxiv.org/abs/2503.07792</a></p>\n<p>On Wed, Dec 10, 2025, 7:47 PM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Sledgehammer run easily on a laptop and its energy consumption is<br>\nessentially zero compared with the amount of energy consumed to train GPT<br>\nagents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;,<br>\nwrote:</p>\n<p>It would be great if someone holding a position at academia does a study<br>\nspecifically on ITPs. Comparing the amount of energy needed for<br>\nSledgehammer to generate a proof. And the amount of energy consumed to<br>\ntrain  GPT agents and prompting them to generate the same proof. And study<br>\nthe impact of energy consumption from prompting and training GPT agents on<br>\nsocieties, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<br>\n<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the<br>\nfuture to adhere to Isabelle standards. However, for the demonstration<br>\npurposes you mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems<br>\nin Isabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the<br>\nmanual parts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a></p>\n<blockquote>\n<p>Date: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for<br>\nIsabelle?</p>\n</blockquote>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that<br>\ninteractive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure<br>\nmany<br>\non this mailing list know this situation.) I intend to build some<br>\narguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I<br>\nwill<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to<br>\nthe<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding<br>\nIsabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can<br>\nsolve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of<br>\nthe<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich<br>\notherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<blockquote>\n<p>--</p>\n</blockquote>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning</p>\n</blockquote>\n</blockquote>",
        "id": 563040229,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765397448
    },
    {
        "content": "<p><strong>From:</strong> \"\\\"Lammich, Peter (UT-EEMCS)\\\"\" &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;</p>\n<p>I've seen ChatGPT hallucinating lemma and function names that do not exist. And coming up with pretty random looking 'proofs', that obviously don't work. Is there a better model for that than GPT?</p>\n<p>Peter</p>\n<p>On 10 Dec 2025 18:08, Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:<br>\nUseful to know. I find them good for finding things in our libraries (both lemmas and obscure syntax). They also generate pretend proofs.</p>\n<p>Larry</p>\n<blockquote>\n<p>On 10 Dec 2025, at 14:07, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt; wrote:</p>\n<p>Not only that, when I prompt them to translate some spec written in natural language to Isabelle/HOL, even if they generate something that works it is always looking clunky, not generic, can be better her and there. Namely, it adds an unnecessary layer of distraction and time wasting for users.<br>\n</p>\n</blockquote>",
        "id": 563050087,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765399923
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>I think this is the right approach. Before introducing such a tool to<br>\nstudent, it is always good to remind the about foundations of computation,<br>\nand have the following reminder/disclaimer at the beginning:</p>\n<p>“In CS there is a set of problems called undecidable problems that cannot<br>\nbe automated by any kind of algorithm, whether it is AI based or not. For<br>\nexample, there is no algorithm that allows to systematically provide a yes<br>\nor no answer to all statements written in HOL and automatically know if a<br>\nproof exists, i.e., demonstrating automatically if the statement is true or<br>\nfalse for all HOL formulas. The best solution figured so far are ITPs<br>\nthemselves ( including their backend consisting automated reasoning tools).<br>\nNow we have a new expansive toy in town, which is less efficient and way<br>\nmore taxing for society, environment, and communities. If you guys really<br>\nwant to use it anyways, here is how.  And by the way this is not the only<br>\nform of AI that exits, symbolic AI (i.e., automated reasoning tools)<br>\nexisted for at least the last 50 years.”</p>\n<p>On Wed, Dec 10, 2025 at 1:10 PM Josef Urban &lt;<a href=\"mailto:josef.urban@gmail.com\">josef.urban@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>I said recently in a talk that the ATP and hammer algorithms were<br>\n\"generative AI\" long before LLMs appeared [1]. For someone using a hammer<br>\n(or an efficient tactical prover like TacticToe/Tactician) routinely to get<br>\ncorrect proofs, \"Chatgpt as a prover\" felt like an expensive joke when it<br>\nfirst appeared. (I have started to call Chatgpt a \"gateway drug to ML\" :).</p>\n<p>I would hope the \"magic of scaling up\" hype is mostly over and even the<br>\nLLM/DL community has recently (e.g. with the Deepseek paper) acknowledged<br>\nthat efficient search/reasoning and combinations of algorithms matter a lot<br>\n(cf \"agentic AI\" as the next emerging buzzword).</p>\n<p>Projects like Jonathan's should allow people in academia to eventually<br>\nrigorously evaluate which (combinations of) algorithms and architectures<br>\nwork better than others. There has been plenty of decent and<br>\ninteresting/innovative work done continuously by the AITP community in this<br>\ndirection (e.g. [2,3] pointing to nice non-Transformer architectures).<br>\nHopefully, some of the \"super excited\" mathematicians will eventually<br>\nrealize that AI/TP is also a science ;-).</p>\n<p>Josef</p>\n<p>[1] <a href=\"https://github.com/JUrban/LMvsATP\">https://github.com/JUrban/LMvsATP</a><br>\n[2] <a href=\"https://arxiv.org/abs/2401.02949\">https://arxiv.org/abs/2401.02949</a><br>\n[3] <a href=\"https://arxiv.org/abs/2503.07792\">https://arxiv.org/abs/2503.07792</a></p>\n<p>On Wed, Dec 10, 2025, 7:47 PM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Sledgehammer run easily on a laptop and its energy consumption is<br>\nessentially zero compared with the amount of energy consumed to train GPT<br>\nagents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;,<br>\nwrote:</p>\n<p>It would be great if someone holding a position at academia does a study<br>\nspecifically on ITPs. Comparing the amount of energy needed for<br>\nSledgehammer to generate a proof. And the amount of energy consumed to<br>\ntrain  GPT agents and prompting them to generate the same proof. And study<br>\nthe impact of energy consumption from prompting and training GPT agents on<br>\nsocieties, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<br>\n<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the<br>\nfuture to adhere to Isabelle standards. However, for the demonstration<br>\npurposes you mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems<br>\nin Isabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the<br>\nmanual parts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<br>\n<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for<br>\nIsabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that<br>\ninteractive<br>\ntheorem proving is the future of mathematics and verification. (I'm<br>\nsure many<br>\non this mailing list know this situation.) I intend to build some<br>\narguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I<br>\nwill<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to<br>\nthe<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding<br>\nIsabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can<br>\nsolve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of<br>\nthe<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered</p>\n<p><a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich<br>\notherwise would at least be some answer.</p>\n<p><a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<blockquote>\n<p>--</p>\n</blockquote>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning</p>\n</blockquote>\n</blockquote>\n</blockquote>",
        "id": 563050101,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765399926
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 08/12/2025 21:07, Makarius wrote:</p>\n<blockquote>\n<p>better use Lean then.</p>\n</blockquote>\n<p>More side-remarks: The Lean community has enough money and manpower to follow <br>\nthe latest and greatest trends quickly, even if they turn out dead ends. Thus <br>\nit is always interesting to attend the virtual Lean Together event, every year <br>\nin January. Non-Lean users are explicitly welcome.</p>\n<p>The website for Jan-2026 is here: <a href=\"https://leanprover-community.github.io/lt2026\">https://leanprover-community.github.io/lt2026</a></p>\n<p>The past event from Jan-2025 is documented here: <br>\n<a href=\"https://leanprover-community.github.io/lt2025/schedule.html\">https://leanprover-community.github.io/lt2025/schedule.html</a></p>\n<p>This particular talk from 15-Jan-2025 is relevant to the current mail thread:</p>\n<p>\"\"\"<br>\nJason Rute (IBM Research)</p>\n<p>Title: The last mile: How do we make AI theorem provers which work in the real <br>\nworld for real users and not just on benchmarks?</p>\n<p>Abstract: As AI research progresses, we are seeing massive gains on formal <br>\nmath benchmarks like MiniF2F and challenges like the IMO. However, these gains <br>\nare not directly accessible to the typical ITP user, nor are they used to <br>\nbuild formal mathematical libraries. Is this because the technology is not as <br>\ngood as promised or because there is a disconnect between research and the <br>\nday-to-day needs of users? I propose that even today, we have sufficient AI <br>\ntechnology to enhance the experience of proof assistant users significantly. I <br>\napproach this from the lens of product-focused software engineering. How do we <br>\nbridge “the last mile” to make a useful product for the end user?<br>\n\"\"\"</p>\n<p>E.g. see this introductory slide \"Why don't we have AI assistants for real ITP <br>\nusers?\" <a href=\"https://youtu.be/Yr8dzfVkeHg?t=141\">https://youtu.be/Yr8dzfVkeHg?t=141</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"Yr8dzfVkeHg\" href=\"https://youtu.be/Yr8dzfVkeHg?t=141\"><img src=\"https://uploads.zulipusercontent.net/b6f6457a0ce3de21445be6f2de56ad6060528140/68747470733a2f2f692e7974696d672e636f6d2f76692f597238647a66566b6548672f6d7164656661756c742e6a7067\"></a></div><p>I have attended the talk virtually on that day. To me, the abstract sounded <br>\nmore optimistic than the impression given in the talk. I have mentally <br>\nticked-off the topic with the note: \"Check again in 3-5 years, if they have <br>\nsomething that works properly, or have discovered that the very approach is a <br>\nbad idea\".</p>\n<p>It will be still interesting to see what will be presented in a few weeks on <br>\nvirtual Lean Together 2026.</p>\n<p>Makarius</p>",
        "id": 563057813,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765401279
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>Peter, if you want something serious I suggest you build your GPT agent<br>\nbased on Mistral models. I trust tech coming from France because French<br>\neducation system have a culture of looping in reasoning techniques for<br>\ncomputation in CS class, rather than teaching students engineering<br>\n techniques that rely only on brute force computation.</p>\n<p>I always keep an eye on tech products coming from researchers or companies<br>\nbased in France. They always end up finding a balance between powerful<br>\ncomputation and resource efficiency for their products because they loop in<br>\nreasoning in their R&amp;D. Maybe my perception is wrong but this is my<br>\npersonal experience with other tech products.</p>\n<p>PS: I am Isabelle user not Coq user. But for example Isabelle/Naproche is<br>\nbased on CNL model from Franch research institution. I am sure Sledgehammer<br>\nleverage a lot from french researchers.</p>\n<p>Best wishes,<br>\nYakoub.</p>\n<p>On Wed, Dec 10, 2025 at 1:51 PM Lammich, Peter (UT-EEMCS) &lt;<br>\n<a href=\"mailto:p.lammich@utwente.nl\">p.lammich@utwente.nl</a>&gt; wrote:</p>\n<blockquote>\n<p>I've seen ChatGPT hallucinating lemma and function names that do not<br>\nexist. And coming up with pretty random looking 'proofs', that obviously<br>\ndon't work. Is there a better model for that than GPT?</p>\n<p>Peter</p>\n<p>On 10 Dec 2025 18:08, Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:<br>\nUseful to know. I find them good for finding things in our libraries (both<br>\nlemmas and obscure syntax). They also generate pretend proofs.</p>\n<p>Larry</p>\n<blockquote>\n<p>On 10 Dec 2025, at 14:07, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt; wrote:</p>\n<p>Not only that, when I prompt them to translate some spec written in<br>\nnatural language to Isabelle/HOL, even if they generate something that<br>\nworks it is always looking clunky, not generic, can be better her and<br>\nthere. Namely, it adds an unnecessary layer of distraction and time wasting<br>\nfor users.<br>\n</p>\n</blockquote>\n</blockquote>",
        "id": 563068249,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765404012
    },
    {
        "content": "<p><strong>From:</strong> waldinge &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;</p>\n<p>Plugging my recent paper on extracting programs from automatically discovered proofs.  (No LLMs used, but the matter is discussed).<br>\n<a href=\"https://arxiv.org/abs/2508.11136\">https://arxiv.org/abs/2508.11136</a></p>\n<blockquote>\n<p>On Dec 10, 2025, at 12:51 PM, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt; wrote:</p>\n<p>I think this is the right approach. Before introducing such a tool to student, it is always good to remind the about foundations of computation, and have the following reminder/disclaimer at the beginning:</p>\n<p>“In CS there is a set of problems called undecidable problems that cannot be automated by any kind of algorithm, whether it is AI based or not. For example, there is no algorithm that allows to systematically provide a yes or no answer to all statements written in HOL and automatically know if a proof exists, i.e., demonstrating automatically if the statement is true or false for all HOL formulas. The best solution figured so far are ITPs themselves ( including their backend consisting automated reasoning tools). Now we have a new expansive toy in town, which is less efficient and way more taxing for society, environment, and communities. If you guys really want to use it anyways, here is how.  And by the way this is not the only form of AI that exits, symbolic AI (i.e., automated reasoning tools) existed for at least the last 50 years.”</p>\n<p>On Wed, Dec 10, 2025 at 1:10 PM Josef Urban &lt;<a href=\"mailto:josef.urban@gmail.com\">josef.urban@gmail.com</a> &lt;mailto:<a href=\"mailto:josef.urban@gmail.com\">josef.urban@gmail.com</a>&gt;&gt; wrote:</p>\n<blockquote>\n<p>I said recently in a talk that the ATP and hammer algorithms were \"generative AI\" long before LLMs appeared [1]. For someone using a hammer (or an efficient tactical prover like TacticToe/Tactician) routinely to get correct proofs, \"Chatgpt as a prover\" felt like an expensive joke when it first appeared. (I have started to call Chatgpt a \"gateway drug to ML\" :).</p>\n<p>I would hope the \"magic of scaling up\" hype is mostly over and even the LLM/DL community has recently (e.g. with the Deepseek paper) acknowledged that efficient search/reasoning and combinations of algorithms matter a lot (cf \"agentic AI\" as the next emerging buzzword).</p>\n<p>Projects like Jonathan's should allow people in academia to eventually rigorously evaluate which (combinations of) algorithms and architectures work better than others. There has been plenty of decent and interesting/innovative work done continuously by the AITP community in this direction (e.g. [2,3] pointing to nice non-Transformer architectures). Hopefully, some of the \"super excited\" mathematicians will eventually realize that AI/TP is also a science ;-).</p>\n<p>Josef </p>\n<p>[1] <a href=\"https://github.com/JUrban/LMvsATP\">https://github.com/JUrban/LMvsATP</a><br>\n[2] <a href=\"https://arxiv.org/abs/2401.02949\">https://arxiv.org/abs/2401.02949</a><br>\n[3] <a href=\"https://arxiv.org/abs/2503.07792\">https://arxiv.org/abs/2503.07792</a></p>\n<p>On Wed, Dec 10, 2025, 7:47 PM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a> &lt;mailto:<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;&gt; wrote:</p>\n<blockquote>\n<p>Sledgehammer run easily on a laptop and its energy consumption is essentially zero compared with the amount of energy consumed to train GPT agents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a> &lt;mailto:<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;&gt;, wrote:</p>\n<blockquote>\n<p>It would be great if someone holding a position at academia does a study specifically on ITPs. Comparing the amount of energy needed for Sledgehammer to generate a proof. And the amount of energy consumed to train  GPT agents and prompting them to generate the same proof. And study the impact of energy consumption from prompting and training GPT agents on societies, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a> &lt;mailto:<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt;&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project &lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace Transformers.<br>\nIt is very much in a prototypical state and will be upgraded in the future to adhere to Isabelle standards. However, for the demonstration purposes you mention, it should suffice. For instance, here is a video &lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems in Isabelle. The result is still interactive theorem proving, but the DeepIsaHOL project has support &lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the manual parts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<blockquote>\n<hr>\n<p>Message-ID: &lt;<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a> &lt;mailto:<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a> &lt;mailto:<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for Isabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that interactive<br>\ntheorem proving is the future of mathematics and verification. (I'm sure many<br>\non this mailing list know this situation.) I intend to build some arguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I will<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate questions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to the<br>\nincompatibilities introduced by Microsoft on one side and the Isabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this year's<br>\nLLM coding assistants appear to finally be quite decent at finding Isabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can solve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or ChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for ITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but there is<br>\nin Lean, I already know how 100 % of the listeners will decide which of the<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on LLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium<br>\n<a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a> .<br>\nThe 2025 message on the topic to this mailing list went unanswered<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a> .<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code, which<br>\notherwise would at least be some answer.<br>\n<a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></li>\n</ul>\n</blockquote>\n<p>&gt; </p>\n<p>--</p>\n<p>Jonathan Julian Huerta y Munive <br>\nResearcher on formal methods and automated reasoning</p>\n</blockquote>\n</blockquote>\n</blockquote>\n</blockquote>\n</blockquote>",
        "id": 563086630,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765414080
    },
    {
        "content": "<p><strong>From:</strong> Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;</p>\n<p>Josef -</p>\n<p>Just for clarification. I am not questioning the value of Jonathan’s work<br>\nor others work.</p>\n<p>I am just trying to create some awareness for CS community in the middle of<br>\nthis LLMs noise.</p>\n<p>Best,<br>\nYakoub.</p>\n<p>On Wed, Dec 10, 2025 at 1:10 PM Josef Urban &lt;<a href=\"mailto:josef.urban@gmail.com\">josef.urban@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>I said recently in a talk that the ATP and hammer algorithms were<br>\n\"generative AI\" long before LLMs appeared [1]. For someone using a hammer<br>\n(or an efficient tactical prover like TacticToe/Tactician) routinely to get<br>\ncorrect proofs, \"Chatgpt as a prover\" felt like an expensive joke when it<br>\nfirst appeared. (I have started to call Chatgpt a \"gateway drug to ML\" :).</p>\n<p>I would hope the \"magic of scaling up\" hype is mostly over and even the<br>\nLLM/DL community has recently (e.g. with the Deepseek paper) acknowledged<br>\nthat efficient search/reasoning and combinations of algorithms matter a lot<br>\n(cf \"agentic AI\" as the next emerging buzzword).</p>\n<p>Projects like Jonathan's should allow people in academia to eventually<br>\nrigorously evaluate which (combinations of) algorithms and architectures<br>\nwork better than others. There has been plenty of decent and<br>\ninteresting/innovative work done continuously by the AITP community in this<br>\ndirection (e.g. [2,3] pointing to nice non-Transformer architectures).<br>\nHopefully, some of the \"super excited\" mathematicians will eventually<br>\nrealize that AI/TP is also a science ;-).</p>\n<p>Josef</p>\n<p>[1] <a href=\"https://github.com/JUrban/LMvsATP\">https://github.com/JUrban/LMvsATP</a><br>\n[2] <a href=\"https://arxiv.org/abs/2401.02949\">https://arxiv.org/abs/2401.02949</a><br>\n[3] <a href=\"https://arxiv.org/abs/2503.07792\">https://arxiv.org/abs/2503.07792</a></p>\n<p>On Wed, Dec 10, 2025, 7:47 PM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Sledgehammer run easily on a laptop and its energy consumption is<br>\nessentially zero compared with the amount of energy consumed to train GPT<br>\nagents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;,<br>\nwrote:</p>\n<p>It would be great if someone holding a position at academia does a study<br>\nspecifically on ITPs. Comparing the amount of energy needed for<br>\nSledgehammer to generate a proof. And the amount of energy consumed to<br>\ntrain  GPT agents and prompting them to generate the same proof. And study<br>\nthe impact of energy consumption from prompting and training GPT agents on<br>\nsocieties, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<br>\n<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the<br>\nfuture to adhere to Isabelle standards. However, for the demonstration<br>\npurposes you mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems<br>\nin Isabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the<br>\nmanual parts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<br>\n<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for<br>\nIsabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that<br>\ninteractive<br>\ntheorem proving is the future of mathematics and verification. (I'm<br>\nsure many<br>\non this mailing list know this situation.) I intend to build some<br>\narguments<br>\naround Terence Tao getting ten-thousands of people to watch him use Lean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I<br>\nwill<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to<br>\nthe<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding<br>\nIsabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can<br>\nsolve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which of<br>\nthe<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions on<br>\nLLM-<br>\nsupported proof generation in Isabelle I could report to advertise it?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered</p>\n<p><a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS Code,<br>\nwhich<br>\notherwise would at least be some answer.</p>\n<p><a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<blockquote>\n<p>--</p>\n</blockquote>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning</p>\n</blockquote>\n</blockquote>\n</blockquote>",
        "id": 563173540,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765455743
    },
    {
        "content": "<p><strong>From:</strong> Harry Butterworth &lt;<a href=\"mailto:heb1001@gmail.com\">heb1001@gmail.com</a>&gt;</p>\n<p>I think the main thing missing from historical AI approaches in general is<br>\nthe ability to create higher level abstractions from observations.</p>\n<p>IMO, creating higher level abstractions is a significant part of what maths<br>\nis about: observe a pattern, make a formal statement of the pattern, search<br>\nfor a proof to determine if the pattern always holds.</p>\n<p>If you consider that mathematical expressions and statements are enumerable<br>\nthen the interesting proofs are those that appear on the shortest paths<br>\nlinking nodes of the tree of the enumeration where proofs linking nodes<br>\ncloser to the root of the tree are more interesting and useful (because<br>\nthey are more generic) than proofs linking nodes at more remote levels<br>\n(where they are more specific).</p>\n<p>Taking Euler’s identity as an example: it’s a statement that sits near the<br>\nroot of the tree (because it’s short) that links expressions that also sit<br>\nnear the root of the tree (because they are short too) and it’s an<br>\nabstraction — a shortcut — for its own proof which, in contrast, is a more<br>\nconvoluted path that climbs high up into the branches of the tree before<br>\ncoming back down again.</p>\n<p>The “noise” about LLMs has arisen because they are demonstrating the<br>\nability to create higher level abstractions from observations (the training<br>\ndata) during self-supervised learning without requiring explicit human<br>\ninput.  This is abductive inference and it’s something that historical<br>\napproaches can’t do (AFAIK).</p>\n<p>LLMs are not necessarily the best architecture for abductive inference and<br>\nthe scaffolding around current LLMs is not necessarily particularly<br>\nappropriate for doing mathematics but LLMs do represent a step change in<br>\nthe right direction in terms of capability.</p>\n<p>Undecidability and Godel’s theorems do not restrict computers from becoming<br>\nsuperhuman at mathematics (even if you believe in some kind of substrate<br>\ndependence, which I don’t, it is possible to create biological computers).</p>\n<p>Another way of looking at Godel’s theorems is that every undecidable<br>\nproposition creates two new branches within mathematics and that this<br>\nbranching tree is proved to be infinite.  You wouldn’t want it any other<br>\nway as there is an isomorphism between reality and a mathematical<br>\ndescription of reality and who would choose to live in a finite universe?</p>\n<p>In fact, if you subscribe to the simulation hypothesis (and consequentially<br>\nthe dual aspect theory of information), the entire universe may simply be<br>\nthe internal perspective of a theorem prover currently working on a<br>\nstatement which is isomorphic to me winning this argument about the<br>\nsignificance of LLMs.  A statement somewhere almost inconceivably high up<br>\nin the branches of highly specific and asymptotically useless mathematics.</p>\n<p>Enjoy!</p>\n<p>On Thu, 11 Dec 2025 at 12:22, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Josef -</p>\n<p>Just for clarification. I am not questioning the value of Jonathan’s work<br>\nor others work.</p>\n<p>I am just trying to create some awareness for CS community in the middle<br>\nof this LLMs noise.</p>\n<p>Best,<br>\nYakoub.</p>\n<p>On Wed, Dec 10, 2025 at 1:10 PM Josef Urban &lt;<a href=\"mailto:josef.urban@gmail.com\">josef.urban@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>I said recently in a talk that the ATP and hammer algorithms were<br>\n\"generative AI\" long before LLMs appeared [1]. For someone using a hammer<br>\n(or an efficient tactical prover like TacticToe/Tactician) routinely to get<br>\ncorrect proofs, \"Chatgpt as a prover\" felt like an expensive joke when it<br>\nfirst appeared. (I have started to call Chatgpt a \"gateway drug to ML\" :).</p>\n<p>I would hope the \"magic of scaling up\" hype is mostly over and even the<br>\nLLM/DL community has recently (e.g. with the Deepseek paper) acknowledged<br>\nthat efficient search/reasoning and combinations of algorithms matter a lot<br>\n(cf \"agentic AI\" as the next emerging buzzword).</p>\n<p>Projects like Jonathan's should allow people in academia to eventually<br>\nrigorously evaluate which (combinations of) algorithms and architectures<br>\nwork better than others. There has been plenty of decent and<br>\ninteresting/innovative work done continuously by the AITP community in this<br>\ndirection (e.g. [2,3] pointing to nice non-Transformer architectures).<br>\nHopefully, some of the \"super excited\" mathematicians will eventually<br>\nrealize that AI/TP is also a science ;-).</p>\n<p>Josef</p>\n<p>[1] <a href=\"https://github.com/JUrban/LMvsATP\">https://github.com/JUrban/LMvsATP</a><br>\n[2] <a href=\"https://arxiv.org/abs/2401.02949\">https://arxiv.org/abs/2401.02949</a><br>\n[3] <a href=\"https://arxiv.org/abs/2503.07792\">https://arxiv.org/abs/2503.07792</a></p>\n<p>On Wed, Dec 10, 2025, 7:47 PM Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Sledgehammer run easily on a laptop and its energy consumption is<br>\nessentially zero compared with the amount of energy consumed to train GPT<br>\nagents.</p>\n<p>Larry<br>\nOn 10 Dec 2025 at 03:01 +0000, Yakoub Nemouchi &lt;<a href=\"mailto:y.nemouchi@gmail.com\">y.nemouchi@gmail.com</a>&gt;,<br>\nwrote:</p>\n<p>It would be great if someone holding a position at academia does a study<br>\nspecifically on ITPs. Comparing the amount of energy needed for<br>\nSledgehammer to generate a proof. And the amount of energy consumed to<br>\ntrain  GPT agents and prompting them to generate the same proof. And study<br>\nthe impact of energy consumption from prompting and training GPT agents on<br>\nsocieties, communities and environment.</p>\n<p>Best wishes,</p>\n<p>Yakoub.<br>\nOn Tue, Dec 9, 2025 at 10:06 AM Jonathan Julián Huerta y Munive &lt;<br>\n<a href=\"mailto:jonjulian23@gmail.com\">jonjulian23@gmail.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Benjamin,</p>\n<p>You might want to try the resources in the DeepIsaHOL project<br>\n&lt;<a href=\"https://github.com/yonoteam/DeepIsaHOL\">https://github.com/yonoteam/DeepIsaHOL</a>&gt;.<br>\nCurrently it has support for ChatGPT, Gemini, Ollama, and HuggingFace<br>\nTransformers.<br>\nIt is very much in a prototypical state and will be upgraded in the<br>\nfuture to adhere to Isabelle standards. However, for the demonstration<br>\npurposes you mention, it should suffice. For instance, here is a video<br>\n&lt;<a href=\"https://youtu.be/Uq7I5sGaHo0\">https://youtu.be/Uq7I5sGaHo0</a>&gt; showing ChatGPT proving simple theorems<br>\nin Isabelle. The result is still interactive theorem proving, but the<br>\nDeepIsaHOL project has support<br>\n&lt;<a href=\"https://ieeexplore.ieee.org/document/11024329\">https://ieeexplore.ieee.org/document/11024329</a>&gt; for automating the<br>\nmanual parts at the end of the video.</p>\n<p>Best wishes,<br>\nJonathan</p>\n<hr>\n<blockquote>\n<p>Message-ID: &lt;<br>\n<a href=\"mailto:3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de\">3ee6efa75b672760cd3484fe2ca903abafddfdd5.camel@tu-berlin.de</a>&gt;<br>\nDate: Mon, 8 Dec 2025 20:04:32 +0000<br>\nFrom: \"Bisping, Benjamin\" &lt;<a href=\"mailto:benjamin.bisping@tu-berlin.de\">benjamin.bisping@tu-berlin.de</a>&gt;<br>\nSubject: [isabelle] Copilot (or other programming assistants) for<br>\nIsabelle?</p>\n<p>Hello everybody,</p>\n<p>This week, I plan to convince a computer science audience that<br>\ninteractive<br>\ntheorem proving is the future of mathematics and verification. (I'm<br>\nsure many<br>\non this mailing list know this situation.) I intend to build some<br>\narguments<br>\naround Terence Tao getting ten-thousands of people to watch him use<br>\nLean<br>\n+Copilot this year&lt;<a href=\"https://www.youtube.com/watch?v=cyyR7j2ChCI\">https://www.youtube.com/watch?v=cyyR7j2ChCI</a>&gt;. As I<br>\nwill<br>\nemploy Isabelle/HOL for the demonstration, I strongly anticipate<br>\nquestions in<br>\nthe direction of how to hook it up with GitHub Copilot.</p>\n<p>I tried it myself and Isabelle+Copilot seems highly non-trivial due to<br>\nthe<br>\nincompatibilities introduced by Microsoft on one side and the<br>\nIsabelle/Codium<br>\npackage on the other side.* This is a pity because, in principle, this<br>\nyear's<br>\nLLM coding assistants appear to finally be quite decent at finding<br>\nIsabelle<br>\nproofs. If I open Isabelle/HOL theories in VS Code, GPT-5.1-Codex can<br>\nsolve<br>\ntricky stuff, for instance, find fitting induction invariants.</p>\n<p>But of course, the workflow to co-edit theories between VSCode (or<br>\nChatGPT<br>\npromts) and JEdit is too clunky to be proposed in my “sales pitch” for<br>\nITPs.<br>\nAnd if there's no easy automation for writing proofs in Isabelle, but<br>\nthere is<br>\nin Lean, I already know how 100 % of the listeners will decide which<br>\nof the<br>\ntwo systems to look into.</p>\n<p>I wonder whether people here have positive experiences / suggestions<br>\non LLM-<br>\nsupported proof generation in Isabelle I could report to advertise<br>\nit?**</p>\n<p>Kind regards,</p>\n<p>Ben</p>\n<ul>\n<li>Prior 2023 hacky solution for Copilot in Isabelle's VS Codium</li>\n</ul>\n<p><a href=\"https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html\">https://isabelle.systems/zulip-archive/stream/202961-General/topic/Isabelle.2FVSCode.20Github.20Copilot.html</a><br>\n.<br>\nThe 2025 message on the topic to this mailing list went unanswered</p>\n<p><a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2025-05/msg00002.html</a><br>\n.<br>\n** Prior discussion about the discontinued Isabelle plugin for VS<br>\nCode, which<br>\notherwise would at least be some answer.</p>\n<p><a href=\"https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html\">https://lists.cam.ac.uk/sympa/arc/cl-isabelle-users/2023-10/msg00005.html</a></p>\n</blockquote>\n<blockquote>\n<p>--</p>\n</blockquote>\n<p>*Jonathan Julian Huerta y Munive *</p>\n<p>Researcher on formal methods and automated reasoning</p>\n</blockquote>\n</blockquote>\n</blockquote>\n</blockquote>",
        "id": 563213557,
        "sender_full_name": "Email Gateway",
        "timestamp": 1765466324
    }
]