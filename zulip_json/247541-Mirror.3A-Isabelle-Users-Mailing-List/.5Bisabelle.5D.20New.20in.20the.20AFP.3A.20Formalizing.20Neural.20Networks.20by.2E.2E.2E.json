[
    {
        "content": "<p>From: \"Thiemann, René\" &lt;<a href=\"mailto:cl-isabelle-users@lists.cam.ac.uk\">cl-isabelle-users@lists.cam.ac.uk</a>&gt;<br>\nDear all,</p>\n<p>I’m happy to announce a new AFP entry.</p>\n<p>Formalizing Neural Networks<br>\n  by Achim D. Brucker and Amy Stell</p>\n<p>Abstract</p>\n<p>Deep learning, i.e., machine learning using neural networks, is used<br>\nsuccessfully in many application areas. Still, their use in safety-critical or<br>\nsecurity-critical applications is limited, due to the lack of testing and<br>\nverification techniques. We address this problem by formalizing an important<br>\nclass of neural networks, feed-forward neural networks, in Isabelle/HOL. We<br>\npresent two different approaches of formalizing feed-forward networks and show<br>\ntheir equivalence as well as demonstrate their use in verifying certain safety<br>\nand correctness properties of various example. Moreover, we do not only provide<br>\na formal model that allows to reason over feed-forward neural networks, we also<br>\nprovide a datatype package for Isabelle/HOL that supports importing models from<br>\nTensorFlow.js.</p>\n<p><a href=\"https://www.isa-afp.org/entries/Neural_Networks.html\">https://www.isa-afp.org/entries/Neural_Networks.html</a></p>\n<p>Enjoy,<br>\nRené</p>",
        "id": 556821933,
        "sender_full_name": "Email Gateway",
        "timestamp": 1763383950
    }
]