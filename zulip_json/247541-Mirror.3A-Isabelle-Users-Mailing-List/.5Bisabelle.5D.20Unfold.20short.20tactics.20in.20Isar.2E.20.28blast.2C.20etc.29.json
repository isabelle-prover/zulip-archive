[
    {
        "content": "<p>From: Georgy Dunaev &lt;<a href=\"mailto:georgedunaev@gmail.com\">georgedunaev@gmail.com</a>&gt;<br>\nHow to deal with short proofs like \"by blast\"?<br>\nThey leave gaps in the knowledge of reader, force one to re-prove theorems.</p>\n<p>I mean the best option is to obtain some information about proof. (Not just<br>\n\"Yes, proved\" or \"No\")</p>\n<p>I understand that sometimes this proofs are results of oracles, but the aim<br>\nis to obtain more verbose proof.</p>\n<p>a) Did someone considered unfolding such short proof to something in<br>\nIsar-style? ( from ... have ... qed.)</p>\n<p>b) The other option is to obtain a term from proved theorem. How to do this?</p>\n<p>Let's use this example from Isabelle/ZF  (ZF-ex).</p>\n<p>\"<br>\ntext‹The singleton problems are much harder in HOL.›</p>\n<p>lemma singleton_example_1: \"∀x ∈ S. ∀y ∈ S. x ⊆ y    ⟹  ∃z. S ⊆ {z}\"<br>\nby blast<br>\n\"</p>\n<p>Sincerely Yours,<br>\nG. D.</p>",
        "id": 205986082,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596599486
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nDear Georgy</p>\n<p>Just to clarify one point: blast doesn’t use oracles and overall the significance of oracles in Isabelle proofs is small. I understand that for a beginner it could be interesting and instructive to see a blast proof broken into smaller parts, but (unfortunately) it’s rare for Isabelle’s automation to prove anything that isn’t obvious. Our problem really is that many obvious facts can only be proved with elaborate formal arguments that take much time and labour to construct.</p>\n<p>To take your example: if ∀x ∈ S. ∀y ∈ S. x ⊆ y then clearly all elements of S must equal one another, from which the conclusion ∃z. S ⊆ {z} obviously follows. I agree it is impressive that blast can prove this in a single step. </p>\n<p>Larry Paulson</p>",
        "id": 206006201,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596622231
    },
    {
        "content": "<p>From: Manuel Eberl &lt;<a href=\"mailto:eberlm@in.tum.de\">eberlm@in.tum.de</a>&gt;<br>\nTo add to what Larry said: unlike systems like Coq or Lean, Isabelle<br>\ndoes not allow you to look at ‘the proof’ that was constructed by<br>\ndefault. The reason for that is that Isabelle's design differs from<br>\nthose systems a lot. In Coq, proof terms fall out of the system<br>\nbasically for free anyway. In Isabelle, you can get something like this,<br>\nbut you have to do extra implementation work and invest extra CPU time<br>\nand memory to get it. So usually, it's not done at all.</p>\n<p>There /is/ an Isabelle feature called ‘proof terms’ that you can switch<br>\non and then you can look at the ‘proof’ (in some sense) that was found,<br>\neven if it was constructed by blast or auto. But this proof will usually<br>\nbe big, cluttered with ‘unnecessary’ steps, and completely unreadable<br>\nfor a human, much like e.g. SMT proofs that you can get from Z3. Because<br>\nproof terms are more of an afterthought in Isabelle, none of the<br>\nautomation even tries to produce small and beautiful proof terms.</p>\n<p>However, generally, Isabelle's automation does not perform magic. It<br>\nreally is surprisingly simple. It is a combination of a good library of<br>\nrewrite rules, simple general-purpose automation for classical<br>\nreasoning, some specialised decision procedures, and some specialised<br>\nrewriting procedures. Blast, for instance, is ‘just’ a Tableaux solver,<br>\nif I recall correctly.</p>\n<p>The situation is a bit different with provers like \"smt\" and \"metis\".<br>\nSledgehammer calls occasionally produce very puzzling one-line proofs<br>\nthat I find very hard to retrace by hand. Sledgehammer does have an<br>\n\"Isar proof generation\" feature that tries to produce more structured<br>\nproofs, but I never really got it to produce anything illuminating and<br>\noften it fails entirely. I have no idea how it works either.<br>\nSledgehammer, all in all, indeed feels a bit magical – unlike the more<br>\npedestrian methods like blast and auto.</p>\n<p>(@everone else: Please do correct me if I am wrong; I am not really an<br>\nexpert on this automation. Some of it is probably almost as old as I am<br>\nand my understanding of it is sometimes rather vague.)</p>\n<p>Cheers,</p>\n<p>Manuel</p>",
        "id": 206007716,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596623841
    },
    {
        "content": "<p>From: Georgy Dunaev &lt;<a href=\"mailto:georgedunaev@gmail.com\">georgedunaev@gmail.com</a>&gt;<br>\nThanks for the feedback!</p>\n<p>Indeed, it is more psychological/ philosophical effect.<br>\nI think, a fact is understood completely when it's proven.<br>\n(Maybe it's just an irrational fear of loosing control over proofs and a<br>\nfear of degrading right into a mindless trying of different tactics.)</p>\n<p>I didn't mean that that obvious proof should be separated into parts, I was<br>\njust curious about technical possibilities of reviving proofs. But, I<br>\nagree, the possible drawback is that proof may not be elegant or even not<br>\nhuman-readable, so it's complicated issue.</p>\n<p>Kind regards,<br>\nG. D.</p>",
        "id": 206008636,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596624841
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nAlso important to note: back around 1977, Robin Milner introduced the LCF architecture (with an abstract type of theorems defined within a strongly typed functional programming language, namely ML) with the specific aim of eliminating the need to store proofs. He had observed a simple fact: proofs take up too much memory. Since then, you may retort, memory capacity has increased by three or four orders of magnitude. But so have our proofs.</p>\n<p>Larry</p>",
        "id": 206008686,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596624862
    },
    {
        "content": "<p>From: Manuel Eberl &lt;<a href=\"mailto:eberlm@in.tum.de\">eberlm@in.tum.de</a>&gt;<br>\nIndeed they have!</p>\n<p>I wonder if the memory requirements of storing proof terms for<br>\neverything is a problem for systems that do this. I vaguely recall Leah<br>\nNeukirchen giving a talk about proofs by reflection in Coq and listed<br>\n\"saves memory because there are no proof terms associated with the<br>\ntheorem\" as an advantage – so that seems to indicate that proof term<br>\nsize can indeed cause performance problems in Coq.</p>\n<p>However, I think the performance situation in these systems is not quite<br>\nas bad as it is in Isabelle (with proof terms enabled) because they have<br>\ndefinitional equality and implicit normalisation, which Isabelle does<br>\nnot. In Isabelle, every rewrite step must be recorded explicitly.</p>\n<p>In any case, I have it on good authority that some people are planning<br>\nto improve proof terms in Isabelle, so let's see what comes out of that.<br>\nMario Carneiro seemed quite interested in them for the purpose of<br>\nimporting Isabelle proofs into other systems.</p>\n<p>Still, considering the fact that whenever our tools become more<br>\ncapable/performant, proof applications seem to scale up almost<br>\nimmediately until they are again at the very limit of what the system<br>\ncan do, it is probably a good thing that we can just \"switch off\" proof<br>\nterms if we have to.</p>\n<p>Manuel</p>",
        "id": 206011053,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596627045
    },
    {
        "content": "<p>From: Mario Carneiro &lt;<a href=\"mailto:di.gama@gmail.com\">di.gama@gmail.com</a>&gt;<br>\nMario Carneiro is watching this thread with great interest. :) I think that<br>\nthe fact that proof terms in isabelle are large is very correlated with the<br>\nfact that they are not stored. (A good comparison is the observation that<br>\nsoftware is still about as fast from the user perspective as it was 20<br>\nyears ago, even though the processor and memory capacity has increased by<br>\norders of magnitude over the period. We've just managed to fill the<br>\navailable capacity with more work and less efficient software, with the<br>\nreasoning that a human can't tell the difference between 10 milliseconds<br>\nand 3 nanoseconds.) I personally have no doubts that it is possible to<br>\nimprove on the current situation by several orders of magnitude, although I<br>\ndon't know how feasible they are given the current architecture and social<br>\ncontext. The general attitude that proof terms \"don't matter\" is terribly<br>\ndestructive to attempts to work on improving their efficiency, though. They<br>\nenable all manner of proof export, cross linking of libraries, and external<br>\nchecking. I don't plan to settle for less than the entire standard<br>\nlibrary + AFP, but as I understand it this is completely out of the range<br>\nof feasibility of the current proof term mode, because too much processing<br>\nis spent putting things into lambda calculus rather than just logging<br>\nkernel calls.</p>\n<p>To give some sense of what I think is possible, I have managed to enable<br>\nproof export for the cadical SAT solver such that the runtime is not much<br>\naffected (+0-10%), and the resulting proof checking time is also<br>\nnegligible. Disk space can be a problem for large automated proofs,<br>\nassuming you aren't doing any proof processing, but it is easier to make a<br>\ntradeoff of disk space for more implicit data starting from a fully<br>\nelaborated proof baseline, plus disk space is relatively cheap so I'm not<br>\noverly concerned about this. Of course it would be better if the proofs<br>\nwere actually optimized, but I'll take what I can get.</p>\n<p>Mario</p>",
        "id": 206013512,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596628763
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nThis observation may be true for Microsoft Word, but it is certainly not true for Isabelle. I don’t have the precise numbers at my fingertips but I recall for example that the MicroJava session took about 45 minutes to run in the late 1990s. And here it is today:</p>\n<p>Finished HOL-MicroJava (0:01:10 elapsed time, 0:05:44 cpu time, factor 4.90)</p>\n<p>That is an improvement of nearly 2 orders of magnitude, partly achieved through parallelism (by a factor of almost 5).</p>\n<p>Larry</p>",
        "id": 206015020,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596629765
    },
    {
        "content": "<p>From: Mario Carneiro &lt;<a href=\"mailto:di.gama@gmail.com\">di.gama@gmail.com</a>&gt;<br>\nIf you look at the same program over time, it will appear to get faster<br>\nbecause the hardware is changing and the software isn't. Similarly here, if<br>\nyou look at the MicroJava session over time it has improved. But I would<br>\nbet there are other sessions that exist now that also take 45 minutes,<br>\nperhaps even more. They just use different proof methods and prove<br>\ndifferent things. In one sense this is certainly a gain - we can now use<br>\nmethods that would not be practical in the past, and tackle much bigger<br>\nproblems now than before. But it is this exact fact that means that<br>\ncomputer systems will always live at human timescales, because we don't<br>\noptimize past the point that we can notice the difference, and we don't<br>\nattempt to run programs that take too long (depending on the context that<br>\nupper bound might be 1 second or 30 seconds for an editor action, several<br>\nminutes for a theory compiled on the spot, and hours to weeks for a full<br>\ndevelopment).</p>",
        "id": 206015764,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596630381
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nIt is a common view that improvements in software performance have come for free from hardware improvements alone. But in the case of Isabelle a simple calculation shows that this is no explanation. A processor in the late 1990s might have a clock speed of 400 MHz. Simply multiplying by today’s speedup factor of 40 would suggest that today we have a 16 GHz processor, so obviously something else is going on. In the case of Isabelle it’s the huge investment in parallelism.</p>\n<p>I was curious to see how many really big problems there are in the AFP. It turns out that there are only six (out of 547) in the “slow” category. The slowest of these (Iptables_Semantics) has a time limit of 17 hours. It’s a far cry from the era in which running jobs overnight was a regular necessity.</p>\n<p>Given the major role of proof objects in Coq, we can be sure that they are optimised to the maximum extent. Yet it’s clear that Coq users try to avoid creating proof objects altogether. Formalisations minimise the role of proof objects by working as much as possible with primitive recursive functions (which are evaluated within the kernel and don’t create proof objects).</p>\n<p>Larry Paulson</p>",
        "id": 206028725,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596637820
    },
    {
        "content": "<p>From: Manuel Eberl &lt;<a href=\"mailto:eberlm@in.tum.de\">eberlm@in.tum.de</a>&gt;<br>\nIt should be mentioned that the slow iptables session, as far as I<br>\nunderstand, is an application of generated code (a piece of software<br>\nthat was verified in Isabelle/HOL) to a really big example application,<br>\nand that is the only thing that is slow about it. Not the actual proofs.</p>\n<p>For Flyspeck, it is somewhat similar. I think this is some kind of<br>\nexhaustive search procedure that is proven correct and then the<br>\ngenerated code is executed, and that is what is so slow about it.</p>\n<p>Neither of these actually involve Isabelle itself in the slow bits.</p>\n<p>I don't know about the other ones, but I think those might actually be<br>\nactual Isabelle proofs that are a bit slow.</p>\n<p>Of the four others, two take about 30 minutes and two take about 60<br>\nminutes, with 8 threads each. That's not so bad. Bicategories and<br>\nJinjaThreads are probably slow because they are just huge (in terms of<br>\nlines of code). With ConcurrentGC and AODV I don't really know why they<br>\nare so slow. Perhaps they use an exorbitant amount of automated case<br>\ndistinctions?</p>\n<p>Manuel</p>",
        "id": 206034796,
        "sender_full_name": "Email Gateway",
        "timestamp": 1596640557
    },
    {
        "content": "<p>From: Wolfgang Jeltsch &lt;<a href=\"mailto:wolfgang-it@jeltsch.info\">wolfgang-it@jeltsch.info</a>&gt;<br>\nJust to be sure: Something like a proof object is nevertheless created<br>\nwhen a proof method is invoked, right? My understanding was that<br>\nfollowing the LCF approach means that Isabelle will never trust methods<br>\nlike <code>blast</code> to produce correct results but always require them to<br>\nprovide proof objects that are then checked by a minimal trusted kernel<br>\nfor correctness. Is this the case, or did I misunderstand something?</p>\n<p>All the best,<br>\nWolfgang</p>",
        "id": 207785798,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598208038
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nNo proof objects are created. Soundness is enforced through the abstract type discipline.</p>\n<p>Here is an analogy: imagine a programming project that requires a dictionary datatype. Somebody implements the dictionary￼￼ using red-black trees, hash tables or whatever, and provides an interface with abstract operations such as the empty dictionary, insert, lookup, update, delete. Those operations are the only means available to work with dictionaries outside the data structure definition itself, and in that way the integrity of the internal representation is protected￼. Provided that the code implementing the representation is correct, and assuming of course a type-safe programming language, all dictionary operations are guaranteed to deliver the correct results regardless of how many errors there may be in other parts of the program.</p>\n<p>Maintaining a separate audit trail for each dictionary would provide a means of checking the dictionary operations at runtime (in particular to verify that lookup delivers correct results), but it's unnecessary and would cause the program to quickly run out of memory.</p>\n<p>Proof objects are precisely such audit trails. That they are unnecessary (and indeed unaffordable) was Robin Milner's insight, around 1975. It is noteworthy that in proof assistants such as Coq that represent propositions by types, great efforts are made to use Bool or Prop rather than Type in order to keep proof objects to a minimum.</p>\n<p>Larry</p>",
        "id": 207819334,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598258391
    },
    {
        "content": "<p>From: Wolfgang Jeltsch &lt;<a href=\"mailto:wolfgang-it@jeltsch.info\">wolfgang-it@jeltsch.info</a>&gt;<br>\nThanks a lot for your explanation.</p>\n<p>I don’t want to claim that I fully understand Isabelle’s technique<br>\nalready, but I hope I got the essence of it.</p>\n<p>My understanding is as follows: You could let proof methods build proof<br>\nobjects whose correctness you check afterwards. Proof objects would be<br>\nof some algebraic data type, and you would use the data constructors of<br>\nthis type to build proof objects. To get to the Isabelle style, you<br>\nessentially replace these data constructors by operations of an abstract<br>\ndata type whose values correspond to proofs. The properties of the<br>\nabstract data type ensure that it is impossible for you to construct<br>\nincorrect proofs. Is that roughly how it works?</p>\n<p>In any case, it’s reassuring that in Isabelle there is indeed only this<br>\nsmall kernel you have to trust.</p>\n<p>All the best,<br>\nWolfgang</p>",
        "id": 207839356,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598273876
    },
    {
        "content": "<p>From: Freek Wiedijk &lt;<a href=\"mailto:freek@cs.ru.nl\">freek@cs.ru.nl</a>&gt;<br>\nDear all,</p>\n<p>Larry wrote:</p>\n<blockquote>\n<p>No proof objects are created. Soundness is enforced<br>\nthrough the abstract type discipline.</p>\n</blockquote>\n<p>Henk Barendregt calls what is implemented in the HOL family<br>\nof systems _ephemeral_ proof objects.  His image is of<br>\nsomeone writing a proof with a stick in the sand at the sea,<br>\nand the sea washing away the writing all the time.  At the<br>\nend the full proof has been written but nothing remains.</p>\n<p>Freek</p>",
        "id": 207839946,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598274252
    },
    {
        "content": "<p>From: Wolfgang Jeltsch &lt;<a href=\"mailto:wolfgang-it@jeltsch.info\">wolfgang-it@jeltsch.info</a>&gt;<br>\nInteresting analogy!</p>\n<p>From what I understand, the invocations of the functions you use for<br>\nconstructing a new fact collectively form a proof of this fact, but no<br>\nactual data resembling the proof is ever constructed by these functions.</p>\n<p>All the best,<br>\nWolfgang</p>",
        "id": 207840424,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598274520
    },
    {
        "content": "<p>From: Freek Wiedijk &lt;<a href=\"mailto:freek@cs.ru.nl\">freek@cs.ru.nl</a>&gt;<br>\nDear Wolfgang,</p>\n<p>In most systems (at least in Isabelle and HOL Light) there<br>\nis a switch that you can turn on/off to allow you to store<br>\nthe proof object in memory, but in normal operation this<br>\nswitch is always off.</p>\n<p>Freek</p>",
        "id": 207841785,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598275211
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;</p>\n<blockquote>\n<p>On 24 Aug 2020, at 14:03, Freek Wiedijk &lt;<a href=\"mailto:freek@cs.ru.nl\">freek@cs.ru.nl</a>&gt; wrote:</p>\n<p>Henk Barendregt calls what is implemented in the HOL family<br>\nof systems _ephemeral_ proof objects.  His image is of<br>\nsomeone writing a proof with a stick in the sand at the sea,<br>\nand the sea washing away the writing all the time.  At the<br>\nend the full proof has been written but nothing remains.</p>\n</blockquote>\n<p>That image is evocative but doesn’t indicate how you prevent the “someone” from writing a faulty proof. Here is Milner himself:</p>\n<blockquote>\n<p>we’re not so concerned with checking or generating proofs as with performing proofs. Thus, we don’t normally store or display proofs but only the results of them - i.e. theorems. These form an abstract type on which the only allowed operations are the inference rules …; this ensures that a well-typed program cannot perform faulty proofs (it may not prove the theorem expected but the result will be a theorem!). If extra security or formal proof-checking is desired, full proofs are easily generated -- only minor changes in the implementation of the abstract type for theorems would be required. The principal aims then in designing ML were to make it impossible to prove non-theorems yet easy to program strategies for performing proofs.</p>\n</blockquote>\n<p>Gordon, Milner, Morris, Newey, and Wadsworth<br>\nA Metalanguage for interactive proof in LCF<br>\nPOPL '78: Proceedings of the 5th ACM SIGACT-SIGPLAN symposium on Principles of programming languages<br>\nJanuary 1978 Pages 119–130<br>\n<a href=\"https://doi.org/10.1145/512760.512773\">https://doi.org/10.1145/512760.512773</a><br>\n<a href=\"http://www-public.imtbs-tsp.eu/~gibson/Teaching/CSC4504/ReadingMaterial/GordonMMNW78.pdf\">http://www-public.imtbs-tsp.eu/~gibson/Teaching/CSC4504/ReadingMaterial/GordonMMNW78.pdf</a></p>",
        "id": 207842141,
        "sender_full_name": "Email Gateway",
        "timestamp": 1598275422
    }
]