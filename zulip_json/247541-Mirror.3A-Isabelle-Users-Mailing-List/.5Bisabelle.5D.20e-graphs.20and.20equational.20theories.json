[
    {
        "content": "<p>From: Patrick Nicodemus &lt;<a href=\"mailto:gadget142@gmail.com\">gadget142@gmail.com</a>&gt;<br>\nThe Nelson-Oppen congruence closure paper gives a decision algorithm for<br>\nthe theory of LISP lists. You can generalize this to other universal<br>\nalgebra theories: to decide equality between two terms over an equational<br>\ntheory, \\forall x1...xn, t1 = t2. One starts by adding ground equations<br>\nwhenever one side of an equation unifies with a subterm of the goal, adding<br>\nthese as equivalence constraints, and taking the congruence closure. Then<br>\none repeats the procedure, trying to unify one side of the universally<br>\nquantified theorems with a subterm of the new set of subterms (or sub-node<br>\nin the e-graph). If you are lucky then this process eventually hits a<br>\nfixpoint in the sense that every rewrite of an e-node in the graph yields<br>\nanother e-node already in the graph, for such theories this gives a nice<br>\ndecision procedure.</p>\n<p>I'm interested in some sufficient conditions on the theory such that for<br>\nevery term t, the e-graph built by repeatedly rewriting subterms in t<br>\naccording to axioms in t eventually stabilizes. For example the theory<br>\n\\forall x. x = f(x), after the first time I apply this to a term t, I have<br>\na new term f(t) in my graph, but t ~ f(t) so I don't get any new<br>\nequivalence classes in the term graph. What references should I look at for<br>\nconditions on the theory that guarantee this stabilizes?</p>",
        "id": 541087061,
        "sender_full_name": "Email Gateway",
        "timestamp": 1758656520
    }
]