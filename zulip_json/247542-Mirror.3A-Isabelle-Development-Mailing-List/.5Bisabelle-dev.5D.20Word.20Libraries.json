[
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nDear power users of the bit and word libraries,</p>\n<p>I have finished polishing the bit and word material as envisaged before<br>\nthe next Isabelle release.</p>\n<p>The changes are by no means as invasive as for the last Isabelle<br>\nrelease, but you might check your existing applications against before<br>\nthe upcoming release – there is still time for corrections and improvements.</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/ryWwE1yJlhyriT8piPcN2uAL/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 248995045,
        "sender_full_name": "Email Gateway",
        "timestamp": 1628609671
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;</p>\n<blockquote>\n<p>On 11 Aug 2021, at 01:34, Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt; wrote:</p>\n<p>Dear power users of the bit and word libraries,</p>\n<p>I have finished polishing the bit and word material as envisaged before<br>\nthe next Isabelle release.</p>\n</blockquote>\n<p>This sounds good, but I don't quite remember any more what exactly that was, can you give a summary?</p>\n<blockquote>\n<p>The changes are by no means as invasive as for the last Isabelle<br>\nrelease, but you might check your existing applications against before<br>\nthe upcoming release – there is still time for corrections and improvements.</p>\n</blockquote>\n<p>As you know, it's a bit of work to check that for l4v, esp since it is still on Isabelle2020 (no real issues, mostly organisational upheavals have taken up all available attention). It will take a while, but it looks like it will break in the usually hopefully small ways.</p>\n<p>Do you have a list of changes that users will likely ned to apply?</p>\n<p>Cheers,<br>\nGerwin<br>\n<a href=\"/user_uploads/14278/j4r38KOXhFJRPUA33uNc3Psm/signature.asc\">signature.asc</a></p>",
        "id": 249047856,
        "sender_full_name": "Email Gateway",
        "timestamp": 1628635544
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Gerwin,</p>\n<blockquote>\n<p>This sounds good, but I don't quite remember any more what exactly that was, can you give a summary?</p>\n<p>As you know, it's a bit of work to check that for l4v, esp since it is still on Isabelle2020 (no real issues, mostly organisational upheavals have taken up all available attention). It will take a while, but it looks like it will break in the usually hopefully small ways.</p>\n<p>Do you have a list of changes that users will likely ned to apply?</p>\n</blockquote>\n<p>it’s in the NEWS</p>\n<blockquote>\n<ul>\n<li>\n<p>Infix syntax for bit operations AND, OR, XOR is now organized in<br>\nbundle bit_operations_syntax. INCOMPATIBILITY.</p>\n</li>\n<li>\n<p>Bit operations set_bit, unset_bit and flip_bit are now class<br>\noperations. INCOMPATIBILITY.</p>\n</li>\n<li>\n<p>Theory Bit_Operations is now part of HOL-Main. Minor INCOMPATIBILITY.</p>\n</li>\n<li>\n<p>Simplified class hierarchy for bit operations: bit operations reside<br>\nin classes (semi)ring_bit_operations, class semiring_bit_shifts is<br>\ngone.</p>\n</li>\n<li>\n<p>Abbreviation \"max_word\" has been moved to session Word_Lib in the AFP,<br>\nas also have constants \"shiftl1\", \"shiftr1\", \"sshiftr1\", \"bshiftr1\",<br>\n\"setBit\", \"clearBit\". See there further the changelog in theory Guide.<br>\nINCOMPATIBILITY.</p>\n</li>\n</ul>\n</blockquote>\n<p>and as a separate section in the »Guide« in session Word_Lib:</p>\n<blockquote>\n<p>➧[Changes since AFP 2021] ~</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Theory \\&lt;^theory&gt;‹Word_Lib.Ancient_Numeral› is no part of \\&lt;^theory&gt;‹Word_Lib.Word_Lib_Sumo›<br>\n      any longer.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Infix syntax for \\&lt;^term&gt;‹(AND)›, \\&lt;^term&gt;‹(OR)›, \\&lt;^term&gt;‹(XOR)› organized in<br>\n      syntax bundle \\&lt;^bundle&gt;‹bit_operations_syntax›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Abbreviation \\&lt;^abbrev&gt;‹max_word› moved from distribution into theory<br>\n      \\&lt;^theory&gt;‹Word_Lib.Legacy_Aliases›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Operation \\&lt;^const&gt;‹test_bit› replaced by input abbreviation \\&lt;^abbrev&gt;‹test_bit›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Operation \\&lt;^const&gt;‹shiftl› replaced by abbreviation \\&lt;^abbrev&gt;‹shiftl›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Operation \\&lt;^const&gt;‹shiftr› replaced by abbreviation \\&lt;^abbrev&gt;‹shiftr›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Operation \\&lt;^const&gt;‹sshiftr› replaced by abbreviation \\&lt;^abbrev&gt;‹sshiftr›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Abbreviations \\&lt;^abbrev&gt;‹bin_nth›, \\&lt;^abbrev&gt;‹bin_last›, \\&lt;^abbrev&gt;‹bin_rest›,<br>\n      \\&lt;^abbrev&gt;‹bintrunc›, \\&lt;^abbrev&gt;‹sbintrunc›, \\&lt;^abbrev&gt;‹norm_sint›,<br>\n      \\&lt;^abbrev&gt;‹bin_cat› moved into theory \\&lt;^theory&gt;‹Word_Lib.Legacy_Aliases›.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Operations \\&lt;^abbrev&gt;‹shiftl1›, \\&lt;^abbrev&gt;‹shiftr1›, \\&lt;^abbrev&gt;‹sshiftr1›, \\&lt;^abbrev&gt;‹bshiftr1›,<br>\n      \\&lt;^abbrev&gt;‹setBit›, \\&lt;^abbrev&gt;‹clearBit› moved from distribution into theory<br>\n      \\&lt;^theory&gt;‹Word_Lib.Legacy_Aliases› and replaced by input abbreviations.</p>\n<p><span aria-label=\"black small square\" class=\"emoji emoji-25aa\" role=\"img\" title=\"black small square\">:black_small_square:</span> Operation \\&lt;^const&gt;‹complement› replaced by input abbreviation \\&lt;^abbrev&gt;‹complement›.</p>\n</blockquote>\n<p>Hope this helps,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/ICrO34vig7RXpmIx6JD07ICA/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 249204723,
        "sender_full_name": "Email Gateway",
        "timestamp": 1628753100
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nSide-remark: 2021 is a year of 2 Isabelle releases. So maybe you manage to<br>\ncatch up for Isabelle2021-1 (December 2021). The release process will start<br>\napprox. 01-Nov-2021 and finish 15-Dec-2021.</p>\n<p>Makarius</p>\n<hr>\n<p>isabelle-dev mailing list<br>\n<a href=\"mailto:isabelle-dev@in.tum.de\">isabelle-dev@in.tum.de</a><br>\n<a href=\"https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev\">https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev</a></p>",
        "id": 249215650,
        "sender_full_name": "Email Gateway",
        "timestamp": 1628762192
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nIs this failure a consequence of it? (Seen in current Isabelle/0f051404f487 +<br>\nAFP/bd6c4c7c76ec)</p>\n<p>Native_Word FAILED<br>\n(see also<br>\n/Users/wenzelm/.isabelle/heaps/polyml-5.8.2_x86_64_32-darwin/log/Native_Word)<br>\n*** Type unification failed: Clash of types \"_ ⇒ _\" and \"uint64\"</p>\n<hr>\n<p>*** Type error in application: operator not of function type</p>\n<hr>\n<p>*** Operator:  x :: uint64<br>\n*** Operand:   AND :: ??'a</p>\n<hr>\n<p>*** At command \"lemma\" (line 25 of \"$AFP/Native_Word/Native_Word_Test_GHC.thy\")<br>\n*** At command \"test_code\" (line 13 of<br>\n\"$AFP/Native_Word/Native_Word_Test_GHC.thy\")<br>\n*** Type unification failed: Clash of types \"_ ⇒ _\" and \"uint64\"</p>\n<hr>\n<p>*** Type error in application: operator not of function type</p>\n<hr>\n<p>*** Operator:  x :: uint64<br>\n*** Operand:   AND :: ??'a</p>\n<hr>\n<p>*** At command \"lemma\" (line 25 of \"$AFP/Native_Word/Native_Word_Test_GHC.thy\")<br>\nUnfinished session(s): Native_Word</p>\n<p>Makarius</p>\n<hr>\n<p>isabelle-dev mailing list<br>\n<a href=\"mailto:isabelle-dev@in.tum.de\">isabelle-dev@in.tum.de</a><br>\n<a href=\"https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev\">https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev</a></p>",
        "id": 249228752,
        "sender_full_name": "Email Gateway",
        "timestamp": 1628771899
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOK. It looks fine.</p>\n<p>Makarius</p>\n<hr>\n<p>isabelle-dev mailing list<br>\n<a href=\"mailto:isabelle-dev@in.tum.de\">isabelle-dev@in.tum.de</a><br>\n<a href=\"https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev\">https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev</a></p>",
        "id": 249280635,
        "sender_full_name": "Email Gateway",
        "timestamp": 1628796120
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;<br>\nHaving finally managed to get some time to look over the changes to Word_Lib, I have strong concerns about this development and how it was made.</p>\n<p>We only finished updating to Isabelle2021 a week ago -- it was major amount of work, mostly due to Word_Lib change, but I could see the value of the generalisations of the last round.</p>\n<p>I do not see the value in most of these current changes. They have neither been articulated, nor are they obvious to me. In fact, to my mind the opposite is true for several of the changes.</p>\n<p>For instance, who on earth wants to read something like \"is_aligned (push_bit m k) m\" instead of \"is_aligned (k &lt;&lt; m) m\"? It is entirely unacceptable to make such a change in an AFP library without even consulting the original authors. I would never write this. Please revert it. The syntax was introduced for good reasons. It is fine to make it a bundle to not pollute a global syntax space, it is not fine to change original material that was written with a purpose.</p>\n<p>It is <em>absolutely</em> not fine to produce commits like \"dropped junk\" which removes a theory that was critical to how this library is used after in previous commits having made it unusable, entirely missing the point of its existence. Please revert that entire series of commits and reproduce the old setup.</p>\n<p>Further, a whole lot of constants have been moved around. Why? What does this improve? This can cause major amounts of renaming work for no gain to anyone. Please either produce a convincing argument for the benefit of these moves or revert them.</p>\n<p>Changing definitions such as shiftl1 to input abbreviations is likely to cause major breakage because term structure changes significantly. Again, what rationale has been considered, what cost/benefit analysis led to this decision? I strongly prefer definitions for these concepts. Please articulate these <em>before</em> you make such changes, and either convince the authors of the benefits or revert the change.</p>\n<p>It is not acceptable to make such sweeping changes to other people's work without getting the author's consent first. As you very well know 90% of the use of this library is outside the AFP, and Word_Lib is the interface to that work, as well as an ingredient of a number of automated tools. </p>\n<p>Gerwin</p>\n<hr>\n<p>isabelle-dev mailing list<br>\n<a href=\"mailto:isabelle-dev@in.tum.de\">isabelle-dev@in.tum.de</a><br>\n<a href=\"https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev\">https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev</a></p>",
        "id": 256175855,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633408144
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Gerwin and all reading this thread,</p>\n<p>I went through the repositories’ history and my memory to recap what<br>\nhappened here in the post-Isabelle2020 and post-Isabelle2021 time.</p>\n<p>Overall, the changes at a glance are guided by the following aims,<br>\nquoted from the write-up at<br>\n&lt;<a href=\"https://isabelle.in.tum.de/~haftmann/bits_and_word/\">https://isabelle.in.tum.de/~haftmann/bits_and_word/</a>&gt;:</p>\n<ul>\n<li>\n<p>Theory Word contains the word type and its operations proper, located<br>\nin session HOL-Library.</p>\n</li>\n<li>\n<p>Additional material of somehow unclear status in relevance is<br>\nmodularized into separate theories and moved to session Word_Lib in the AFP.</p>\n</li>\n<li>\n<p>The historically grown Word_Lib is minimally structured and augmented<br>\nwith a guide.</p>\n</li>\n<li>\n<p>The ultimate goal is that future development can happen mostly in the AFP.</p>\n</li>\n</ul>\n<p>Some of that work has already happened before Isabelle2021; what<br>\nhappened for Isabelle2021-1 as far as I can see from the history:</p>\n<ul>\n<li>\n<p>Some disentanglement of theory dependencies to enable users to use the<br>\nlibrary more selectively (»Word_Lib is minimally structured«) – this<br>\naffects genuine Word_Lib material .</p>\n</li>\n<li>\n<p>Movement of material from the distribution / HOL-Library.Word to<br>\nWord_Lib (»moved to session Word_Lib in the AFP«)</p>\n</li>\n<li>\n<p>Restructuring of that (originally non-Word_Lib (!)) material<br>\n(»modularized into separate theories«).</p>\n</li>\n</ul>\n<p>(I emphasize here that most of the changes seen in the AFP actually<br>\noriginate from the Bit/Word material in the distribution, where the<br>\ncumulative reworking over two releases gives me kind of responsibility<br>\nand »legitimacy« for proactive developments. Coming back to the original<br>\naims: »The ultimate goal is that future development can happen mostly in<br>\nthe AFP.« Ie. without subtle and hard to maintain dependencies between<br>\nAFP and distribution. Note also that the changes towards Isabelle2021<br>\nare far more massive than those afterwards.)</p>\n<p>If these intentions and measures <em>by itself</em> infringe your authorship or<br>\nthe intended purpose or usability of Word_Lib, this is a fundamental<br>\nissue and we should make a stop here and find a way to work that out in<br>\nparticular.</p>\n<p>Otherwise I would appreciate to get to the particular problems with the<br>\ncurrent matter of affairs. I thankfully accept any hints on slips,<br>\nomissions, misperceptions, doubtful quality, theory and tool break-downs<br>\nboth in the visible and the non-visible universe – be it due to changes<br>\nor not. In that manner both authors and non-authors of Word_Lib in<br>\nprivate conversation have already given feedback and also contributions.</p>\n<p>Generally: If there are any repositories I should have a look at for<br>\nsome kind of assessment, please let me know. Also if there is particular<br>\nexperience of the migration to Isabelle2021 I should take into<br>\nconsideration.</p>\n<blockquote>\n<p>For instance, who on earth wants to read something like \"is_aligned (push_bit m k) m\" instead of \"is_aligned (k &lt;&lt; m) m\"? . The syntax was introduced for good reasons. It is fine to make it a bundle to not pollute a global syntax space, it is not fine to change original material that was written with a purpose.</p>\n</blockquote>\n<p>If your point is to to apply the ‹_ &lt;&lt; _› syntax etc. thoroughly and<br>\nconsistently among Word_Lib theories, I am happy to look after these slips.</p>\n<blockquote>\n<p>It is <em>absolutely</em> not fine to produce commits like \"dropped junk\" which removes a theory that was critical to how this library is used after in previous commits having made it unusable, entirely missing the point of its existence. Please revert that entire series of commits and reproduce the old setup.</p>\n</blockquote>\n<p>After a second study of history I notice that I messed this up already<br>\nin the AFP release for Isabelle2021; the change after that point of<br>\nreference was indeed just a cleanup of dead theories. Looks I should<br>\njust revert to pre-Isabelle2021 there?</p>\n<blockquote>\n<p>Further, a whole lot of constants have been moved around. Why? What does this improve? This can cause major amounts of renaming work for no gain to anyone. Please either produce a convincing argument for the benefit of these moves or revert them</p>\n</blockquote>\n<p>These moves AFAICS originate from the distribution (see above), where<br>\nthe elimination of the ancient HOL-Word session for Isabelle2021 already<br>\nhad massive impact on internal names for operations. Is your concern<br>\nabout renaming work just abstract or based on concrete observations? I<br>\nam asking since if any tool survived the Isabelle2021 movements, there<br>\nis little reason to assume that it won’t survive the current state of<br>\naffairs – Isabelle is far more robust against such things as, say, 15<br>\nyears ago.</p>\n<blockquote>\n<p>Changing definitions such as shiftl1 to input abbreviations is likely to cause major breakage because term structure changes significantly.</p>\n</blockquote>\n<p>The shift*1 Operations have been auxiliary definitions in the<br>\ndistribution to bootstrap the bit shifts operations, similarly to<br>\niszero, equipped only with a minimal set of lemmas. If one tool out<br>\nthere relies on it as explicit constant i. e. due to pattern matching, I<br>\nwon’t shed a tear to keep it as constant.</p>\n<p>(Aside, the primitive definitions then would be maybe: shiftl1 a = (a &lt;&lt;<br>\n1), shiftr1 a = (a &gt;&gt; 1), sshiftr1 a = (a &gt;&gt;&gt; 1)).</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/jxsa2g3n2u23yE4mu3lHenvU/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 256402445,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633523501
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;</p>\n<blockquote>\n<p>On 6 Oct 2021, at 23:30, Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt; wrote:</p>\n<ul>\n<li>\n<p>Theory Word contains the word type and its operations proper, located<br>\nin session HOL-Library.</p>\n</li>\n<li>\n<p>Additional material of somehow unclear status in relevance is<br>\nmodularized into separate theories and moved to session Word_Lib in the AFP.</p>\n</li>\n<li>\n<p>The historically grown Word_Lib is minimally structured and augmented<br>\nwith a guide.</p>\n</li>\n<li>\n<p>The ultimate goal is that future development can happen mostly in the AFP.</p>\n</li>\n</ul>\n</blockquote>\n<p>So far that is as we discussed back then and I continue to agree with it. The problems are in the details.</p>\n<blockquote>\n<ul>\n<li>\n<p>Some disentanglement of theory dependencies to enable users to use the<br>\nlibrary more selectively (»Word_Lib is minimally structured«) – this<br>\naffects genuine Word_Lib material .</p>\n</li>\n<li>\n<p>Movement of material from the distribution / HOL-Library.Word to<br>\nWord_Lib (»moved to session Word_Lib in the AFP«)</p>\n</li>\n<li>\n<p>Restructuring of that (originally non-Word_Lib (!)) material<br>\n(»modularized into separate theories«).</p>\n</li>\n</ul>\n<p>(I emphasize here that most of the changes seen in the AFP actually<br>\noriginate from the Bit/Word material in the distribution, where the<br>\ncumulative reworking over two releases gives me kind of responsibility<br>\nand »legitimacy« for proactive developments. Coming back to the original<br>\naims: »The ultimate goal is that future development can happen mostly in<br>\nthe AFP.« Ie. without subtle and hard to maintain dependencies between<br>\nAFP and distribution. Note also that the changes towards Isabelle2021<br>\nare far more massive than those afterwards.)</p>\n</blockquote>\n<p>This is the thing: I don't object to the massive changes for Isabelle2021, at least not the ones we discussed and looked at together. I saw (and still see) the value in the reorganisation and generalisation you did there. The problem are the subsequent \"cleanup\" etc commits, which to me did not actually clean much up but have managed to leave Word_Lib unusable (it'll be fine with the changes I wanted). If we had gone through the same cycle of discussion beforehand I could have pointed these out very easily.</p>\n<p>I can see where our misunderstand originated and I'll get over my annoyance. I'm glad I had the time now to look at it before we have to freeze this for the release.</p>\n<blockquote>\n<p>Generally: If there are any repositories I should have a look at for<br>\nsome kind of assessment, please let me know. Also if there is particular<br>\nexperience of the migration to Isabelle2021 I should take into<br>\nconsideration.</p>\n</blockquote>\n<p>There is some relevant experience from Isabelle2021. As a rough order of magnitude, it took about 2 full person months to do the complete proof update for l4v, which finished a bit more than a week ago now. 2 person months is about 1 person month higher than a usual Isabelle update. Not quite all, but most of the changes were due to Word_Lib.</p>\n<p>You did an initial foray into this proof update for one architecture (ARM, 32 bit) after the first half of the Isabelle2021 changes. The result of that foray was that those changes were relatively benign, which is why I was surprised by the much higher effort later. I think the main fallout was from a few small changes in the second half of the Isabelle2021 update. What is relevant for the next update are these:</p>\n<ul>\n<li>\n<p>things started breaking immediately for 64-bit architectures, because the Sumo concept alone does not quite work. It is not enough to make all lemmas for all word lengths available. The point of the Word_SetupXX theories is to additionally establish a set of common names that refer to the default word type of the program (basically, whatever \"unsigned int\" is in C for that architecture, and what the register width is for the machine). Having these names common means that the same proof text can work on different concrete types. This is different to actually generic lemmas that work for any word length or that need to resolve preconditions on the word length before they can be applied (the latter can be solved in theories like Word8 etc). It is not the prettiest form of genericity, but it is crucial for not having to duplicate thousands of lemmas that for other reasons do need to refer to a concrete word length (which is known in the proof state, but unknown to the proof text). Ultimately this is comes from C, which as painful as it is, works on exactly that principle that the same type name can refer to different representations, depending on architecture.</p>\n</li>\n<li>\n<p>the default simpset setup changed, it no longer reliably normalises ground terms with numerals. This caused a bunch of proof changes, hunting for which rules are needed etc. My reading of NEWS it that this is getting worse with NOT terms not being normalised any more. This potentially makes sense for int/nat, but I would suggest to keep them for Word (and to make sure the rest of the numeral simplification actually covers all cases -- usually 0, 1, Suc 0 are the corner cases to look out for).</p>\n</li>\n<li>\n<p>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</p>\n</li>\n<li>\n<p>punning max_word with -1 conflicts with normalising numerals to the interval [0; 2^len). There were a few test lemmas in the repository that made sure this was not accidentally removed, I'm not sure where these went. Removing normalisation for -1 in turn leads to terms like unat(-1) which proofs then get stuck on. This can be fixed locally by finding the right rule to re-establish the old normalisation, but that will of course mean that abstract lemmas that refer to -1 won't apply any more. This means there is no principled way to deal with ground terms any more. I can see the appeal of using -1 for generic lemmas, because it has nice algebraic meaning (as opposed to max_word). Maybe the solution is to build a rule set for arithmetic that can be added on demand or as a bundle. It's a bit of a crutch, but at least it would provide a choice.</p>\n</li>\n<li>\n<p>the new simpset often loops in the l4v proofs, because it either reversed polarity or added additional rules about ucast/unat. Some of this was fall-out from the more general treatment (e.g. unsigned)</p>\n</li>\n<li>\n<p>not all new looping is due to that specific problem. I haven't been able to track down what rules exactly are the problem, but adding field_simps now almost always loops in word proofs. This might be a symptom of a different problem (i.e. not related to Word_Lib), because the usual fix was to instantiate specific commutativity rules. This indicates that something doesn't quite work any more with ordered rewriting. Possibly there is now an additional rewriting step or something like that so that the simple test in <code>simp</code> no longer suffices.</p>\n</li>\n<li>\n<p>related to simp rules for \"unsigned\", there are many (hundreds) of instances where casts or unat now leave terms of the form \"take_bit 32 ..\" in the goal which have little chance of making progress. This was such frequent cause of breakage that we introduced a bundle which removes the rules producing take_bit terms. Trying to remove them globally is hopeless, because any theory merge with a theory that still has them, will re-introduce them.</p>\n</li>\n<li>\n<p>similarly, there is a rule that automatically rewrites \"x = 0\" to something in the direction of \"x dvd 2^len\". This is rarely useful with concrete len, and preventing these terms from being produced is similarly manual as take_bit.</p>\n</li>\n<li>\n<p>the unat_arith tactic solves fewer goals. I might be mistaken, but I think this is mostly due to simpset changes, but I have not had the time to track down which exactly.</p>\n</li>\n</ul>\n<p>Overall, it looks like a number of aspects of the new simpset are convenient for reasoning abstractly about machine words when you are working within the library (esp take_bit and 0/dvd), but counterproductive once you are working with specific word lengths as you do in program verification.</p>\n<p>I think it would make sense to attempt to tune the simpset such that both scenarios (concrete and abstract) are available separately as bundles, making the global default conservative.</p>\n<p>The problem is that the old setup was fairly well tuned and recreating it will not be easy, but at least removing some of the global rules that only work well for the abstract setup would help, because adding simp rules later is easy, but removing them is annoying.</p>\n<p>There is a separate question of what a good setup is for the interplay between casts to different types and what good normal forms for these are. We had settled on never unfolding ucast/unat/uint etc automatically, instead producing abstract rules that describe the interaction with the usual operators and relationships between each other. I still think that is a reasonable setting.</p>\n<blockquote>\n<blockquote>\n<p>For instance, who on earth wants to read something like \"is_aligned (push_bit m k) m\" instead of \"is_aligned (k &lt;&lt; m) m\"? . The syntax was introduced for good reasons. It is fine to make it a bundle to not pollute a global syntax space, it is not fine to change original material that was written with a purpose.</p>\n</blockquote>\n<p>If your point is to to apply the ‹_ &lt;&lt; _› syntax etc. thoroughly and<br>\nconsistently among Word_Lib theories, I am happy to look after these slips.</p>\n</blockquote>\n<p>That would be appreciated. My complaint was not that a new lemma did not use the word syntax (although it would be nice to remain consistent), but that old lemmas were rewritten to not use it. Possibly as part of another change.</p>\n<blockquote>\n<blockquote>\n<p>It is <em>absolutely</em> not fine to produce commits like \"dropped junk\" which removes a theory that was critical to how this library is used after in previous commits having made it unusable, entirely missing the point of its existence. Please revert that entire series of commits and reproduce the old setup.</p>\n</blockquote>\n<p>After a second study of history I notice that I mess<br>\n[message truncated]</p>\n</blockquote>",
        "id": 256707063,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633682421
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nSide-remark: About 50% of the time I do look at the hg history (using e.g. \"hg<br>\ngrep --all\") to see how names evolve, and what needs to be done. This also<br>\napplies to magic (simp add: ...) or (simp del: ...) details.</p>\n<p>Makarius</p>\n<hr>\n<p>isabelle-dev mailing list<br>\n<a href=\"mailto:isabelle-dev@in.tum.de\">isabelle-dev@in.tum.de</a><br>\n<a href=\"https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev\">https://mailman46.in.tum.de/mailman/listinfo/isabelle-dev</a></p>",
        "id": 256709264,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633683659
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;</p>\n<blockquote>\n<p>There is some relevant experience from Isabelle2021. As a rough order of magnitude, it took about 2 full person months to do the complete proof update for l4v, which finished a bit more than a week ago now. 2 person months is about 1 person month higher than a usual Isabelle update. Not quite all, but most of the changes were due to Word_Lib.</p>\n<p>You did an initial foray into this proof update for one architecture (ARM, 32 bit) after the first half of the Isabelle2021 changes. The result of that foray was that those changes were relatively benign, which is why I was surprised by the much higher effort later. I think the main fallout was from a few small changes in the second half of the Isabelle2021 update.</p>\n</blockquote>\n<p>In the retrospective I did underestimate the side conditions imposed by<br>\nthe life cycle of l4v wrt. to Isabelle releases.</p>\n<p>Do I understand correctly that there is a running version built on<br>\nIsabelle2021 / AFP 2021?  If yes, this can be used as point of reference<br>\nwhen appropriate.</p>\n<p>It seems there are a couple of things to iron out properly.  There is<br>\nstill some time towards the upcoming Isabelle release.  Beyond that, how<br>\nstrictly is l4v coupled to the Isabelle / AFP release cycle?  Maybe<br>\nconsolidations for Word_Lib could also happen on a dedicated AFP branch<br>\n<em>after</em> the Isabelle release and later converge to the (then) next AFP<br>\nrelease.</p>\n<blockquote>\n<ul>\n<li>things started breaking immediately for 64-bit architectures, because the Sumo concept alone does not quite work. It is not enough to make all lemmas for all word lengths available. The point of the Word_SetupXX theories is to additionally establish a set of common names that refer to the default word type of the program (basically, whatever \"unsigned int\" is in C for that architecture, and what the register width is for the machine). Having these names common means that the same proof text can work on different concrete types. This is different to actually generic lemmas that work for any word length or that need to resolve preconditions on the word length before they can be applied (the latter can be solved in theories like Word8 etc). It is not the prettiest form of genericity, but it is crucial for not having to duplicate thousands of lemmas that for other reasons do need to refer to a concrete word length (which is known in the proof state, but unknown to the proof text). Ultimately this is comes from C, which as painful as it is, works on exactly that principle that the same type name can refer to different representations, depending on architecture.</li>\n</ul>\n</blockquote>\n<p>My proposal:</p>\n<ul>\n<li>\n<p>Theories Word_SetupXX re-appear offering the same name bindings as<br>\npre-Isabelle2021</p>\n</li>\n<li>\n<p>Their purpose is documented in the Guide.thy</p>\n</li>\n</ul>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>The shift*1 Operations have been auxiliary definitions in the<br>\ndistribution to bootstrap the bit shifts operations, similarly to<br>\niszero, equipped only with a minimal set of lemmas. If one tool out<br>\nthere relies on it as explicit constant i. e. due to pattern matching, I<br>\nwon’t shed a tear to keep it as constant.</p>\n</blockquote>\n<p>Great, let's keep them constants.</p>\n<blockquote>\n<p>(Aside, the primitive definitions then would be maybe: shiftl1 a = (a &lt;&lt; 1), shiftr1 a = (a &gt;&gt; 1), sshiftr1 a = (a &gt;&gt;&gt; 1)).</p>\n</blockquote>\n<p>I'd be fine with these as definitions as long as the old forms still available as lemmas, preferably under the previous names. Maybe we can make sure over time that these constants are not produced any more by any tools and then they can finally be removed, but that is a number of release cycles away.</p>\n</blockquote>\n</blockquote>\n<p>My proposal:</p>\n<ul>\n<li>\n<p>Proper constants for shiftl1 a = (a &lt;&lt; 1), shiftr1 a = (a &gt;&gt; 1),<br>\nsshiftr1 a = (a &gt;&gt;&gt; 1)</p>\n</li>\n<li>\n<p>Facts for those available under the same names as Isabelle2021 / AFP<br>\n2021 (point of reference)</p>\n</li>\n</ul>\n<blockquote>\n<blockquote>\n<p>In terms of Isabelle's robustness: I'd agree with it being more robust for moving constants where antiquotations can be used to refer to unqualified names, but renaming is still one of the major pain points in almost every Isabelle release -- compounded by the fact that by far not all of these are documented in a way that would be usable for a simple search/replace. Those names that are listed in NEWS with their replacements are highly appreciated, but the lists are not complete, and there is no such NEWS for Word_Lib.</p>\n<p>Maybe the impression of robustness comes from the incremental way we update the AFP. Each specific renaming is obvious to the author of that change and likely not hard to automate. On the other hand, being confronted with all of these at the same time, and having to find all instances by proof failure is time consuming and can be extremely frustrating when you have to hunt in hg history for what something has been renamed to.</p>\n</blockquote>\n</blockquote>\n<p>Concerning NEWS, the Guide.thy has a changelog section.</p>\n<p>Concerning robustness I did refer to changes to the internal<br>\nidentifiers, e.g. due to a move to a different theory, not to a renaming<br>\nproper, ie. a change of the typical (unqualified) name visible to the<br>\nend-user.  And according to my memory such renamings should not have<br>\nhappened.  Did you stumble over a renaming though?</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>For instance, who on earth wants to read something like \"is_aligned (push_bit m k) m\" instead of \"is_aligned (k &lt;&lt; m) m\"? . The syntax was introduced for good reasons. It is fine to make it a bundle to not pollute a global syntax space, it is not fine to change original material that was written with a purpose.</p>\n</blockquote>\n<p>If your point is to to apply the ‹_ &lt;&lt; _› syntax etc. thoroughly and<br>\nconsistently among Word_Lib theories, I am happy to look after these slips.</p>\n</blockquote>\n<p>That would be appreciated. My complaint was not that a new lemma did not use the word syntax (although it would be nice to remain consistent), but that old lemmas were rewritten to not use it. Possibly as part of another change.</p>\n</blockquote>\n</blockquote>\n<p>There is one issue which prevents a 100% satisfactory solution here: the<br>\nsyntax needs abbreviations, and these cannot be organized in bundles.</p>\n<p>Taking into consideration that there seem to be enough rough edges at<br>\nthe moment, I would not object to postpone the reconciliation of the two<br>\ndifferent layers of bit shift operations to a future release, ie.<br>\nkeeping &lt;&lt; &gt;&gt; &gt;&gt;&gt; as distinct constants at the moment.</p>\n<p>(This would be one remaining item on my todo list, the other one being<br>\nthe final dismantling of Ancient_Numeral.thy sometime in the future)</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the unat_arith tactic solves fewer goals. I might be mistaken, but I think this is mostly due to simpset changes, but I have not had the time to track down which exactly.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Tactic unat_arith has a technical deficiency: at the time of its<br>\ndeclaration it takes a simpset »as it is« as base, and hence its<br>\nbehavior is brittle wrt. to movements in the surroundings.  Since there<br>\nare many things to work out concerning the simp setup, I would postpone<br>\nthis issue after these have been resolved.</p>\n<blockquote>\n<ul>\n<li>the default simpset setup changed, it no longer reliably normalises ground terms with numerals.</li>\n</ul>\n</blockquote>\n<p>Ie. terms involving operations like AND + - * and numerals 0, 1, 42?  If<br>\nthat breaks down, something is really weird.</p>\n<blockquote>\n<p>This caused a bunch of proof changes, hunting for which rules are needed etc. My reading of NEWS it that this is getting worse with NOT terms not being normalised any more. This potentially makes sense for int/nat, but I would suggest to keep them for Word (and to make sure the rest of the numeral simplification actually covers all cases -- usually 0, 1, Suc 0 are the corner cases to look out for).</p>\n</blockquote>\n<p>After Thomas Sewell pointed out some problems with simplifying bit<br>\nexpressions over natural numbers, I took over the elementary numeral<br>\nrewriting approach by Andreas Lochbihler originating in session<br>\nNative_Word to overcome that;  in the first stage that relied on NOT not<br>\nbeing simplified by default, but with everything now in place, it should<br>\nnot be difficult to recover that.</p>\n<p>Simplification of bit expressions involving word numerals works still<br>\nthe same way as pre-Isabelle2021: rewriting to int first.  If this by<br>\nitself exhibits problems.</p>\n<blockquote>\n<ul>\n<li>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</li>\n</ul>\n</blockquote>\n<p>Yes, that is definitely supposed to work.  Do you have examples at hand?<br>\n Otherwise I will augment the Examples.thy to cover more combinations.</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>punning max_word with -1 conflicts with normalising numerals to the interval [0; 2^len). There were a few test lemmas in the repository that made sure this was not accidentally removed, I'm not sure where these went. Removing normalisation for -1 in turn leads to terms like unat(-1) which proofs then get stuck on. This can be fixed locally by finding the right rule to re-establish the old normalisation, but that will of course mean that abstract lemmas that refer to -1 won't apply any more. This means there is no principled way to deal with ground terms any more. I can see the appeal of using -1 for generic lemmas, because it has nice algebraic meaning (as opposed to max_word). Maybe the solution is to build a rule set for arithmetic that can be added on demand or as a bundle. It's a bit of a crutch, but at least it would provide a choice.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Concerning normalizing numerals to the interval [0; 2^len) – is that<br>\nsupposed to work universally?  There seems to be no such mechanism<br>\nneither in Isabelle2020 nor Isabelle2021:</p>\n<p>lemma ‹w = 2342342› for w :: ‹4 word›<br>\n  apply simp</p>\n<p>(I think something like that would require a simproc).</p>\n<p>Concerning max_word – would it help to let it abbreviate 2^len - 1<br>\nrather than -1?  If it is used in terms involving concrete numerals, the<br>\nabstract properties of -1 are not that relevant.  (I pondered that issue<br>\ninto different directions, but will spare the space here for the moment).</p>\n<p>Coming back to word numeral norm<br>\n[message truncated]</p>",
        "id": 256852807,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633768671
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\n(Repost after using a bad mail address – sorry for the noise)</p>\n<blockquote>\n<p>There is some relevant experience from Isabelle2021. As a rough order of magnitude, it took about 2 full person months to do the complete proof update for l4v, which finished a bit more than a week ago now. 2 person months is about 1 person month higher than a usual Isabelle update. Not quite all, but most of the changes were due to Word_Lib.</p>\n<p>You did an initial foray into this proof update for one architecture (ARM, 32 bit) after the first half of the Isabelle2021 changes. The result of that foray was that those changes were relatively benign, which is why I was surprised by the much higher effort later. I think the main fallout was from a few small changes in the second half of the Isabelle2021 update.</p>\n</blockquote>\n<p>In the retrospective I did underestimate the side conditions imposed by<br>\nthe life cycle of l4v wrt. to Isabelle releases.</p>\n<p>Do I understand correctly that there is a running version built on<br>\nIsabelle2021 / AFP 2021?  If yes, this can be used as point of reference<br>\nwhen appropriate.</p>\n<p>It seems there are a couple of things to iron out properly.  There is<br>\nstill some time towards the upcoming Isabelle release.  Beyond that, how<br>\nstrictly is l4v coupled to the Isabelle / AFP release cycle?  Maybe<br>\nconsolidations for Word_Lib could also happen on a dedicated AFP branch<br>\n<em>after</em> the Isabelle release and later converge to the (then) next AFP<br>\nrelease.</p>\n<blockquote>\n<ul>\n<li>things started breaking immediately for 64-bit architectures, because the Sumo concept alone does not quite work. It is not enough to make all lemmas for all word lengths available. The point of the Word_SetupXX theories is to additionally establish a set of common names that refer to the default word type of the program (basically, whatever \"unsigned int\" is in C for that architecture, and what the register width is for the machine). Having these names common means that the same proof text can work on different concrete types. This is different to actually generic lemmas that work for any word length or that need to resolve preconditions on the word length before they can be applied (the latter can be solved in theories like Word8 etc). It is not the prettiest form of genericity, but it is crucial for not having to duplicate thousands of lemmas that for other reasons do need to refer to a concrete word length (which is known in the proof state, but unknown to the proof text). Ultimately this is comes from C, which as painful as it is, works on exactly that principle that the same type name can refer to different representations, depending on architecture.</li>\n</ul>\n</blockquote>\n<p>My proposal:</p>\n<ul>\n<li>\n<p>Theories Word_SetupXX re-appear offering the same name bindings as<br>\npre-Isabelle2021</p>\n</li>\n<li>\n<p>Their purpose is documented in the Guide.thy</p>\n</li>\n</ul>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>The shift*1 Operations have been auxiliary definitions in the<br>\ndistribution to bootstrap the bit shifts operations, similarly to<br>\niszero, equipped only with a minimal set of lemmas. If one tool out<br>\nthere relies on it as explicit constant i. e. due to pattern matching, I<br>\nwon’t shed a tear to keep it as constant.</p>\n</blockquote>\n<p>Great, let's keep them constants.</p>\n<blockquote>\n<p>(Aside, the primitive definitions then would be maybe: shiftl1 a = (a &lt;&lt; 1), shiftr1 a = (a &gt;&gt; 1), sshiftr1 a = (a &gt;&gt;&gt; 1)).</p>\n</blockquote>\n<p>I'd be fine with these as definitions as long as the old forms still available as lemmas, preferably under the previous names. Maybe we can make sure over time that these constants are not produced any more by any tools and then they can finally be removed, but that is a number of release cycles away.</p>\n</blockquote>\n</blockquote>\n<p>My proposal:</p>\n<ul>\n<li>\n<p>Proper constants for shiftl1 a = (a &lt;&lt; 1), shiftr1 a = (a &gt;&gt; 1),<br>\nsshiftr1 a = (a &gt;&gt;&gt; 1)</p>\n</li>\n<li>\n<p>Facts for those available under the same names as Isabelle2021 / AFP<br>\n2021 (point of reference)</p>\n</li>\n</ul>\n<blockquote>\n<blockquote>\n<p>In terms of Isabelle's robustness: I'd agree with it being more robust for moving constants where antiquotations can be used to refer to unqualified names, but renaming is still one of the major pain points in almost every Isabelle release -- compounded by the fact that by far not all of these are documented in a way that would be usable for a simple search/replace. Those names that are listed in NEWS with their replacements are highly appreciated, but the lists are not complete, and there is no such NEWS for Word_Lib.</p>\n<p>Maybe the impression of robustness comes from the incremental way we update the AFP. Each specific renaming is obvious to the author of that change and likely not hard to automate. On the other hand, being confronted with all of these at the same time, and having to find all instances by proof failure is time consuming and can be extremely frustrating when you have to hunt in hg history for what something has been renamed to.</p>\n</blockquote>\n</blockquote>\n<p>Concerning NEWS, the Guide.thy has a changelog section.</p>\n<p>Concerning robustness I did refer to changes to the internal<br>\nidentifiers, e.g. due to a move to a different theory, not to a renaming<br>\nproper, ie. a change of the typical (unqualified) name visible to the<br>\nend-user.  And according to my memory such renamings should not have<br>\nhappened.  Did you stumble over a renaming though?</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>For instance, who on earth wants to read something like \"is_aligned (push_bit m k) m\" instead of \"is_aligned (k &lt;&lt; m) m\"? . The syntax was introduced for good reasons. It is fine to make it a bundle to not pollute a global syntax space, it is not fine to change original material that was written with a purpose.</p>\n</blockquote>\n<p>If your point is to to apply the ‹_ &lt;&lt; _› syntax etc. thoroughly and<br>\nconsistently among Word_Lib theories, I am happy to look after these slips.</p>\n</blockquote>\n<p>That would be appreciated. My complaint was not that a new lemma did not use the word syntax (although it would be nice to remain consistent), but that old lemmas were rewritten to not use it. Possibly as part of another change.</p>\n</blockquote>\n</blockquote>\n<p>There is one issue which prevents a 100% satisfactory solution here: the<br>\nsyntax needs abbreviations, and these cannot be organized in bundles.</p>\n<p>Taking into consideration that there seem to be enough rough edges at<br>\nthe moment, I would not object to postpone the reconciliation of the two<br>\ndifferent layers of bit shift operations to a future release, ie.<br>\nkeeping &lt;&lt; &gt;&gt; &gt;&gt;&gt; as distinct constants at the moment.</p>\n<p>(This would be one remaining item on my todo list, the other one being<br>\nthe final dismantling of Ancient_Numeral.thy sometime in the future)</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the unat_arith tactic solves fewer goals. I might be mistaken, but I think this is mostly due to simpset changes, but I have not had the time to track down which exactly.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Tactic unat_arith has a technical deficiency: at the time of its<br>\ndeclaration it takes a simpset »as it is« as base, and hence its<br>\nbehavior is brittle wrt. to movements in the surroundings.  Since there<br>\nare many things to work out concerning the simp setup, I would postpone<br>\nthis issue after these have been resolved.</p>\n<blockquote>\n<ul>\n<li>the default simpset setup changed, it no longer reliably normalises ground terms with numerals.</li>\n</ul>\n</blockquote>\n<p>Ie. terms involving operations like AND + - * and numerals 0, 1, 42?  If<br>\nthat breaks down, something is really weird.</p>\n<blockquote>\n<p>This caused a bunch of proof changes, hunting for which rules are needed etc. My reading of NEWS it that this is getting worse with NOT terms not being normalised any more. This potentially makes sense for int/nat, but I would suggest to keep them for Word (and to make sure the rest of the numeral simplification actually covers all cases -- usually 0, 1, Suc 0 are the corner cases to look out for).</p>\n</blockquote>\n<p>After Thomas Sewell pointed out some problems with simplifying bit<br>\nexpressions over natural numbers, I took over the elementary numeral<br>\nrewriting approach by Andreas Lochbihler originating in session<br>\nNative_Word to overcome that;  in the first stage that relied on NOT not<br>\nbeing simplified by default, but with everything now in place, it should<br>\nnot be difficult to recover that.</p>\n<p>Simplification of bit expressions involving word numerals works still<br>\nthe same way as pre-Isabelle2021: rewriting to int first.  If this by<br>\nitself exhibits problems.</p>\n<blockquote>\n<ul>\n<li>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</li>\n</ul>\n</blockquote>\n<p>Yes, that is definitely supposed to work.  Do you have examples at hand?<br>\n Otherwise I will augment the Examples.thy to cover more combinations.</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>punning max_word with -1 conflicts with normalising numerals to the interval [0; 2^len). There were a few test lemmas in the repository that made sure this was not accidentally removed, I'm not sure where these went. Removing normalisation for -1 in turn leads to terms like unat(-1) which proofs then get stuck on. This can be fixed locally by finding the right rule to re-establish the old normalisation, but that will of course mean that abstract lemmas that refer to -1 won't apply any more. This means there is no principled way to deal with ground terms any more. I can see the appeal of using -1 for generic lemmas, because it has nice algebraic meaning (as opposed to max_word). Maybe the solution is to build a rule set for arithmetic that can be added on demand or as a bundle. It's a bit of a crutch, but at least it would provide a choice.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Concerning normalizing numerals to the interval [0; 2^len) – is that<br>\nsupposed to work universally?  There seems to be no such mechanism<br>\nneither in Isabelle2020 nor Isabelle2021:</p>\n<p>lemma ‹w = 2342342› for w :: ‹4 word›<br>\n  apply simp</p>\n<p>(I think something like that would require a simproc).</p>\n<p>Concerning max_word – would it help to let it abbreviate 2^len - 1<br>\nrather than -1?  If it is used in terms involving concrete numerals, the<br>\nabstract properties of -1 are not that relevant.  (I pondered that issue<br>\ninto different directions, but will spare th<br>\n[message truncated]</p>",
        "id": 256853030,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633768884
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nNo need to investigate that further – the critical rules are<br>\nword_of_nat_eq_0_iff and word_of_int_eq_0_iff</p>\n<p>Florian<br>\n<a href=\"/user_uploads/14278/HOTKmgN6cRPaXF2dtb9_59gj/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 256884034,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633799387
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nA quick report after reaching isabelle 807b094a9b78 / AFP c42c2c2447c2.</p>\n<ul>\n<li>\n<p>NOT &lt;numeric expression&gt; is normalized without interfering with other<br>\nnormalization rules;  rules have been augmented accordingly.</p>\n</li>\n<li>\n<p>Conversions are not normalized over-aggressively, ie. only if no<br>\nauxiliary »glue« operations have to be inserted.</p>\n</li>\n</ul>\n<p>In the pipeline is a change which makes the normalizing set on int, nat,<br>\nword more complete, esp. wrt. negative numerals; while there is no<br>\nevidence that is the reason for the observed breakdown in normalization<br>\nof words, it has been a good opportunity to tackle that systematically.</p>\n<p>An observation: Normalization rules for words typically work by<br>\nrewriting to int. This approach is historic – normalization could be<br>\nachieved by more elementary rewriting in most cases. At least this seems<br>\nto be the cause for the illusion of implicit normalization of word numerals:</p>\n<p>unbundle bit_operations_syntax</p>\n<p>lemma<br>\n  ‹w = 1705› for w :: ‹8 word›<br>\n  apply simp \\&lt;comment&gt; ‹no normalization›<br>\n  oops</p>\n<p>lemma<br>\n  ‹w = 1705 AND 255› for w :: ‹8 word›<br>\n  apply simp \\&lt;comment&gt; ‹normalizes due to rewriting to int›<br>\n  oops</p>\n<p>My next steps are to conclude the obvious normalization issues in the<br>\ndistribution and then tackle the open more technical issues in the AFP.</p>\n<p>Then I have to find a way to find out whether these resolve the observed<br>\nissues in l4v, particularly:</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the default simpset setup changed, it no longer reliably normalises ground terms with numerals.</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>There is a separate question of what a good setup is for the interplay between casts to different types and what good normal forms for these are. We had settled on never unfolding ucast/unat/uint etc automatically, instead producing abstract rules that describe the interaction with the usual operators and relationships between each other. I still think that is a reasonable setting.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the new simpset often loops in the l4v proofs, because it either reversed polarity or added additional rules about ucast/unat. Some of this was fall-out from the more general treatment (e.g. unsigned)</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>not all new looping is due to that specific problem. I haven't been able to track down what rules exactly are the problem, but adding field_simps now almost always loops in word proofs. This might be a symptom of a different problem (i.e. not related to Word_Lib), because the usual fix was to instantiate specific commutativity rules. This indicates that something doesn't quite work any more with ordered rewriting. Possibly there is now an additional rewriting step or something like that so that the simple test in <code>simp</code> no longer suffices.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Just a further observation:</p>\n<blockquote>\n<blockquote>\n<p>Overall, it looks like a number of aspects of the new simpset are convenient for reasoning abstractly about machine words when you are working within the library (esp take_bit and 0/dvd), but counterproductive once you are working with specific word lengths as you do in program verification.</p>\n</blockquote>\n</blockquote>\n<p>Simp rules for concrete values are often oriented the other way round<br>\nthan those for abstract reasoning; typical instances I’m familiar with<br>\nare abstract code equations and simp rules for numerals – which makes it<br>\npainful to prove <em>new</em> simp rules for numerals since the concrete<br>\nrewrites always get into the way.</p>\n<p>But from what I have seen so far I don’t think that this applies here –<br>\nthe bias towards take_bit stems from a few new simp rules on<br>\nconversions, which are now not default any longer.  Whether more rules<br>\non take_bit would have resolved the problems is unclear to me, but the<br>\nidea behind the current setup to leave conversions in case of doubt<br>\nsounds like a reasonable and understandable approach to settle on.</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/0we9FgrBqwE8gDS0O5yzRD8C/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 256966440,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633882765
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\n(Repost after using a bad mail address (again) – sorry for the noise)</p>\n<p>A quick report after reaching isabelle 807b094a9b78 / AFP c42c2c2447c2.</p>\n<ul>\n<li>\n<p>NOT &lt;numeric expression&gt; is normalized without interfering with other<br>\nnormalization rules;  rules have been augmented accordingly.</p>\n</li>\n<li>\n<p>Conversions are not normalized over-aggressively, ie. only if no<br>\nauxiliary »glue« operations have to be inserted.</p>\n</li>\n</ul>\n<p>In the pipeline is a change which makes the normalizing set on int, nat,<br>\nword more complete, esp. wrt. negative numerals; while there is no<br>\nevidence that this the reason for the observed breakdown in<br>\nnormalization of words, it has been a good opportunity to tackle that<br>\nsystematically.</p>\n<p>An observation: Normalization rules for words typically work by<br>\nrewriting to int. This approach is historic – normalization could be<br>\nachieved by more elementary rewriting in most cases. At least this seems<br>\nto be the cause for the illusion of implicit normalization of word numerals:</p>\n<p>unbundle bit_operations_syntax</p>\n<p>lemma<br>\n  ‹w = 1705› for w :: ‹8 word›<br>\n  apply simp \\&lt;comment&gt; ‹no normalization›<br>\n  oops</p>\n<p>lemma<br>\n  ‹w = 1705 AND 255› for w :: ‹8 word›<br>\n  apply simp \\&lt;comment&gt; ‹normalizes due to rewriting to int›<br>\n  oops</p>\n<p>My next steps are to conclude the obvious normalization issues in the<br>\ndistribution and then tackle the open more technical issues in the AFP.</p>\n<p>Then I have to find a way to find out whether these resolve the observed<br>\nissues in l4v, particularly:</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the default simpset setup changed, it no longer reliably normalises ground terms with numerals.</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>There is a separate question of what a good setup is for the interplay between casts to different types and what good normal forms for these are. We had settled on never unfolding ucast/unat/uint etc automatically, instead producing abstract rules that describe the interaction with the usual operators and relationships between each other. I still think that is a reasonable setting.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the new simpset often loops in the l4v proofs, because it either reversed polarity or added additional rules about ucast/unat. Some of this was fall-out from the more general treatment (e.g. unsigned)</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>not all new looping is due to that specific problem. I haven't been able to track down what rules exactly are the problem, but adding field_simps now almost always loops in word proofs. This might be a symptom of a different problem (i.e. not related to Word_Lib), because the usual fix was to instantiate specific commutativity rules. This indicates that something doesn't quite work any more with ordered rewriting. Possibly there is now an additional rewriting step or something like that so that the simple test in <code>simp</code> no longer suffices.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Just a further observation:</p>\n<blockquote>\n<blockquote>\n<p>Overall, it looks like a number of aspects of the new simpset are convenient for reasoning abstractly about machine words when you are working within the library (esp take_bit and 0/dvd), but counterproductive once you are working with specific word lengths as you do in program verification.</p>\n</blockquote>\n</blockquote>\n<p>Simp rules for concrete values are often oriented the other way round<br>\nthan those for abstract reasoning; typical instances I’m familiar with<br>\nare abstract code equations and simp rules for numerals – which makes it<br>\npainful to prove <em>new</em> simp rules for numerals since the concrete<br>\nrewrites always get into the way.</p>\n<p>But from what I have seen so far I don’t think that this applies here –<br>\nthe bias towards take_bit stems from a few new simp rules on<br>\nconversions, which are now not default any longer.  Whether more rules<br>\non take_bit would have resolved the problems is unclear to me, but the<br>\nidea behind the current setup to leave conversions in case of doubt<br>\nsounds like a reasonable and understandable approach to settle on.</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/z1JOzO_FUtLKxNoBFBCGX-1u/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 256966732,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633883042
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nA clarifying remark:</p>\n<p>This does only refer to Word.thy proper.</p>\n<p>In Word_Lib, there is theory Norm_Words.thy which does a normalization<br>\nof word numerals except ‹- 1›; according to its examples, it works as<br>\nadvertized.</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/_Wdq-3SUY1UOtwFbg-lkKemO/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 256971890,
        "sender_full_name": "Email Gateway",
        "timestamp": 1633887872
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;</p>\n<blockquote>\n<p>On 11 Oct 2021, at 03:19, Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt; wrote:</p>\n<p>Signed PGP part<br>\nA quick report after reaching isabelle 807b094a9b78 / AFP c42c2c2447c2.</p>\n<ul>\n<li>NOT &lt;numeric expression&gt; is normalized without interfering with other<br>\nnormalization rules;  rules have been augmented accordingly.</li>\n</ul>\n</blockquote>\n<p>Excellent.</p>\n<blockquote>\n<ul>\n<li>Conversions are not normalized over-aggressively, ie. only if no<br>\nauxiliary »glue« operations have to be inserted.</li>\n</ul>\n</blockquote>\n<p>Also sounds good.</p>\n<blockquote>\n<p>An observation: Normalization rules for words typically work by<br>\nrewriting to int. This approach is historic – normalization could be<br>\nachieved by more elementary rewriting in most cases. At least this seems<br>\nto be the cause for the illusion of implicit normalization of word numerals:</p>\n<p>unbundle bit_operations_syntax</p>\n<p>lemma<br>\n ‹w = 1705› for w :: ‹8 word›<br>\n apply simp \\&lt;comment&gt; ‹no normalization›<br>\n oops</p>\n<p>lemma<br>\n ‹w = 1705 AND 255› for w :: ‹8 word›<br>\n apply simp \\&lt;comment&gt; ‹normalizes due to rewriting to int›<br>\n oops</p>\n<p>My next steps are to conclude the obvious normalization issues in the<br>\ndistribution and then tackle the open more technical issues in the AFP.</p>\n</blockquote>\n<p>This sounds all good.</p>\n<blockquote>\n<p>Then I have to find a way to find out whether these resolve the observed<br>\nissues in l4v, particularly:</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the default simpset setup changed, it no longer reliably normalises ground terms with numerals.</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>There is a separate question of what a good setup is for the interplay between casts to different types and what good normal forms for these are. We had settled on never unfolding ucast/unat/uint etc automatically, instead producing abstract rules that describe the interaction with the usual operators and relationships between each other. I still think that is a reasonable setting.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the new simpset often loops in the l4v proofs, because it either reversed polarity or added additional rules about ucast/unat. Some of this was fall-out from the more general treatment (e.g. unsigned)</li>\n</ul>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>not all new looping is due to that specific problem. I haven't been able to track down what rules exactly are the problem, but adding field_simps now almost always loops in word proofs. This might be a symptom of a different problem (i.e. not related to Word_Lib), because the usual fix was to instantiate specific commutativity rules. This indicates that something doesn't quite work any more with ordered rewriting. Possibly there is now an additional rewriting step or something like that so that the simple test in <code>simp</code> no longer suffices.</li>\n</ul>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>The last update fixed all the occurrences that Isabelle2021 introduces, so it might be nontrivial to find examples. I can try to start a partial update to Isabelle2021-1-RC0 and report on how that goes. I can probably also still relatively easily find the positions where looping with commutativity was the specific problem.</p>\n<blockquote>\n<p>Just a further observation:</p>\n<blockquote>\n<blockquote>\n<p>Overall, it looks like a number of aspects of the new simpset are convenient for reasoning abstractly about machine words when you are working within the library (esp take_bit and 0/dvd), but counterproductive once you are working with specific word lengths as you do in program verification.</p>\n</blockquote>\n</blockquote>\n<p>Simp rules for concrete values are often oriented the other way round<br>\nthan those for abstract reasoning; typical instances I’m familiar with<br>\nare abstract code equations and simp rules for numerals – which makes it<br>\npainful to prove <em>new</em> simp rules for numerals since the concrete<br>\nrewrites always get into the way.</p>\n<p>But from what I have seen so far I don’t think that this applies here –<br>\nthe bias towards take_bit stems from a few new simp rules on<br>\nconversions, which are now not default any longer.  Whether more rules<br>\non take_bit would have resolved the problems is unclear to me, but the<br>\nidea behind the current setup to leave conversions in case of doubt<br>\nsounds like a reasonable and understandable approach to settle on.</p>\n</blockquote>\n<p>I'd be happy with that.</p>\n<p>Cheers,<br>\nGerwin<br>\n<a href=\"/user_uploads/14278/0-aYblZ9Aa8tAfTOkP3jV33Q/signature.asc\">signature.asc</a></p>",
        "id": 257149929,
        "sender_full_name": "Email Gateway",
        "timestamp": 1634014880
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;</p>\n<blockquote>\n<p>On 9 Oct 2021, at 19:37, Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt; wrote:</p>\n<p>Signed PGP part</p>\n<blockquote>\n<p>There is some relevant experience from Isabelle2021. As a rough order of magnitude, it took about 2 full person months to do the complete proof update for l4v, which finished a bit more than a week ago now. 2 person months is about 1 person month higher than a usual Isabelle update. Not quite all, but most of the changes were due to Word_Lib.</p>\n<p>You did an initial foray into this proof update for one architecture (ARM, 32 bit) after the first half of the Isabelle2021 changes. The result of that foray was that those changes were relatively benign, which is why I was surprised by the much higher effort later. I think the main fallout was from a few small changes in the second half of the Isabelle2021 update.</p>\n</blockquote>\n<p>In the retrospective I did underestimate the side conditions imposed by<br>\nthe life cycle of l4v wrt. to Isabelle releases.</p>\n<p>Do I understand correctly that there is a running version built on<br>\nIsabelle2021 / AFP 2021?  If yes, this can be used as point of reference<br>\nwhen appropriate.</p>\n</blockquote>\n<p>Yes, the current master branch of <a href=\"https://github.com/seL4/l4v\">https://github.com/seL4/l4v</a> &lt;<a href=\"https://github.com/seL4/l4v\">https://github.com/seL4/l4v</a>&gt; is on Isabelle2021</p>\n<blockquote>\n<p>It seems there are a couple of things to iron out properly.  There is<br>\nstill some time towards the upcoming Isabelle release.  Beyond that, how<br>\nstrictly is l4v coupled to the Isabelle / AFP release cycle?</p>\n</blockquote>\n<p>l4v is strongly coupled to the release cycle in the sense that it only uses Isabelle release versions. It maybe lag behind Isabelle releases sometimes, and it may take new versions of AFP entries as long as these still work with the corresponding Isabelle release (or may add its own changes) .</p>\n<blockquote>\n<p>Maybe consolidations for Word_Lib could also happen on a dedicated AFP branch<br>\n<em>after</em> the Isabelle release and later converge to the (then) next AFP<br>\nrelease.</p>\n</blockquote>\n<p>Yes, that would be a possibility.</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>things started breaking immediately for 64-bit architectures, because the Sumo concept alone does not quite work. It is not enough to make all lemmas for all word lengths available. The point of the Word_SetupXX theories is to additionally establish a set of common names that refer to the default word type of the program (basically, whatever \"unsigned int\" is in C for that architecture, and what the register width is for the machine). Having these names common means that the same proof text can work on different concrete types. This is different to actually generic lemmas that work for any word length or that need to resolve preconditions on the word length before they can be applied (the latter can be solved in theories like Word8 etc). It is not the prettiest form of genericity, but it is crucial for not having to duplicate thousands of lemmas that for other reasons do need to refer to a concrete word length (which is known in the proof state, but unknown to the proof text). Ultimately this is comes from C, which as painful as it is, works on exactly that principle that the same type name can refer to different representations, depending on architecture.</li>\n</ul>\n</blockquote>\n<p>My proposal:\n* Theories Word_SetupXX re-appear offering the same name bindings as<br>\npre-Isabelle2021\n* Their purpose is documented in the Guide.thy</p>\n</blockquote>\n<p>Sounds good.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>The shift*1 Operations have been auxiliary definitions in the<br>\ndistribution to bootstrap the bit shifts operations, similarly to<br>\niszero, equipped only with a minimal set of lemmas. If one tool out<br>\nthere relies on it as explicit constant i. e. due to pattern matching, I<br>\nwon’t shed a tear to keep it as constant.</p>\n</blockquote>\n<p>Great, let's keep them constants.</p>\n<blockquote>\n<p>(Aside, the primitive definitions then would be maybe: shiftl1 a = (a &lt;&lt; 1), shiftr1 a = (a &gt;&gt; 1), sshiftr1 a = (a &gt;&gt;&gt; 1)).</p>\n</blockquote>\n<p>I'd be fine with these as definitions as long as the old forms still available as lemmas, preferably under the previous names. Maybe we can make sure over time that these constants are not produced any more by any tools and then they can finally be removed, but that is a number of release cycles away.</p>\n</blockquote>\n</blockquote>\n<p>My proposal:\n* Proper constants for shiftl1 a = (a &lt;&lt; 1), shiftr1 a = (a &gt;&gt; 1),<br>\nsshiftr1 a = (a &gt;&gt;&gt; 1)\n* Facts for those available under the same names as Isabelle2021 / AFP<br>\n2021 (point of reference)</p>\n</blockquote>\n<p>Perfect.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>For instance, who on earth wants to read something like \"is_aligned (push_bit m k) m\" instead of \"is_aligned (k &lt;&lt; m) m\"? . The syntax was introduced for good reasons. It is fine to make it a bundle to not pollute a global syntax space, it is not fine to change original material that was written with a purpose.</p>\n</blockquote>\n<p>If your point is to to apply the ‹_ &lt;&lt; _› syntax etc. thoroughly and<br>\nconsistently among Word_Lib theories, I am happy to look after these slips.</p>\n</blockquote>\n<p>That would be appreciated. My complaint was not that a new lemma did not use the word syntax (although it would be nice to remain consistent), but that old lemmas were rewritten to not use it. Possibly as part of another change.</p>\n</blockquote>\n</blockquote>\n<p>There is one issue which prevents a 100% satisfactory solution here: the<br>\nsyntax needs abbreviations, and these cannot be organized in bundles.</p>\n<p>Taking into consideration that there seem to be enough rough edges at<br>\nthe moment, I would not object to postpone the reconciliation of the two<br>\ndifferent layers of bit shift operations to a future release, ie.<br>\nkeeping &lt;&lt; &gt;&gt; &gt;&gt;&gt; as distinct constants at the moment.</p>\n</blockquote>\n<p>I think that would be Ok, yes.</p>\n<blockquote>\n<p>(This would be one remaining item on my todo list, the other one being<br>\nthe final dismantling of Ancient_Numeral.thy sometime in the future)</p>\n</blockquote>\n<p>That is probably a good idea, although some of these old lemmas are still used. It should be possible to find where these are given a list of names.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>the unat_arith tactic solves fewer goals. I might be mistaken, but I think this is mostly due to simpset changes, but I have not had the time to track down which exactly.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Tactic unat_arith has a technical deficiency: at the time of its<br>\ndeclaration it takes a simpset »as it is« as base, and hence its<br>\nbehavior is brittle wrt. to movements in the surroundings.  Since there<br>\nare many things to work out concerning the simp setup, I would postpone<br>\nthis issue after these have been resolved.</p>\n</blockquote>\n<p>I'm fine with that, and yes, it would be much better for unat_arith to use a more controlled simpset (possibly augmentable with a named theorem set).</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the default simpset setup changed, it no longer reliably normalises ground terms with numerals.</li>\n</ul>\n</blockquote>\n<p>Ie. terms involving operations like AND + - * and numerals 0, 1, 42?  If<br>\nthat breaks down, something is really weird.</p>\n</blockquote>\n<p>I don't remember the concrete term, I think it was something with shifting + AND/OR, getting stuck either on one of the usual suspects (0, 1, Suc 0 or -1).</p>\n<blockquote>\n<blockquote>\n<p>This caused a bunch of proof changes, hunting for which rules are needed etc. My reading of NEWS it that this is getting worse with NOT terms not being normalised any more. This potentially makes sense for int/nat, but I would suggest to keep them for Word (and to make sure the rest of the numeral simplification actually covers all cases -- usually 0, 1, Suc 0 are the corner cases to look out for).</p>\n</blockquote>\n<p>After Thomas Sewell pointed out some problems with simplifying bit<br>\nexpressions over natural numbers, I took over the elementary numeral<br>\nrewriting approach by Andreas Lochbihler originating in session<br>\nNative_Word to overcome that;  in the first stage that relied on NOT not<br>\nbeing simplified by default, but with everything now in place, it should<br>\nnot be difficult to recover that.</p>\n<p>Simplification of bit expressions involving word numerals works still<br>\nthe same way as pre-Isabelle2021: rewriting to int first.  If this by<br>\nitself exhibits problems.</p>\n</blockquote>\n<p>pre-Isabelle2021 it worked reliably enough, so I think that is Ok.</p>\n<blockquote>\n<blockquote>\n<ul>\n<li>the same issue caused C/assembly refinement to fail, as well as generated bitfield proofs (for 64 bit architectures) because arithmetic leaves different terms. This might be unavoidable for arbitrary terms in a larger update, but Isabelle should be able to compute with at least numeral ground terms reliably.</li>\n</ul>\n</blockquote>\n<p>Yes, that is definitely supposed to work.  Do you have examples at hand?<br>\nOtherwise I will augment the Examples.thy to cover more combinations.</p>\n</blockquote>\n<p>I can have a look if I can recover them from the update diff (it's over 480 changed files, so it might take a bit).</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>punning max_word with -1 conflicts with normalising numerals to the interval [0; 2^len). There were a few test lemmas in the repository that made sure this was not accidentally removed, I'm not sure where these went. Removing normalisation for -1 in turn leads to terms like unat(-1) which proofs then get stuck on. This can be fixed locally by finding the right rule to re-establish the old normalisation, but that will of course mean that abstract lemmas that refer to -1 won't apply any more. This means there is no principled way to deal with ground terms any more. I can see the appeal of using -1 for generic lemmas, because it has nice algebraic meaning (as opposed to max_word). Maybe the solution is to build a rule set for arithmetic that can be added on demand or as a bundle. It's a bit of a crutch, but at least it would provide a choice.</li>\n</ul>\n</blockquote>\n</blockquote>\n<p>Concerning normalizing numerals to the interval [0; 2^len) – is that<br>\nsupposed to work universally?  There seems to be no such mechanism<br>\nneither in Isabelle2020 nor Isabelle2021:</p>\n<p>lemma ‹w = 2342342› for w :: ‹4 word›<br>\n apply simp</p>\n</blockquote>\n<p>Yes, that was definitely supposed to work, also deeper in the term, e.g. P (9::3 word) used to normalise to P 1. I don't know exactly when that was lost, it might have been before Isabelle2021. It looks like it is enough for us to not actually normalise, but instead be able to decide the usual operators (=, &lt;, etc), which did <br>\n[message truncated]</p>",
        "id": 257149940,
        "sender_full_name": "Email Gateway",
        "timestamp": 1634014896
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Gerwin,</p>\n<blockquote>\n<blockquote>\n<p>Maybe consolidations for Word_Lib could also happen on a dedicated AFP<br>\nbranch<br>\n<em>after</em> the Isabelle release and later converge to the (then) next AFP<br>\nrelease.</p>\n</blockquote>\n<p>Yes, that would be a possibility.</p>\n</blockquote>\n<p>At the moment I am optimistic we won’t need this.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<ul>\n<li>things started breaking immediately for 64-bit architectures,<br>\nbecause the Sumo concept alone does not quite work. It is not enough<br>\nto make all lemmas for all word lengths available. The point of the<br>\nWord_SetupXX theories is to additionally establish a set of common<br>\nnames that refer to the default word type of the program (basically,<br>\nwhatever \"unsigned int\" is in C for that architecture, and what the<br>\nregister width is for the machine). Having these names common means<br>\nthat the same proof text can work on different concrete types. This<br>\nis different to actually generic lemmas that work for any word length<br>\nor that need to resolve preconditions on the word length before they<br>\ncan be applied (the latter can be solved in theories like Word8 etc).<br>\nIt is not the prettiest form of genericity, but it is crucial for not<br>\nhaving to duplicate thousands of lemmas that for other reasons do<br>\nneed to refer to a concrete word length (which is known in the proof<br>\nstate, but unknown to the proof text). Ultimately this is comes from<br>\nC, which as painful as it is, works on exactly that principle that<br>\nthe same type name can refer to different representations, depending<br>\non architecture.</li>\n</ul>\n</blockquote>\n<p>My proposal:\n* Theories Word_SetupXX re-appear offering the same name bindings as<br>\npre-Isabelle2021\n* Their purpose is documented in the Guide.thy</p>\n</blockquote>\n<p>Sounds good.</p>\n</blockquote>\n<p>After having a second look, the story appears more delicate: there is<br>\nnot only Word_Setup_ARCH.thy, but also Word_Lemmas_ARCH.thy; while<br>\nWord_Lemmas_32.thy and Word_Lemmas_64.thy mimic each other, they contain<br>\nboth »generic« lemmas with same name like</p>\n<p>lemma word_bits_len_of:<br>\n  \"len_of TYPE (32) = word_bits\"<br>\n  by (simp add: word_bits_conv)</p>\n<p>vs.</p>\n<p>lemma word_bits_len_of:<br>\n  \"len_of TYPE (64) = word_bits\"<br>\n  by (simp add: word_bits_conv)</p>\n<p>and »specific« lemmas with differentiated name like</p>\n<p>lemma of_nat32_0:<br>\n  \"\\&lt;lbrakk&gt;of_nat n = (0::word32); n &lt; 2 ^ word_bits\\&lt;rbrakk&gt;<br>\n\\&lt;Longrightarrow&gt; n = 0\"<br>\n  by (erule of_nat_0, simp add: word_bits_def)</p>\n<p>vs.</p>\n<p>lemma of_nat64_0:<br>\n  \"\\&lt;lbrakk&gt;of_nat n = (0::word64); n &lt; 2 ^ word_bits\\&lt;rbrakk&gt;<br>\n\\&lt;Longrightarrow&gt; n = 0\"<br>\n  by (erule of_nat_0, simp add: word_bits_def)</p>\n<p>And none of them uses the »generic« type alias machine_word introduced<br>\nin the corresponding Word_Setup_ARCH.thy theory.</p>\n<p>What is the state supposed to be achieved here?  Naively I would think<br>\nthat Word_Setup_ARCH.thy should contain all »generic« lemmas and make<br>\nuse of the »generic« type alias, wheres »specific« lemmas should stay in<br>\nWord_32 / Word_64.</p>\n<p>Florian<br>\n<a href=\"/user_uploads/14278/MsgqlhNYE3FqOvJXmvMSnn5G/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 257564065,
        "sender_full_name": "Email Gateway",
        "timestamp": 1634228889
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Gerwin et al.,</p>\n<p>my report about the state of affairs reached inisabelle 8ab92e40dde6 /<br>\nafp: 807c0639d73d tip</p>\n<p>A. &lt;&lt; &gt;&gt; &gt;&gt;&gt; are back as conventional operations (constants)</p>\n<p>The glitch of two different sets of bit shift operations naturally<br>\nsometimes produces unclear situations.</p>\n<p>An ideal solution would be available if abbreviations could be organized<br>\nin bundles.</p>\n<p>B. A confluent set of rewrite rules on ground terms</p>\n<p>Particularly for signed operations like &lt;s &lt;=s sdiv smod this has not<br>\nbeen present even for int so far.</p>\n<p>An explicit exception is the mask :: nat =&gt; 'a, where there is too<br>\nlittle context to determine whether it is supposed to be understood as<br>\nabstract or concrete value.</p>\n<p>A related cause is the singleton bit expression 2 ^ numeral _ which<br>\nnormalizes due to the conventional rules on exponentiation – but this<br>\nhas never been different.</p>\n<p>C. Poor man's genericity 32 vs. 64</p>\n<p>I still need feedback on this -- my further post maybe got lost due to<br>\nmy ongoing confusion of mail adresses.</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/XceUOyUiq2g07ROF_O4KHCF0/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 259722156,
        "sender_full_name": "Email Gateway",
        "timestamp": 1635588302
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;</p>\n<blockquote>\n<p>On 30 Oct 2021, at 21:04, Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt; wrote:</p>\n<p>Hi Gerwin et al.,</p>\n<p>my report about the state of affairs reached inisabelle 8ab92e40dde6 /<br>\nafp: 807c0639d73d tip</p>\n<p>A. &lt;&lt; &gt;&gt; &gt;&gt;&gt; are back as conventional operations (constants)</p>\n</blockquote>\n<p>That sounds good.</p>\n<blockquote>\n<p>The glitch of two different sets of bit shift operations naturally<br>\nsometimes produces unclear situations.</p>\n</blockquote>\n<p>I'll have to get deeper into a proof update to see how that interacts. Might be Ok.</p>\n<blockquote>\n<p>B. A confluent set of rewrite rules on ground terms</p>\n<p>Particularly for signed operations like &lt;s &lt;=s sdiv smod this has not<br>\nbeen present even for int so far.</p>\n</blockquote>\n<p>Yes, that right, those were underdeveloped.</p>\n<blockquote>\n<p>An explicit exception is the mask :: nat =&gt; 'a, where there is too<br>\nlittle context to determine whether it is supposed to be understood as<br>\nabstract or concrete value.</p>\n</blockquote>\n<p>Agreed, we have so far left mask abstract and not automatically reduced it for that reason.</p>\n<blockquote>\n<p>A related cause is the singleton bit expression 2 ^ numeral _ which<br>\nnormalizes due to the conventional rules on exponentiation – but this<br>\nhas never been different.</p>\n</blockquote>\n<p>Also good.</p>\n<blockquote>\n<p>C. Poor man's genericity 32 vs. 64</p>\n<p>I still need feedback on this -- my further post maybe got lost due to<br>\nmy ongoing confusion of mail adresses.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>My proposal:\n* Theories Word_SetupXX re-appear offering the same name bindings as<br>\npre-Isabelle2021\n* Their purpose is documented in the Guide.thy</p>\n</blockquote>\n</blockquote>\n<p>After having a second look, the story appears more delicate: there is<br>\nnot only Word_Setup_ARCH.thy, but also Word_Lemmas_ARCH.thy; while<br>\nWord_Lemmas_32.thy and Word_Lemmas_64.thy mimic each other, they contain<br>\nboth »generic« lemmas with same name like</p>\n<p>lemma word_bits_len_of:<br>\n \"len_of TYPE (32) = word_bits\"<br>\n by (simp add: word_bits_conv)</p>\n<p>vs.</p>\n<p>lemma word_bits_len_of:<br>\n \"len_of TYPE (64) = word_bits\"<br>\n by (simp add: word_bits_conv)</p>\n<p>and »specific« lemmas with differentiated name like</p>\n<p>lemma of_nat32_0:<br>\n \"\\&lt;lbrakk&gt;of_nat n = (0::word32); n &lt; 2 ^ word_bits\\&lt;rbrakk&gt;<br>\n\\&lt;Longrightarrow&gt; n = 0\"<br>\n by (erule of_nat_0, simp add: word_bits_def)</p>\n<p>vs.</p>\n<p>lemma of_nat64_0:<br>\n \"\\&lt;lbrakk&gt;of_nat n = (0::word64); n &lt; 2 ^ word_bits\\&lt;rbrakk&gt;<br>\n\\&lt;Longrightarrow&gt; n = 0\"<br>\n by (erule of_nat_0, simp add: word_bits_def)</p>\n<p>And none of them uses the »generic« type alias machine_word introduced<br>\nin the corresponding Word_Setup_ARCH.thy theory.</p>\n</blockquote>\n</blockquote>\n<p>lemmas that can be phrased with machine_word usually should be, so that would be an improvement.</p>\n<blockquote>\n<blockquote>\n<p>What is the state supposed to be achieved here?  Naively I would think<br>\nthat Word_Setup_ARCH.thy should contain all »generic« lemmas and make<br>\nuse of the »generic« type alias, whereas »specific« lemmas should stay in<br>\nWord_32 / Word_64.</p>\n</blockquote>\n</blockquote>\n<p>Yes, that would make sense and would clarify the setup. It is possible that some lemmas are not in the right place due to dependencies, but a lot of material has been generalised and moved into generic Word_Lemmas instead, so it is quite possible that this could now be applied consistently.</p>\n<p>Cheers,<br>\nGerwin<br>\n<a href=\"/user_uploads/14278/zjze8QM35WQonBd5OFWFEu4n/signature.asc\">signature.asc</a></p>",
        "id": 259767806,
        "sender_full_name": "Email Gateway",
        "timestamp": 1635654642
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Gerwin et. al.,</p>\n<p>I have arranged this now in</p>\n<p>isabelle: d1117655110c<br>\nafp: 0b1dccde39f0</p>\n<p>This his been my tentative last work on that before the upcoming release.</p>\n<p>Are there still issues I should look after?</p>\n<p>Cheers,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/BNirQlaAlDRaEDkm-pDzKYID/OpenPGP_signature\">OpenPGP_signature</a></p>",
        "id": 260255533,
        "sender_full_name": "Email Gateway",
        "timestamp": 1636024298
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:kleing@unsw.edu.au\">kleing@unsw.edu.au</a>&gt;<br>\nHi Florian,</p>\n<blockquote>\n<p>On 4 Nov 2021, at 22:11, Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt; wrote:<br>\n[..]<br>\nisabelle: d1117655110c<br>\nafp: 0b1dccde39f0</p>\n<p>This his been my tentative last work on that before the upcoming release.</p>\n<p>Are there still issues I should look after?</p>\n</blockquote>\n<p>There is nothing open on my list at least. The next step should probably be for me to get a bit deeper into at least one of the proof updates to flush out any remaining issues. Will report back when I have anything.</p>\n<p>Cheers,<br>\nGerwin<br>\n<a href=\"/user_uploads/14278/usjP6fEXOk0tt4qzuls4kQcX/signature.asc\">signature.asc</a></p>",
        "id": 260340040,
        "sender_full_name": "Email Gateway",
        "timestamp": 1636062907
    }
]