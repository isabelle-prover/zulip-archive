[
    {
        "content": "<p><strong>From:</strong> Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@cit.tum.de\">florian.haftmann@cit.tum.de</a>&gt;</p>\n<p>There is a reproducible break down in the build system:</p>\n<p><a href=\"https://build.proof.cit.tum.de/build?id=038ecd8c-6a3e-4e55-bacd-a455cf7f6b40\">https://build.proof.cit.tum.de/build?id=038ecd8c-6a3e-4e55-bacd-a455cf7f6b40</a></p>\n<p>A few weeks ago there was a similar break down.</p>\n<p>What is going on here?</p>\n<p>Thanks a lot,<br>\n    Florian</p>\n<p><a href=\"/user_uploads/14278/DKgCQ4OoTKzCCIqfW3ghE7Vw/OpenPGP_0xA707172232CFA4E9.asc\">OpenPGP_0xA707172232CFA4E9.asc</a><br>\n<a href=\"/user_uploads/14278/ZqtDiqNJy6pzHYGFUuBMeSH-/OpenPGP_signature.asc\">OpenPGP_signature.asc</a></p>",
        "id": 565826940,
        "sender_full_name": "Email Gateway",
        "timestamp": 1767124186
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 30/12/2025 20:49, Florian Haftmann wrote:</p>\n<blockquote>\n<p>There is a reproducible break down in the build system:</p>\n<p><a href=\"https://build.proof.cit.tum.de/build?id=038ecd8c-6a3e-4e55-bacd-a455cf7f6b40\">https://build.proof.cit.tum.de/build?id=038ecd8c-6a3e-4e55-bacd-a455cf7f6b40</a></p>\n</blockquote>\n<p>Thanks for the hint. I have now reset the database state of the build server.</p>\n<blockquote>\n<p>A few weeks ago there was a similar break down.</p>\n<p>What is going on here?<br>\nThere is some fragility in the design and/or implementation of the cluster. <br>\nRather soon, I need to sit down with Fabian Huch, to sort it out.</p>\n</blockquote>\n<p>Makarius</p>",
        "id": 566001220,
        "sender_full_name": "Email Gateway",
        "timestamp": 1767304065
    },
    {
        "content": "<p><strong>From:</strong> Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;</p>\n<p>Unfortunately the build system has hit the same problem again.</p>\n<p>Tobias</p>\n<p>On 01/01/2026 22:46, Makarius wrote:</p>\n<blockquote>\n<p>On 30/12/2025 20:49, Florian Haftmann wrote:</p>\n<blockquote>\n<p>There is a reproducible break down in the build system:</p>\n<p><a href=\"https://build.proof.cit.tum.de/build?id=038ecd8c-6a3e-4e55-bacd-a455cf7f6b40\">https://build.proof.cit.tum.de/build?id=038ecd8c-6a3e-4e55-bacd-a455cf7f6b40</a></p>\n</blockquote>\n<p>Thanks for the hint. I have now reset the database state of the build server.</p>\n<blockquote>\n<p>A few weeks ago there was a similar break down.</p>\n<p>What is going on here?<br>\nThere is some fragility in the design and/or implementation of the cluster. <br>\nRather soon, I need to sit down with Fabian Huch, to sort it out.</p>\n</blockquote>\n<p>Makarius<br>\n</p>\n</blockquote>\n<p><a href=\"/user_uploads/14278/KSuwvXdsxxluEuh54sLFdCbl/smime.p7s\">smime.p7s</a></p>",
        "id": 566031142,
        "sender_full_name": "Email Gateway",
        "timestamp": 1767341769
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 02/01/2026 09:15, Tobias Nipkow wrote:</p>\n<blockquote>\n<p>Unfortunately the build system has hit the same problem again.</p>\n</blockquote>\n<p>I have reset everything once more, and tried \"isabelle build_task -a\" <br>\nsuccessfully.</p>\n<p>Hopefully this is sufficient for the rest of the Christmas vacation. I will be <br>\nmostly unavailable at least until 07-Jan-2026.</p>\n<p>Makarius</p>",
        "id": 566101413,
        "sender_full_name": "Email Gateway",
        "timestamp": 1767388115
    },
    {
        "content": "<p><strong>From:</strong> Fabian Huch &lt;<a href=\"mailto:huch@in.tum.de\">huch@in.tum.de</a>&gt;</p>\n<p>There are two problems here:</p>\n<ul>\n<li>\n<p>the underlying problem is that the Isabelle/Scala process uses up a <br>\nlot more memory than it used to, causing OOM errors.</p>\n</li>\n<li>\n<p>the build infrastructure cannot handle build processes that have <br>\nabnormally terminated.</p>\n</li>\n</ul>\n<p>To address this, we can:</p>\n<p>(1) tune memory settings and investigate into why we're using up so much <br>\nmore JVM memory than before -- I'll look into that first.</p>\n<p>(2) Make the system more robust in the face of such problems. I need to <br>\nsit down with Makarius to discuss this.</p>\n<p>(3) Make the scheduling aware of memory limitations. The system was <br>\ndesigned such that this is possible, but it requires more work. I'll <br>\nwork on that once the immediate problems are solved.</p>\n<p>Fabian</p>\n<p>On 1/2/26 22:08, Makarius wrote:</p>\n<blockquote>\n<p>On 02/01/2026 09:15, Tobias Nipkow wrote:</p>\n<blockquote>\n<p>Unfortunately the build system has hit the same problem again.</p>\n</blockquote>\n<p>I have reset everything once more, and tried \"isabelle build_task -a\" <br>\nsuccessfully.</p>\n<p>Hopefully this is sufficient for the rest of the Christmas vacation. I <br>\nwill be mostly unavailable at least until 07-Jan-2026.</p>\n<p>Makarius</p>\n</blockquote>",
        "id": 566528723,
        "sender_full_name": "Email Gateway",
        "timestamp": 1767700021
    },
    {
        "content": "<p><strong>From:</strong> Fabian Huch &lt;<a href=\"mailto:huch@in.tum.de\">huch@in.tum.de</a>&gt;</p>\n<p>On 1/6/26 12:46, Fabian Huch wrote:</p>\n<blockquote>\n<p>There are two problems here:</p>\n<ul>\n<li>\n<p>the underlying problem is that the Isabelle/Scala process uses up a <br>\nlot more memory than it used to, causing OOM errors.</p>\n</li>\n<li>\n<p>the build infrastructure cannot handle build processes that have <br>\nabnormally terminated.</p>\n</li>\n</ul>\n<p>To address this, we can:</p>\n<p>(1) tune memory settings and investigate into why we're using up so <br>\nmuch more JVM memory than before -- I'll look into that first.</p>\n</blockquote>\n<p>I checked and tuned the system:</p>\n<ul>\n<li>\n<p>we had a rogue Isabelle process on one of the nodes that refused to <br>\nterminate, eating up ~30GiB of that machine's RAM</p>\n</li>\n<li>\n<p>I reduced the maximal number of concurrent jobs on our lower-memory <br>\nmachines (which have 64GiB each)</p>\n</li>\n</ul>\n<p>This worked fine for the past week; however the memory consumption of <br>\nthe JVM process is still abnormally high.</p>\n<p>Looking at memory snapshots of the build, one of the reasons is the <br>\nrecent incorporation of Node_Status into the progress: command_timings <br>\nare stored as</p>\n<p>command_timings:Map[Command, Command_Timings]</p>\n<p>and the command (in the key) contains large markups, e.g. in <br>\ninit_markups, during the lifetime of these timings: up to ~1GiB during <br>\nthe build of the distribution, likely significantly more in an AFP <br>\nbuild. I would propose to only keep the Document_ID.Command here, see <br>\nthe attached patch.</p>\n<p>Fabian</p>\n<p><a href=\"/user_uploads/14278/G_dlDv2UMhHWboCTV_8Af6-Z/node_status_memory.patch\">node_status_memory.patch</a></p>",
        "id": 567728843,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768300025
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 13/01/2026 11:26, Fabian Huch wrote:</p>\n<blockquote>\n<p>Looking at memory snapshots of the build, one of the reasons is the recent <br>\nincorporation of Node_Status into the progress: command_timings are stored as</p>\n<p>command_timings:Map[Command, Command_Timings]</p>\n<p>and the command (in the key) contains large markups, e.g. in init_markups, <br>\nduring the lifetime of these timings: up to ~1GiB during the build of the <br>\ndistribution, likely significantly more in an AFP build.<br>\nThanks for the measurements. I've already suspected a problem exactly there, <br>\nbut did not know how to do memory profiling on the JVM.</p>\n</blockquote>\n<p>Can you give some hints on how to do that?</p>\n<p>Makarius</p>",
        "id": 567756181,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768308926
    },
    {
        "content": "<p><strong>From:</strong> Fabian Huch &lt;<a href=\"mailto:huch@in.tum.de\">huch@in.tum.de</a>&gt;</p>\n<p>On 1/13/26 13:54, Makarius wrote:</p>\n<blockquote>\n<p>On 13/01/2026 11:26, Fabian Huch wrote:</p>\n<blockquote>\n<p>Looking at memory snapshots of the build, one of the reasons is the <br>\nrecent incorporation of Node_Status into the progress: <br>\ncommand_timings are stored as</p>\n<p>command_timings:Map[Command, Command_Timings]</p>\n<p>and the command (in the key) contains large markups, e.g. in <br>\ninit_markups, during the lifetime of these timings: up to ~1GiB <br>\nduring the build of the distribution, likely significantly more in an <br>\nAFP build.<br>\nThanks for the measurements. I've already suspected a problem exactly <br>\nthere, but did not know how to do memory profiling on the JVM.</p>\n</blockquote>\n<p>Can you give some hints on how to do that?</p>\n<p>I usually do this by analyzing multiple heap dumps of the JVM during the <br>\nrun. Those can be generated either from within the JVM, like so:</p>\n</blockquote>\n<p>def dump_heap(file: Path, include_live: Boolean =true): Unit = {<br>\n   val mxBean = java.lang.management.ManagementFactory.getPlatformMXBean(<br>\n     classOf[com.sun.management.HotSpotDiagnosticMXBean])<br>\n   mxBean.dumpHeap(file.absolute.implode, include_live)<br>\n}</p>\n<p>or by instructing the JVM from the outside, e.g. via 'jmap <br>\n-dump:format=b,file=heap.hprof &lt;pid&gt;'</p>\n<p>These heap dumps can then be analyzed with tools such as Eclipse MAT or <br>\nJProfiler, in particular by:</p>\n<ul>\n<li>\n<p>looking at histograms of object classes and their shallow heap <br>\nsize/retained heap size, e.g. here you see that command markups retain <br>\n~1GiB of heap:</p>\n</li>\n<li>\n<p>analyzing the memory graph through tree views, e.g. here you can see <br>\nwhat why the command markups are retained (there is a delayed event to <br>\nupdate the progress, where the largest Command key has ~16MiB init_markups):</p>\n</li>\n</ul>\n<p>However, I couldn't get MAT to ignore the weak references of our XML <br>\ncache (displayed as object with largest retained heap); this makes it <br>\nfar less useful here.</p>\n<p>Perhaps this is possible by tinkering with the options, but I don't know <br>\nhow -- I used to work with JProfiler, but that is commercial.</p>\n<p>Fabian</p>\n<p><a href=\"/user_uploads/14278/VIdYsJYWgmBej6qDdlGtpsi_/xVNQjnDCttesdZ9N.png\">xVNQjnDCttesdZ9N.png</a><br>\n<a href=\"/user_uploads/14278/CgNDCUOeHhb34CdrR_K4JamR/IWTyC0NJNa2j0viE.png\">IWTyC0NJNa2j0viE.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/14278/VIdYsJYWgmBej6qDdlGtpsi_/xVNQjnDCttesdZ9N.png\" title=\"xVNQjnDCttesdZ9N.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"702x495\" src=\"/user_uploads/thumbnail/14278/VIdYsJYWgmBej6qDdlGtpsi_/xVNQjnDCttesdZ9N.png/840x560.webp\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/14278/CgNDCUOeHhb34CdrR_K4JamR/IWTyC0NJNa2j0viE.png\" title=\"IWTyC0NJNa2j0viE.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1053x738\" src=\"/user_uploads/thumbnail/14278/CgNDCUOeHhb34CdrR_K4JamR/IWTyC0NJNa2j0viE.png/840x560.webp\"></a></div>",
        "id": 567782091,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768315508
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 13/01/2026 11:26, Fabian Huch wrote:</p>\n<blockquote>\n<p>Looking at memory snapshots of the build, one of the reasons is the recent <br>\nincorporation of Node_Status into the progress: command_timings are stored as</p>\n<p>command_timings:Map[Command, Command_Timings]</p>\n<p>and the command (in the key) contains large markups, e.g. in init_markups, <br>\nduring the lifetime of these timings: up to ~1GiB during the build of the <br>\ndistribution, likely significantly more in an AFP build. I would propose to <br>\nonly keep the Document_ID.Command here, see the attached patch.</p>\n</blockquote>\n<p>See now:</p>\n<p>changeset:   83825:3ed2781b1cc5<br>\nuser:        wenzelm<br>\ndate:        Wed Jan 14 13:09:47 2026 +0100<br>\nfiles:       src/Pure/PIDE/document_status.scala <br>\nsrc/Tools/jEdit/src/timing_dockable.scala<br>\ndescription:<br>\nmore frugal persistent data, notably for batch builds --- proposed by Fabian <br>\nHuch, after Java heap measurements (see also 3f6280aedbcc, a110e7e24e55, <br>\n9cc5d77d505c);</p>\n<p>It is your original change, with my explanation from the history. I've added a <br>\nfew more changes on top, but they don't make a fundamental difference.</p>\n<p>Note that I did not repeat any performance measurements. I want to do this <br>\neventually, also to see if other problems are present.</p>\n<p>Makarius</p>",
        "id": 568073274,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768422190
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 14/01/2026 21:22, Makarius wrote:</p>\n<blockquote>\n<p>See now:</p>\n<p>changeset:   83825:3ed2781b1cc5<br>\nuser:        wenzelm<br>\ndate:        Wed Jan 14 13:09:47 2026 +0100<br>\nfiles:       src/Pure/PIDE/document_status.scala src/Tools/jEdit/src/ <br>\ntiming_dockable.scala<br>\ndescription:<br>\nmore frugal persistent data, notably for batch builds --- proposed by Fabian <br>\nHuch, after Java heap measurements (see also 3f6280aedbcc, a110e7e24e55, <br>\n9cc5d77d505c);</p>\n<p>It is your original change, with my explanation from the history. I've added a <br>\nfew more changes on top, but they don't make a fundamental difference.</p>\n<p>Note that I did not repeat any performance measurements. I want to do this <br>\neventually, also to see if other problems are present.</p>\n</blockquote>\n<p>I have now done some measurements with \"isabelle build -o threads=8 -j2 -a -f\" <br>\non my Linux box (16 cores), using the included patch for the Isabelle/Scala <br>\nimplementation of \"isabelle build\".</p>\n<p>The Scala/Java process uses these settings:</p>\n<p>ISABELLE_TOOL_JAVA_OPTIONS=\"-Djava.awt.headless=true -Xms512m -Xmx4g <br>\n-Xss16m -XX:+UseZGC -XX:+ZGenerational -XX:SoftMaxHeapSize=2g\"</p>\n<p>Attached is raw data from the parent of 3ed2781b1cc5 (1), and from <br>\n3ed2781b1cc5 (2). The diagram.png is from gnuplot:</p>\n<p>plot '1.dat' using 1:2 smooth sbezier title \"1 heap_size\" noenhanced, <br>\n'1.dat' using 1:3 smooth sbezier title \"1 heap_used\" noenhanced, '2.dat' using <br>\n1:2 smooth sbezier title \"2 heap_size\" noenhanced, '2.dat' using 1:3 smooth <br>\nsbezier title \"2 heap_used\" noenhanced</p>\n<p>Conclusion: There is nothing interesting to be seen here. The change hardly <br>\nmakes a difference.</p>\n<p>It could mean that occurrences of Document_ID.Command and Command are in <br>\n1-to-1 correspondence on the heap, i.e. no stored Command is later updated/copied.</p>\n<p>Or it could mean that I've got something wrong in the experimental setup.</p>\n<p>Makarius</p>\n<p><a href=\"/user_uploads/14278/1RbinuCl2VNN0pAaYRhRgH7m/ch\">ch</a><br>\n<a href=\"/user_uploads/14278/m908CwFbPvEA554IT7QB-n6h/1.dat.xz\">1.dat.xz</a><br>\n<a href=\"/user_uploads/14278/iwSdvGOaElhobJcmNBTpfQWp/2.dat.xz\">2.dat.xz</a><br>\n<a href=\"/user_uploads/14278/GQFHuupDCnW7TkZeRqVcpr5s/diagram.png\">diagram.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/14278/GQFHuupDCnW7TkZeRqVcpr5s/diagram.png\" title=\"diagram.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1938x639\" src=\"/user_uploads/thumbnail/14278/GQFHuupDCnW7TkZeRqVcpr5s/diagram.png/840x560.webp\"></a></div>",
        "id": 568620662,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768689319
    },
    {
        "content": "<p><strong>From:</strong> Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;</p>\n<p>On 14/01/2026 21:22, Makarius wrote:</p>\n<blockquote>\n<p>See now:</p>\n<p>changeset:   83825:3ed2781b1cc5<br>\nuser:        wenzelm<br>\ndate:        Wed Jan 14 13:09:47 2026 +0100<br>\nfiles:       src/Pure/PIDE/document_status.scala src/Tools/jEdit/src/ <br>\ntiming_dockable.scala<br>\ndescription:<br>\nmore frugal persistent data, notably for batch builds --- proposed by Fabian <br>\nHuch, after Java heap measurements (see also 3f6280aedbcc, a110e7e24e55, <br>\n9cc5d77d505c);</p>\n<p>It is your original change, with my explanation from the history. I've added a <br>\nfew more changes on top, but they don't make a fundamental difference.</p>\n<p>Note that I did not repeat any performance measurements. I want to do this <br>\neventually, also to see if other problems are present.</p>\n</blockquote>\n<p>I have now done some measurements with \"isabelle build -o threads=8 -j2 -a -f\" <br>\non my Linux box (16 cores), using the included patch for the Isabelle/Scala <br>\nimplementation of \"isabelle build\".</p>\n<p>The Scala/Java process uses these settings:</p>\n<p>ISABELLE_TOOL_JAVA_OPTIONS=\"-Djava.awt.headless=true -Xms512m -Xmx4g <br>\n-Xss16m -XX:+UseZGC -XX:+ZGenerational -XX:SoftMaxHeapSize=2g\"</p>\n<p>Attached is raw data 1.dat from the parent of 3ed2781b1cc5, and 2.dat from <br>\n3ed2781b1cc5. The diagram.png is from gnuplot:</p>\n<p>plot '1.dat' using 1:2 smooth sbezier title \"1 heap_size\" noenhanced, <br>\n'1.dat' using 1:3 smooth sbezier title \"1 heap_used\" noenhanced, '2.dat' using <br>\n1:2 smooth sbezier title \"2 heap_size\" noenhanced, '2.dat' using 1:3 smooth <br>\nsbezier title \"2 heap_used\" noenhanced</p>\n<p>Conclusion: There is nothing interesting to be seen here. The change hardly <br>\nmakes a difference.</p>\n<p>It could mean that occurrences of Document_ID.Command and Command are in <br>\n1-to-1 correspondence on the heap, i.e. no stored Command is later updated/copied.</p>\n<p>Or it could mean that I've got something wrong in the experimental setup.</p>\n<p>Makarius</p>\n<p><a href=\"/user_uploads/14278/Ogkahrk14D2bH7PVWApZYykI/ch\">ch</a><br>\n<a href=\"/user_uploads/14278/Q1w5le9uXVDtgITW8Xt5BRA1/1.dat\">1.dat</a><br>\n<a href=\"/user_uploads/14278/qj0cTpWU_dUk5w0GqOLrYKFL/2.dat\">2.dat</a><br>\n<a href=\"/user_uploads/14278/dE9pydfWo5Bwzjo8v0MA-hnt/diagram.png\">diagram.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/14278/dE9pydfWo5Bwzjo8v0MA-hnt/diagram.png\" title=\"diagram.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1938x639\" src=\"/user_uploads/thumbnail/14278/dE9pydfWo5Bwzjo8v0MA-hnt/diagram.png/840x560.webp\"></a></div>",
        "id": 568666257,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768745583
    },
    {
        "content": "<p><strong>From:</strong> Fabian Huch &lt;<a href=\"mailto:huch@in.tum.de\">huch@in.tum.de</a>&gt;</p>\n<p>On 1/17/26 23:34, Makarius wrote:</p>\n<blockquote>\n<p>On 14/01/2026 21:22, Makarius wrote:</p>\n<blockquote>\n<p>See now:</p>\n<p>changeset:   83825:3ed2781b1cc5<br>\nuser:        wenzelm<br>\ndate:        Wed Jan 14 13:09:47 2026 +0100<br>\nfiles:       src/Pure/PIDE/document_status.scala src/Tools/jEdit/src/ <br>\ntiming_dockable.scala<br>\ndescription:<br>\nmore frugal persistent data, notably for batch builds --- proposed by <br>\nFabian Huch, after Java heap measurements (see also 3f6280aedbcc, <br>\na110e7e24e55, 9cc5d77d505c);</p>\n<p>It is your original change, with my explanation from the history. <br>\nI've added a few more changes on top, but they don't make a <br>\nfundamental difference.</p>\n<p>Note that I did not repeat any performance measurements. I want to do <br>\nthis eventually, also to see if other problems are present.</p>\n</blockquote>\n<p>I have now done some measurements with \"isabelle build -o threads=8 <br>\n-j2 -a -f\" on my Linux box (16 cores), using the included patch for <br>\nthe Isabelle/Scala implementation of \"isabelle build\".</p>\n<p>The Scala/Java process uses these settings:</p>\n<p>ISABELLE_TOOL_JAVA_OPTIONS=\"-Djava.awt.headless=true -Xms512m <br>\n-Xmx4g -Xss16m -XX:+UseZGC -XX:+ZGenerational -XX:SoftMaxHeapSize=2g\"</p>\n<p>Attached is raw data from the parent of 3ed2781b1cc5 (1), and from <br>\n3ed2781b1cc5 (2). The diagram.png is from gnuplot:</p>\n<p>plot '1.dat' using 1:2 smooth sbezier title \"1 heap_size\" <br>\nnoenhanced, '1.dat' using 1:3 smooth sbezier title \"1 heap_used\" <br>\nnoenhanced, '2.dat' using 1:2 smooth sbezier title \"2 heap_size\" <br>\nnoenhanced, '2.dat' using 1:3 smooth sbezier title \"2 heap_used\" <br>\nnoenhanced</p>\n<p>Conclusion: There is nothing interesting to be seen here. The change <br>\nhardly makes a difference.</p>\n<p>It could mean that occurrences of Document_ID.Command and Command are <br>\nin 1-to-1 correspondence on the heap, i.e. no stored Command is later <br>\nupdated/copied.</p>\n</blockquote>\n<p>Hm. I had measured a small number of samples (since heap snapshots are <br>\nexpensive and large) before and after the change and looked at the heap <br>\ncomposition. But it is possible that the (consistently) lower heap size <br>\nwas coincidental, and the extended lifetime of these Command markups did <br>\nnot actually matter -- I'll have to figure out how to properly deal with <br>\nour opaque cache in MAT.</p>\n<blockquote>\n<p>Or it could mean that I've got something wrong in the experimental setup.</p>\n</blockquote>\n<p>One problem with this experimental setup is that current heap size is <br>\nnot a good metric for such a high-throughput application (most memory <br>\nused would actually be dead).</p>\n<p>Also, the smoothing hides what is going on, e.g. when the heap limit is <br>\nhit (cf. plot for 1 below). I would rather use the MXBeans of the <br>\ngarbage collector to obtain GC events and plot a proper peak-to-peak curve.</p>\n<p>Fabian</p>\n<p><a href=\"/user_uploads/14278/7xL8T6sT35JVd39p0b67i27g/eY93XwRiR134kXXF.png\">eY93XwRiR134kXXF.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/14278/7xL8T6sT35JVd39p0b67i27g/eY93XwRiR134kXXF.png\" title=\"eY93XwRiR134kXXF.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"2048x735\" src=\"/user_uploads/thumbnail/14278/7xL8T6sT35JVd39p0b67i27g/eY93XwRiR134kXXF.png/840x560.webp\"></a></div>",
        "id": 568779055,
        "sender_full_name": "Email Gateway",
        "timestamp": 1768822125
    }
]