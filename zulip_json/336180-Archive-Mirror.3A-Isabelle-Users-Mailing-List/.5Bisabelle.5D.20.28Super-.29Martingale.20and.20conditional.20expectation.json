[
    {
        "content": "<p>From: Kawin Worrasangasilpa &lt;<a href=\"mailto:kw448@cam.ac.uk\">kw448@cam.ac.uk</a>&gt;<br>\nHi,</p>\n<p>I need to formalise some big results (see bound 1 in the attachment)<br>\nregarding probability proofs and the hardest part is to formlise some<br>\nconditional expectation and probability equations and inequalities (to<br>\nfinally define (super)martingales). I have used<br>\nProbability_Mass_Function.thy to formalise random variables I need in 'a<br>\npmf function form which is to define a measure space then use them with<br>\nfunctions to build random variables. However, I now get stuck and do not<br>\nknow how to proceed next to get conditional expectation on those random<br>\nvariables. So I would like to know if there is a simple or an efficient way<br>\nto get conditional expectation formalised from what I have?</p>\n<p>In more detail, from this two paragraphs (in full in attachement), and<br>\n\\lamda and \\mu are just function directly define recursively on any member<br>\nof {0,1}*,<br>\n[image: image.png]<br>\nI define n cion-tossings in two ways:<br>\n(<em>first way</em>)<br>\ndefinition w_n_pmf :: \"nat pmf\" where<br>\n \"w_n_pmf = map_pmf (λb. (if b then 1 else 0)) (bernoulli_pmf ((1-ε)/2))\"</p>\n<p>(<em>second way</em>)<br>\ndefinition Pi_pmf :: \"'a set ⇒ 'b ⇒ ('a ⇒ 'b pmf) ⇒ ('a ⇒ 'b) pmf\" where<br>\n  \"Pi_pmf A dflt p =<br>\n     embed_pmf (λf. if (∀x. x ∉ A ⟶ f x = dflt) then ∏x∈A. pmf (p x) (f x)<br>\nelse 0)\"<br>\n(*this is not my definition it is from Manuel Eberl's unpuplished work<br>\nPi_pmf.thy*)</p>\n<p>definition w_i_pmf :: \"nat ⇒ (nat ⇒ bool) pmf\" where \"w_i_pmf n = Pi_pmf<br>\n{..&lt;n} False (λ_. bernoulli_pmf ((1-ε)/2))\"</p>\n<p>definition w_pmf where \"w_pmf n = map_pmf (λf. map f [0..&lt;n]) (w_i_pmf n)\"</p>\n<p>then define<br>\n[image: image.png]<br>\nso I have it formalised as  Φ_n_pmf' as follows, (I drop details of rev_m<br>\nas not necessary here)</p>\n<p>definition Φ_n' :: \"nat ⇒ bool list ⇒ real\" where<br>\n  \"Φ_n' n l= (λp. real_of_int (fst p) + α * (real_of_int (min 0 (snd p))))<br>\n(rev_m (drop (size l - n) l)) + n * ε\"</p>\n<p>definition Φ_n_pmf' where<br>\n  \"Φ_n_pmf' n = map_pmf (λx. Φ_n' n x) (w_pmf n)\"</p>\n<p>So as you can see here I picked my second version of n coin-tossings to<br>\nformalise  Φ_n_pmf'.</p>\n<p>Final result I need to formalise is<br>\n[image: image.png]<br>\nI tried to dig in Conditional_Expectation.thy, but could not see how to<br>\nfomalise this yet while it took some time already, so I wonder if anyone<br>\nhas ever used it to formalise similar results?</p>\n<p>Regards,<br>\nKawin<br>\n<a href=\"/user_uploads/14278/5rVMTIGzBiccg9nbhg7kfUJt/image.png\">image.png</a><br>\n<a href=\"/user_uploads/14278/3yDdiFt7tCTRH8ao4iTY2SQO/image.png\">image.png</a><br>\n<a href=\"/user_uploads/14278/sI8JJdn0_iZaSd69JPaEy16d/image.png\">image.png</a><br>\n<a href=\"/user_uploads/14278/k1RCl-pa6dpkEBWIj6XOx4-l/Forkable-String-are-Rare.pdf\">Forkable String are Rare.pdf</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/14278/5rVMTIGzBiccg9nbhg7kfUJt/image.png\" title=\"image.png\"><img src=\"/user_uploads/14278/5rVMTIGzBiccg9nbhg7kfUJt/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/14278/3yDdiFt7tCTRH8ao4iTY2SQO/image.png\" title=\"image.png\"><img src=\"/user_uploads/14278/3yDdiFt7tCTRH8ao4iTY2SQO/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/14278/sI8JJdn0_iZaSd69JPaEy16d/image.png\" title=\"image.png\"><img src=\"/user_uploads/14278/sI8JJdn0_iZaSd69JPaEy16d/image.png\"></a></div>",
        "id": 294764823,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661201435
    },
    {
        "content": "<p>From: Andreas Lochbihler &lt;<a href=\"mailto:mail@andreas-lochbihler.de\">mail@andreas-lochbihler.de</a>&gt;<br>\nDear Kawin,</p>\n<p>First a few general hints:</p>\n<ol>\n<li>\n<p>There's the function cond_pmf that gives you the conditional distribution of a <br>\nprobability mass function.</p>\n</li>\n<li>\n<p>measure_pmf converts a pmf into a measure space where everything is measurable and <br>\nevents have the right probability. So you can use measure_pmf.expectation to talk about <br>\nthe expectation of a pmf.</p>\n</li>\n</ol>\n<p>I've had a quick look at the attached paper and I noticed that most definitions and proofs <br>\nare somewhat recursive over the length of the bitstring, in particular the margins. So IMO <br>\nit would make sense to mimick this recursion in the definitions, say like this:</p>\n<p>fun wn :: \"nat =&gt; bool list pmf\" where<br>\n   \"wn 0 = return_pmf []\"<br>\n| \"wn (Suc n) = map_pmf (#) (pair_pmf (bernoulli_pmf ((1-ε)/2)) (wn n))\"</p>\n<p>You can then define the generalized margin functions also by recursion:</p>\n<p>fun l :: \"bool list =&gt; int\" and m :: \"bool list =&gt; int\" where<br>\n   \"l [] = 0\"<br>\n| \"m [] = 0\"<br>\n| \"l (True # w) = l w + 1\"<br>\n| \"m (True # w) = m w + 1\"<br>\n| \"l (False # w) =<br>\n    (if l w &gt; m w &amp; m w = 0 then l w - 1 else if l w = 0 then 0 else l w - 1)\"<br>\n| \"m (False # w) = (if l w &gt; m w &amp; m w = 0 then 0 else m w - 1)\"</p>\n<p>Note that I am looking always at the character at the front rather than the back. So what <br>\nI've formalized is actually the margin of the reversed word. But for the purpose of the <br>\nanalysis, this should not matter. So you get the random variable</p>\n<p>definition Phi :: \"bool list =&gt; real\" where<br>\n   \"Phi w = real_of_int (l w) + alpha * real_of_int (min 0 (m w))\"</p>\n<p>I would not even define this as a probability distribution and instead always reason about</p>\n<p>\"map_pmf Phi (wn ...)\"</p>\n<p>explicitly. Then, you can express something like Delta_{t+1} as</p>\n<p>\"map_pmf (%w. Phi w - Phi (tl w)) (wn (t+1))\"</p>\n<p>I hope this helps a bit,<br>\nAndreas</p>",
        "id": 294764840,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661201444
    },
    {
        "content": "<p>From: Andreas Lochbihler &lt;<a href=\"mailto:mail@andreas-lochbihler.de\">mail@andreas-lochbihler.de</a>&gt;<br>\nDear Kawin,</p>\n<p>Thanks for providing the additional context. So here are my comments on the conditional <br>\nexpectations:</p>\n<p>E[X | Y = _] normally denotes a function that takes an outcome y in the range of the <br>\nrandom variable Y and then returns the expectation of the random variable conditioned on Y <br>\n= y. Now, we can also see consider this function as a measurable function itself, where y <br>\ncontributes its probability P[Y = y] to the expectation E[X | Y = y]. The theory <br>\nConditional_Expectation in HOL-Probability formalizes this idea, but the main proof effort <br>\nis to show that the result is again measurable. As you're working with pmf's, you <br>\nshouldn't have to worry about measurability. So unless you find some really important <br>\nlemmas in there, I'd recommend to directly define this as follows:</p>\n<p>Let p :: 'a pmf denote the underlying distribution of the joint random experiment. In your <br>\ncase, the distribution over strings (bool list). Further, assume that X and Y are random <br>\nvariables, i.e., X :: 'a =&gt; real and Y :: 'a =&gt; 'b for some 'b. Then, the conditional <br>\nexpectation is also a random variable given by</p>\n<p>definition cond_exp_pmf :: \"'a pmf ⇒ ('a ⇒ real) ⇒ ('a ⇒ 'b) ⇒ real pmf\" where<br>\n   \"cond_exp_pmf p X Y =<br>\n    map_pmf (λy. measure_pmf.expectation (cond_pmf p (Y -` {y})) X) (map_pmf Y p)\"</p>\n<p>Note that this is well-defined: cond_pmf requires the set (Y -` {y}) to have positive <br>\nprobability. This holds because y is drawn from \"map_pmf Y p\". Also note that you could <br>\nfold the two map_pmf's into one using the equality pmf.map_comp.</p>\n<p>In your case, you want to condition on many random variables Z_1, ..., Z_n. Since random <br>\nvariables have the form Z_i = map_pmf Y_i p for some underlying distribution p :: 'a pmf <br>\nand some function Y_i :: 'a =&gt; 'b_i, you can easily combine them into one joint random <br>\nvariable given by Y :: 'a =&gt; 'b_1 * 'b_2 * ... * b_n by Y a = (Y_1 a, Y_2 a, ..., Y_n a).</p>\n<p>So E[Phi_t+1 | Phi_1, ..., Phi_t] in your notation would be something like</p>\n<p>cond_exp_pmf (w_pmf (t + 1)) (Phi_n' (t + 1))<br>\n   (%w. (Phi_n' 0 w, Phi_n' 1 w, ..., Phi_n' t w))</p>\n<p>Of course, you can't write ... in Isabelle. This would have to be a proper recursive <br>\ndefinition, but I hope that it conveys the main idea.</p>\n<p>Best,<br>\nAndreas</p>",
        "id": 294764876,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661201462
    }
]