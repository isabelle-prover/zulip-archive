[
    {
        "content": "<p>From: Jason Gross &lt;<a href=\"mailto:jasongross9@gmail.com\">jasongross9@gmail.com</a>&gt;<br>\nThanks!  This is very interesting.  (And thanks all for sources.)</p>\n<p>I'm still digesting this, but have one question already:</p>\n<blockquote>\n<p>Clearly, we should use NbE/environment machines for evaluation, and<br>\nimplement conversion checking in the semantic domain.</p>\n</blockquote>\n<p>Does this mean that we can't be agnostic about whether or not we're<br>\nsupporting HoTT, because we either have to pick set theory/irrelevant<br>\nequality proofs or cubical (or some other model of HoTT) when normalizing<br>\nproofs of equality?</p>\n<blockquote>\n<p>I'd be very interested in your findings about proof assistant performance.</p>\n</blockquote>\n<p>I'd be happy to share once I have my thesis in a sufficiently ready state!<br>\nBroadly, the message of my thesis is that performance of<br>\n(dependently-typed) proof assistants / interactive theorem provers is an<br>\ninteresting area of research sorely in need of systematic study.  (My<br>\nthesis will also include some of the research work I've done, which can be<br>\nrendered as \"how to work around some of the asymptotics in Coq without<br>\nneeding to change the system\", but I think that's a bit less broadly<br>\ninteresting.)</p>\n<p>-Jason</p>\n<p>On Fri, May 8, 2020 at 4:55 AM András Kovács &lt;<a href=\"mailto:kovacsandras@inf.elte.hu\">kovacsandras@inf.elte.hu</a>&gt;<br>\nwrote:</p>\n<blockquote>\n<p>Hi Jason,</p>\n<p>You may be interested in my github repos: smalltt<br>\n&lt;<a href=\"https://github.com/AndrasKovacs/smalltt\">https://github.com/AndrasKovacs/smalltt</a>&gt;, normalization-bench<br>\n&lt;<a href=\"https://github.com/AndrasKovacs/normalization-bench\">https://github.com/AndrasKovacs/normalization-bench</a>&gt;. I haven't yet<br>\nupdated the smalltt repo, but there's a simplified implementation<br>\n&lt;<a href=\"https://gist.github.com/AndrasKovacs/a0e0938113b193d6b9c1c0620d853784\">https://gist.github.com/AndrasKovacs/a0e0938113b193d6b9c1c0620d853784</a>&gt;<br>\nof its evaluator, which seems to have roughly the same performance but<br>\nwhich is much simpler to implement.</p>\n<p>The basic idea is that in elaboration there are two primary computational<br>\ntasks, one is conversion checking and the other is generating solutions for<br>\nmetavariables. Clearly, we should use NbE/environment machines for<br>\nevaluation, and implement conversion checking in the semantic domain.<br>\nHowever, when we want to generate meta solutions, we need to compute<br>\nsyntactic terms, and vanilla NbE domain only supports quote/readback to<br>\nnormal forms. Normal forms are way too big and terrible for this purpose.<br>\nHence, we extend vanilla NbE domain with lazy non-deterministic choice<br>\nbetween two or more evaluation strategies. In the simplest case, the point<br>\nof divergence is whether we unfold some class of definitions or not. Then,<br>\nthe conversion checking algorithm can choose to take the full-unfolding<br>\nbranch, and the quoting operation can choose to take the non-unfolding<br>\nbranch. At the same time, we have a great deal of shared computation<br>\nbetween the two branches; we avoid recomputing many things if we choose to<br>\nlook at both branches.</p>\n<p>I believe that a feature like this is absolutely necessary for robust<br>\nperformance. Otherwise, we choke on bad asymptotics, which is surprisingly<br>\ncommon in dependent settings. In Agda and Coq, even something as trivial as<br>\nelaborating a length-indexed vector expression has quadratic complexity in<br>\nthe length of the vector.</p>\n<p>It is also extremely important to stick to the spirit of Coquand's<br>\nsemantic checking algorithm as much as possible. In summary: core syntax<br>\nshould support <em>no</em> expensive computation: no substitution, shifting,<br>\nrenaming, or other ad-hoc term massaging. Core syntax should be viewed as<br>\nimmutable machine code, which supports evaluation into various semantic<br>\ndomains, from which sometimes we can read syntax back; this also leaves it<br>\nopen to swap out the representation of core syntax to efficient<br>\nalternatives such as bytecode or machine code.</p>\n<p>Only after we get  the above two basic points right, can we start to think<br>\nabout more specific and esoteric optimizations. I am skeptical of proposed<br>\nsolutions which do not include these. Hash consing has been brought up many<br>\ntimes, but it is very unsatisfying compared to non-deterministic NbE,<br>\nbecause of its large constant costs, implementation complexity, and the<br>\nfailure to handle sharing loss from beta-redexes in any meaningful way<br>\n(which is the most important source of sharing loss!). I am also skeptical<br>\nof exotic evaluators such as interaction nets and optimal beta reducers;<br>\nthere is a good reason that all modern functional languages run on<br>\nenvironment machines instead of interaction nets.</p>\n<p>If we want to support type classes, then tabled instance resolution<br>\n&lt;<a href=\"https://arxiv.org/pdf/2001.04301.pdf\">https://arxiv.org/pdf/2001.04301.pdf</a>&gt; is also a must, otherwise we are<br>\nagain smothered by bad asymptotics even in modestly complex class<br>\nhierarchies. This can be viewed as a specific instance of hash-consing (or<br>\nrather  \"memoization\"), so while I think ubiquitous hash-consing is bad,<br>\nsome focused usage can do good.</p>\n<p>Injectivity analysis is another thing which I believe has large potential<br>\nimpact. By this I mean checking whether functions are injective up to<br>\ndefinitional equality, which is decidable, and can be used to more<br>\nprecisely optimize unfolding in conversion checking.</p>\n<p>I'd be very interested in your findings about proof assistant performance.<br>\nThis has been a topic that I've been working on on-and-off for several<br>\nyears. I've recently started to implement a system which I intend to be<br>\neventually \"production strength\" and also as fast as possible, and<br>\nnaturally I want to incorporate existing performance know-how.</p>\n<p>Jason Gross &lt;<a href=\"mailto:jasongross9@gmail.com\">jasongross9@gmail.com</a>&gt; ezt írta (időpont: 2020. máj. 8., P,<br>\n0:20):</p>\n<blockquote>\n<p>I'm in the process of writing my thesis on proof assistant performance<br>\nbottlenecks (with a focus on Coq).  I'm having some trouble finding prior<br>\nwork on performance engineering and/or benchmarking of proof assistants<br>\n(other than the paper on the Lean tactic language (<br>\n<a href=\"https://leanprover.github.io/papers/tactic.pdf\">https://leanprover.github.io/papers/tactic.pdf</a>)), and figured I'd reach<br>\nout to these lists.</p>\n<p>Does anyone have references for prior work on performance analysis or<br>\nengineering of proof assistants or dependently typed languages?  (Failing<br>\nthat, I'd also be interested in papers about compile-time performance of<br>\ncompilers.)</p>\n<blockquote>\n<p>Thanks,<br>\nJason</p>\n</blockquote>\n<hr>\n<p>Agda mailing list<br>\n<a href=\"mailto:Agda@lists.chalmers.se\">Agda@lists.chalmers.se</a><br>\n<a href=\"https://lists.chalmers.se/mailman/listinfo/agda\">https://lists.chalmers.se/mailman/listinfo/agda</a></p>\n</blockquote>\n</blockquote>",
        "id": 294829009,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661245725
    }
]