[
    {
        "content": "<p>From: Gottfried Barrow &lt;<a href=\"mailto:igbi@gmx.com\">igbi@gmx.com</a>&gt;<br>\nHi,</p>\n<p>I saw 64-bit Cygwin talked about, so I send this in to show that 64-bit <br>\nJava for Cygwin would be beneficial for some things.</p>\n<p>Basically, I've been testing a lot of different languages for a <br>\nrecursive fibonacci function of this form, for a input value of 42:</p>\n<p>fun fib (n:int) = (if (n &lt; 2) then n else (fib(n - 1) + fib(n - 2)));</p>\n<p>What I can say is that Scala is fast, and most everything else is slow <br>\nin comparison to it, though several things have to be taken into <br>\nconsideration, such as whether a language needs to be compile, and <br>\nwhether the integers are machine integers or big integers.</p>\n<p>The crux of this email is that for Clojure, for 32-bit Java under Cygwin <br>\nor Windows, takes about 48 seconds for fib(42), where for 64-bit Java, <br>\nit's about 8 seconds, which is actually not that bad compared to other <br>\nlanguages.</p>\n<p>For Isabelle/ML, fib(42) is about 4.3 seconds, though it's using big <br>\nintegers.</p>\n<p>For Scala, it's about 2.7 seconds, and the version of Java doesn't make <br>\nmuch difference.</p>\n<p>For compiled Haskell, it's about 37 seconds.</p>\n<p>For compiled Erlang, it's about 16 seconds for a pattern matched form of <br>\nfib, and 36 seconds for the if/then form.</p>\n<p>For Julia, which is supposed to be fast, it was about 5 seconds.</p>\n<p>For Mirah, which has syntax like Ruby, but is just a frontend on Java, <br>\nit was a little slower than Scala.</p>\n<p>I saw Lisp SBCL, but I don't know how to compile a lisp program with it, <br>\nbut <a href=\"http://benchmarksgame.alioth.debian.org\">http://benchmarksgame.alioth.debian.org</a> shows that it should be <br>\nabout as fast as Scala.</p>\n<p>Many of these numbers look somewhat like what the benchmarks site shows, <br>\nother than Haskell.</p>\n<p>I've seen a pattern emerging for me: define a datatype, then define a <br>\nfun using recursion and pattern matching for the datatype, and then do a <br>\nfew calculations with the fun before proving anything.</p>\n<p>Up front, I want to know if it works, and also I'd like to know if it's <br>\na major loser as far as speed. A language doesn't have to be the fastest <br>\nto test that out, but if it's dramatically slower than Scala, then <br>\nthat's a bad road to start down.</p>\n<p>I've gotten the reject twice by the mail server, first because the <br>\nattachment was too big, and the second, with a smaller attachment, <br>\nprobably because of the first reject. I guess Gmx is used a lot for <br>\nspam. I'll see how this one goes, but it's worth a try to put some <br>\nexposure on the possibility of 64-bit Cygwin being used. I might be <br>\nauto-banned by the auto-spam-filter-bot, which wouldn't be a bad thing.</p>\n<p>Regards,<br>\nGB</p>",
        "id": 294277769,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919342
    },
    {
        "content": "<p>From: Gottfried Barrow &lt;<a href=\"mailto:igbi@gmx.com\">igbi@gmx.com</a>&gt;<br>\nKnowing nothing about concurrency, naively, this looks to me like it <br>\nwould be a perfect candidate, since there are two calls to fib.</p>\n<p>It bugs me that when calculating fib(42), the Java process only works <br>\n25% of my CPU.</p>\n<p>Anyway, this idea makes it a higher precedence to use a language that <br>\nfacilitates concurrency, like Scala, Clojure, and Erlang, though <br>\ncompiled Erlang is twice as slow as Clojure.</p>\n<p>Regards,</p>",
        "id": 294277783,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919348
    },
    {
        "content": "<p>From: Gottfried Barrow &lt;<a href=\"mailto:igbi@gmx.com\">igbi@gmx.com</a>&gt;<br>\nComplex things aren't that straightforward, and require talking to <br>\noneself more than one would like.</p>\n<p>With Scala, using BigInt, it takes 77s, and with Clojure using bigint, <br>\nit takes 21s. That assumes that things are doing what I think I've told <br>\nthem to do, which means one should do one's own tests. I thought I had <br>\nread that Erlang's default integer is a machine integer, but maybe I'm <br>\nreading now that it's of arbitrary size, which means, at 16s, it would <br>\nbe faster than Clojure, and arbitrary size integers is what I'd be <br>\nusing. Clojure actually doesn't make you pick; it chooses what works <br>\nbest. With Clojure, it's a 3megabyte jar to get the language. With <br>\nErlang, it's a 90megabyte install.</p>\n<p>Regards,<br>\nGB</p>",
        "id": 294277813,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919360
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Thu, 15 May 2014, Gottfried Barrow wrote:</p>\n<blockquote>\n<p>On 14-05-15 11:23, Gottfried Barrow wrote:</p>\n<blockquote>\n<p>fun fib (n:int) = (if (n &lt; 2) then n else (fib(n - 1) + fib(n - 2)));</p>\n</blockquote>\n<p>Knowing nothing about concurrency, naively, this looks to me like it <br>\nwould be a perfect candidate, since there are two calls to fib.</p>\n</blockquote>\n<p>This kind of example is generally called \"micro benchmark\".  It is fun to <br>\nplay with it, but hardly relevant in practice.  There are so many <br>\nside-conditions to take into account in a real application, to say if it <br>\nis fast or not.  E.g. proper integer arithmetic depends on the libray that <br>\ndoes that in the background, while machine integers are not integers at <br>\nall.</p>\n<p>Just from the parallelization standpoint, the above is relatively <br>\ndifficult to get performance from, and not just heat up all cores to give <br>\nyou a warm feeling.  You would have to do quite smart organization of the <br>\nevaluation.  Some language frameworks try to do that for you, but in <br>\ngeneral you have to do it yourself -- again depending on many <br>\nside-conditions of the overall application.</p>\n<blockquote>\n<p>It bugs me that when calculating fib(42), the Java process only works <br>\n25% of my CPU.</p>\n</blockquote>\n<p>Here is a version for Isabelle/ML that uses approx. 0% of CPU:</p>\n<p>ML {*<br>\n   fun fib2 f0 f1 n = if n = 1 then f1 else fib2 f1 (f0 + f1) (n - 1);<br>\n   fun fib n = if n = 0 then 1 else fib2 0 1 n;<br>\n*}</p>\n<p>See also <br>\n<a href=\"http://www.cs.northwestern.edu/academics/courses/110/html/fib_rec.html\">http://www.cs.northwestern.edu/academics/courses/110/html/fib_rec.html</a> <br>\nwhich happened to be the first page Google spit out on this well-known <br>\nexercise for freshmen.</p>\n<p>To keep this on-track for isabelle-users, I propose that you make a small <br>\nformalization in Isabelle/HOL to relate the two implementations.</p>\n<p>Makarius</p>",
        "id": 294277861,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919373
    },
    {
        "content": "<p>From: Gottfried Barrow &lt;<a href=\"mailto:igbi@gmx.com\">igbi@gmx.com</a>&gt;<br>\nOn 14-05-16 09:35, Makarius wrote:</p>\n<blockquote>\n<p>This kind of example is generally called \"micro benchmark\".  It is fun <br>\nto play with it, but hardly relevant in practice.</p>\n</blockquote>\n<p>I use this to summarize, because things got long, and the long <br>\nexplanation is below.</p>\n<p>The fibonacci test is actually 100% relevant to trying to set myself up, <br>\nin the future, for evaluating how practical it is to use recursive <br>\nfunctions.</p>\n<p>This would be a very relevant test for numeric computation, and that's <br>\nwhat I plan on doing in the future.</p>\n<p>A starting point is to try to and find as many languages that perform <br>\ngood with recursive functions that use pattern matching. If a recursive <br>\nfibonacci function isn't relevant, then why is Isabelle/HOL filled with <br>\nimpractical recursive functions?</p>\n<p>It is important, at least to me, to know how practical any particular <br>\nrecursive function is. The fibonacci function would be one of the worst, <br>\nbut how can I know how bad it is if I don't find the best possible <br>\nlanguage to run it under? \"Best possible\" is related to how I'm <br>\nimplementing mathematics in HOL.</p>\n<p>Recursive functions will be at the very core of what I'm doing in HOL. I <br>\nwant to set myself up to be able to determine what they can and can't do.</p>\n<p>Here, you would be playing the part of the person in Mathematics <br>\nWhatever 101, saying, \"Why are we doing this? Where will we ever use <br>\nthis?\" The application isn't always direct.</p>\n<p>That would be one side of the coin. You're looking at the other side, <br>\nand you don't know exactly what I'm up to, so it's forgivable.</p>\n<blockquote>\n<p>On 14-05-15 11:23, Gottfried Barrow wrote:</p>\n<blockquote>\n<blockquote>\n<p>fun fib (n:int) = (if (n &lt; 2) then n else (fib(n - 1) + fib(n - 2)));<br>\nThis kind of example is generally called \"micro benchmark\".  It is fun <br>\nto play with it, but hardly relevant in practice.  There are so many <br>\nside-conditions to take into account in a real application, to say if <br>\nit is fast or not.  E.g. proper integer arithmetic depends on the <br>\nlibray that does that in the background, while machine integers are <br>\nnot integers at all.</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>So a basic tool of rhetoric is to anticipate arguments. That would be <br>\npart of the logos, pathos, and ethos of Greek rhetoric, but 6 point <br>\narguments on mailing lists tend to not get read, or read any where.</p>\n<p>There's more that you could teach me than not teach me, but here it did <br>\noccur to me, before I forgot about it, to make a comment about the <br>\nnarrowness of what I'm doing.</p>\n<p>The context is the prolific use, by many, of using recursive functions <br>\nthat use pattern matching in Isabelle/HOL.</p>\n<p>I know that recursive functions are bad performers, and recursive <br>\nfunctions with pattern matching are even worse. I've become a follower <br>\nof the HOL crowd. I use recursion and pattern matching, and my <br>\ninclination is to use it as a first choice over if/then/else.</p>\n<p>Consequently, my picking the fibonacci function is totally relevant to <br>\ntesting languages to see how they perform under worst case conditions. <br>\nIt is a micro benchmark, but it's the one single test to test languages <br>\nfor what's on my mind, the use of recursive functions in HOL, and how <br>\nthey will play out when trying to run them with a programming language.</p>\n<p>There's always more context than can be explained. What I'm doing is <br>\n\"the big pursuit of all fast, probably functional, programming languages <br>\nthat sync up good with how I implement logic in HOL.\" That language is <br>\nactually ML, but for some reason, I think I need another one in addition <br>\nto it.</p>\n<p>It's very time consuming. I find a language. I look at the docs on the <br>\nweb to try to determine if it has the basic requirements, which is the <br>\nability to curry or do partial application, pattern matching, and the <br>\nability to define datatypes. I download it. I figure out how to write <br>\nthe fibonocci function. I try to find out what kind of integers it's <br>\nusing by default. I time it multiple times. More.</p>\n<blockquote>\n<p>There are so many side-conditions to take into account in a real <br>\napplication, to say if it is fast or not. </p>\n</blockquote>\n<p>I did mention that it can be hard to know if a test is meaningful. If <br>\nI'm trying to test 20 languages, it's not that I know that I proved <br>\nsomething is slow, but fast generally always means something, especially <br>\nafter I've started to see some patterns emerging, like that out of 20 <br>\nlanguages, none of them run faster than about 6 seconds for fib(42), and <br>\nthat ML is performing the best, at about 4.5 seconds.</p>\n<p>I give two examples where I got mislead. I judged Scala as fast, and was <br>\nusing it as a benchmark, but when I switched to big integers, it got <br>\nreally slow.</p>\n<p>I judged JRuby really slow, but when I switch to running it under 64-bit <br>\nJava, fib(42) went from 51s to 23s, whee 23s isn't that bad relative to <br>\nwhat I've seen</p>\n<p>I just got through installing Rust. It fit that pattern of being a <br>\ncompiled language that's better than most, but not better than ML. It <br>\nran fib(42) at about 6 seconds, which is good.</p>\n<p>The big question is always whether a language is using machine integers <br>\nor big integers. If I know that a language is using machine integers, <br>\nand it runs at fib(42) at 6 seconds, that's alright, but not that <br>\nimpressive, since ML uses arbitrary size ints, though it could be <br>\noptimizing, by using machine ints until it needs big ints.</p>\n<p>I have to make the best possible conclusions given a limited amount of <br>\ntime. Isabelle/ML was #2 as the benchmark until I saw that Scala when <br>\nfrom 2.7s to about 70s, so now ML is the benchmark, and it helps me <br>\nsomething to compare other languages to.</p>\n<blockquote>\n<blockquote>\n<p>It bugs me that when calculating fib(42), the Java process only works <br>\n25% of my CPU.</p>\n</blockquote>\n<p>Here is a version for Isabelle/ML that uses approx. 0% of CPU:</p>\n</blockquote>\n<p>The anticipation of arguments would have saved us some time. I already <br>\nhad 3 other fast fibonacci functions.</p>\n<p>If Ruby is fast at three out of 4 fibonacci functions, does that make <br>\nRuby fast? No, it's slow, though like I say, it wasn't as slow as I thought.</p>\n<blockquote>\n<p>See also <br>\n<a href=\"http://www.cs.northwestern.edu/academics/courses/110/html/fib_rec.html\">http://www.cs.northwestern.edu/academics/courses/110/html/fib_rec.html</a> <br>\nwhich happened to be the first page Google spit out on this well-known <br>\nexercise for freshmen.</p>\n</blockquote>\n<p>Am I insulted? I'm always insulted, but I control myself, and I <br>\nunderstand that I'm a freshman in the big ocean of life on the terra firma.</p>\n<blockquote>\n<p>To keep this on-track for isabelle-users, I propose that you make a <br>\nsmall formalization in Isabelle/HOL to relate the two implementations.</p>\n</blockquote>\n<p>I thought it was somewhat on track. I've shown an example that 32-bit <br>\nJava can be up to 6x slower than 64-bit Java, so 64-bit Java would be a <br>\ngood reason to try and get 64-bit Cygwin going, not that I expect that. <br>\nMany times I've assumed that there's not a real benefit to 32-bit <br>\nprograms, but I've shown there is.</p>\n<p>Regards,<br>\nGB</p>",
        "id": 294277883,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919379
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Fri, 16 May 2014, Gottfried Barrow wrote:</p>\n<blockquote>\n<p>The big question is always whether a language is using machine integers <br>\nor big integers. If I know that a language is using machine integers, <br>\nand it runs at fib(42) at 6 seconds, that's alright, but not that <br>\nimpressive, since ML uses arbitrary size ints, though it could be <br>\noptimizing, by using machine ints until it needs big ints.</p>\n</blockquote>\n<p>Yes, this is the rather obvious thing that David Matthews is doing here <br>\nfor decades.  I always wondered why that is not done everywhere, until <br>\nsome years ago some knowledable people explained to me the reason: <br>\ncompatibility with the C programming model.</p>\n<p>So C is the reason for Java bigints being so slow, because they are always <br>\nbig, even for small numbers.</p>\n<blockquote>\n<blockquote>\n<p>To keep this on-track for isabelle-users, I propose that you make a small<br>\n formalization in Isabelle/HOL to relate the two implementations.</p>\n</blockquote>\n<p>I thought it was somewhat on track. I've shown an example that 32-bit <br>\nJava can be up to 6x slower than 64-bit Java, so 64-bit Java would be a <br>\ngood reason to try and get 64-bit Cygwin going, not that I expect that. <br>\nMany times I've assumed that there's not a real benefit to 32-bit <br>\nprograms, but I've shown there is.</p>\n</blockquote>\n<p>That is actually in the center of isabelle-users in a technical sense: we <br>\nhave this mix of supported platforms (Linux, Windows, Mac OS X) and <br>\nprogramming language environments (e.g. Poly/ML, Scala/JVM, certain <br>\nC-implemented tools on Cygwin).</p>\n<p>So what is the best adjustment of the 32 vs. 64bit switch?  The answer <br>\ndepends on many side-conditions.</p>\n<p>For the Prover IDE a 64bit JVM could actually be beneficial, but it is not <br>\nused on Windows due to some other side-conditions.  64-bit Cygwin is <br>\nunrelated to that, because it is Windows-Java not Cygwin-Java.</p>\n<blockquote>\n<p>From the subject of your initial mail, I was actually expecting some <br>\nproblem report that PIDE no longer works on your machine with only 32-bit <br>\nJava.  The micro-benchmarks are a rather relaxing contrast to that <br>\nprospect.</p>\n</blockquote>\n<p>Makarius</p>",
        "id": 294277896,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919385
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Fri, 16 May 2014, Gottfried Barrow wrote:</p>\n<blockquote>\n<p>A starting point is to try to and find as many languages that perform <br>\ngood with recursive functions that use pattern matching.</p>\n</blockquote>\n<p>You should look in the vicinity of ML and Haskell.  The latter is <br>\nparticularly well-known to beat most other languages in the usual <br>\nbenchmarks.</p>\n<blockquote>\n<p>If a recursive fibonacci function isn't relevant, then why is <br>\nIsabelle/HOL filled with impractical recursive functions?</p>\n</blockquote>\n<p>There is nothing impractical about recursion.  The slowness of the naive <br>\nfibonacci implementation is caused by the non-linearity of the invocation, <br>\nwhich causes an exponential blowup.  But the slightly tuned linear <br>\nimplementation demonstrates that the complexity is actually not there.</p>\n<p>What is nice about a mathematical language like Isabelle/HOL is that you <br>\ndon't have to care about complexity.  You just do symbolic reasoning, and <br>\nyou can e.g. make some equivalence proof of a term that represents the <br>\nnaive implementation to the tuned one.  Then you give the latter to the <br>\ncode generator to run it on the machine.</p>\n<blockquote>\n<p>I know that recursive functions are bad performers, and recursive functions <br>\nwith pattern matching are even worse.</p>\n</blockquote>\n<p>This was disproven in the 1980s or so, when the first efficient <br>\nimplementations of ML came about.  Recursion without pattern matching was <br>\nalready known to be efficient much earlier, in the olden days of LISP.</p>\n<p>It is just due to technical accidents in C or Java that these guys are <br>\nstill lagging begind some decades.  The Scala guys have to play a lot of <br>\nfunny tricks to cope with the tiny constant-sized stack on the JVM and <br>\nlack of tail recursion.</p>\n<p>In Poly/ML you can be relaxed about this, and allocate hundreds of MB or <br>\nsome GB of stack without too much worrying, or no stack at all if written <br>\nslightly differently.  But the art of tail-call optimization is often <br>\nirrelevant these days.</p>\n<p>Makarius</p>",
        "id": 294277917,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919391
    },
    {
        "content": "<p>From: Gottfried Barrow &lt;<a href=\"mailto:igbi@gmx.com\">igbi@gmx.com</a>&gt;<br>\nRichard,</p>\n<p>Thanks for the info from James McDonald. I was confused about SBCL. I <br>\nhad installed it, but I thought the instructions on how to build it was <br>\npart of what to do to compile a script. When sorting through 20 <br>\nlanguages, unfamiliarity and some resistance can cause me to abandon <br>\ntesting a language out.</p>\n<p>This worked out better, because I hadn't downloaded the newest version <br>\nfor Windows.</p>\n<p>With SBCL on Windows, with the default options, I get 5.6 seconds for <br>\nfixnum, and 9.8 seconds for integer. I'm running a 2.8GHz old quad core, <br>\nwhere it only utilizes 25% of the cpu when it's running the program.</p>\n<p>Where SBCL really separates itself is with big integers, because fib(42) <br>\nis only 4807526976. That wasn't forcing these other languages to use <br>\nnon-machine integers, the ones that don't make you choose. I say more <br>\nabout that in my reply to Makarius.</p>\n<p>Regards,<br>\nGB</p>",
        "id": 294277936,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919397
    },
    {
        "content": "<p>From: Richard Waldinger &lt;<a href=\"mailto:waldinger@AI.SRI.COM\">waldinger@AI.SRI.COM</a>&gt;<br>\nfrom jim mcdonald (cc-ed):</p>",
        "id": 294278003,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919407
    },
    {
        "content": "<p>From: James McDonald &lt;<a href=\"mailto:mcdonald@kestrel.edu\">mcdonald@kestrel.edu</a>&gt;<br>\n[re-sending from jlm—-r]</p>\n<p>More generally, if you are really trying to benchmark various languages and implementations,<br>\nyou might want to consider a broader suite of tests.   E.g., within the lisp world, you could<br>\nlook at Dick Gabriel’s “Performance and Evaluation of Lisp Systems”  from around 1985.<br>\n(<a href=\"http://www.dreamsongs.com/NewFiles/Timrep.pdf\">http://www.dreamsongs.com/NewFiles/Timrep.pdf</a>)</p>\n<p>In particular, if your focus is on function call overhead, the TAK and PUZZLE tests might<br>\nbe of interest, including the variants that move things around to account for cache lines.</p>\n<p>jlm</p>",
        "id": 294278012,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919410
    },
    {
        "content": "<p>From: Gottfried Barrow &lt;<a href=\"mailto:igbi@gmx.com\">igbi@gmx.com</a>&gt;<br>\nOn 14-05-17 18:25, James McDonald wrote:</p>\n<blockquote>\n<p>More generally, if you are really trying to benchmark various <br>\nlanguages and implementations,<br>\nyou might want to consider a broader suite of tests.   E.g., within <br>\nthe lisp world, you could<br>\nlook at Dick Gabriel’s “Performance and Evaluation of Lisp Systems” <br>\n from around 1985.<br>\n(<a href=\"http://www.dreamsongs.com/NewFiles/Timrep.pdf\">http://www.dreamsongs.com/NewFiles/Timrep.pdf</a>)</p>\n</blockquote>\n<p>James (and Makarius below),</p>\n<p>Thanks for the specific optimizations. Right now, I'm doing rough <br>\ncomparisons between languages, but all that could come in handy if I go <br>\nthe Lisp route, and I'm not seeing anything other than the Lisps that <br>\ndon't tend to get slaughtered by big integers, though Lisp may get <br>\nslaughtered in other ways. I wouldn't know.</p>\n<p>And thanks for the PDF link also. I used the TAK test out of it, since <br>\nit was short and easy.</p>\n<p>I show times for Isabelle/ML, Haskell, SBCL, Clojure, Scala, and JRuby, <br>\nthree of them with both a 32-bit and 64-bit version. At least for the <br>\nthree tests, SBCL comes out ahead overall. Enough to warrant more <br>\nlooking in to.</p>\n<p><a href=\"http://github.com/gc44/prelim/tree/master/1400/1405A_bigint_prog_lang_perf_tests\">http://github.com/gc44/prelim/tree/master/1400/1405A_bigint_prog_lang_perf_tests</a></p>\n<p>On 14-05-16 15:44, Makarius wrote:</p>\n<blockquote>\n<p>On Fri, 16 May 2014, Gottfried Barrow wrote:</p>\n<blockquote>\n<p>A starting point is to try to and find as many languages that perform <br>\ngood with recursive functions that use pattern matching.<br>\nYou should look in the vicinity of ML and Haskell.  The latter is <br>\nparticularly well-known to beat most other languages in the usual <br>\nbenchmarks.</p>\n</blockquote>\n</blockquote>\n<p>This is where it pays to sometimes do my own tests. I've searched <br>\nmultiple times to get comparisons between Scala and Haskell. I've read <br>\nrepeatedly, and seen on the benchmark sites, that Haskell is comparable, <br>\nbut a little slower than Scala.</p>\n<p>Obviously, they're not talking about the Windows 32-bit version, because <br>\nit's slow. Not a little slow, but a lot slow, relative to my own limited <br>\ntests. I show that on pages at the link above.</p>\n<blockquote>\n<blockquote>\n<p>If a recursive fibonacci function isn't relevant, then why is <br>\nIsabelle/HOL filled with impractical recursive functions?<br>\nThere is nothing impractical about recursion.  The slowness of the <br>\nnaive fibonacci implementation is caused by the non-linearity of the <br>\ninvocation, which causes an exponential blowup. </p>\n</blockquote>\n</blockquote>\n<p>But surely blowups are good for stress tests.</p>\n<blockquote>\n<blockquote>\n<p>I know that recursive functions are bad performers, and recursive <br>\nfunctions with pattern matching are even worse.<br>\nThis was disproven in the 1980s or so, when the first efficient <br>\nimplementations of ML came about.  Recursion without pattern matching <br>\nwas already known to be efficient much earlier, in the olden days of <br>\nLISP.</p>\n</blockquote>\n</blockquote>\n<p>I believe you, but \"implementation\" is the key word, where <br>\n\"implementation\" is on my mind only because some Stackoverflow answerer <br>\nwas making sure everyone knows that languages aren't slow, but <br>\nimplementations are slow. Coming from that guy it was very irritating. <br>\nComing from me, it's profound.</p>\n<p>I've been doing two things on multiple languages. Running the if/then <br>\nform of the fibonacci function, and then hunting down how to do it with <br>\npattern matching. Most of the time, pattern matching has been slower.</p>\n<p>It was even slower for Haskell. I'm looking right now at where I put the <br>\ntime in filenames, that it was 36s for if/then/else, and 51s for pattern <br>\nmatching. But the Windows 32-bit version of HaskellPlatform is slow. <br>\nIt's messed up, so that may not mean anything. I check these things <br>\nmultiple times, and want to check them again, because it's easy to get <br>\nconfused in all the details.</p>\n<p>With Erlang, on the other hand, it was significantly faster with pattern <br>\nmatching. I don't think they even have a normal if/then/else statement.</p>\n<p>I want as much speed as possible, because I think I'll need it.</p>\n<p>I have two datatypes I want to test out, at least at some point, that <br>\npoint not being way off in the future. My first guess is that one of <br>\nthem will be slow, but I need to find out, to make some decisions.</p>\n<p>I added two more tests, so now I'm doing three times more testing than <br>\nwhat I was doing, which is infinitely more than what I was doing before, <br>\nwhich, though not zero, was still only a small number infinitely close <br>\nto zero, call it epsilon.</p>\n<p>I thought about things a little more because you brought these things <br>\nup, but there's no room for that here.</p>\n<p>Regards,<br>\nGB</p>",
        "id": 294278103,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919440
    }
]