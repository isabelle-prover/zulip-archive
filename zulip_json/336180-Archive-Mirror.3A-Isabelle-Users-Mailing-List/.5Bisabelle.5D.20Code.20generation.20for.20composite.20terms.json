[
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Andreas,</p>\n<blockquote>\n<p>Unfortunately, the test data is not an Isabelle constant, the most<br>\nprominent example are literal numbers like \"42 :: code_numeral\".<br>\nHowever, export_code and its ML equivalent only accept constants, not<br>\ngeneral terms like \"42\". Therefore, we'd like to know how we can<br>\ngenerate code for such terms.</p>\n<p>We had a look at how \"value [code]\" achieves to evaluate arbitrary<br>\nterms. After studying the sources, it seems to us that<br>\nCode_Thingol.ensure_value does the necessary wrapping by introducing a<br>\ncode dependency \"dummy_pattern = &lt;term to evaluate&gt;\", then builds the<br>\ncode graph and removes \"dummy_pattern\" and the dependency again.</p>\n</blockquote>\n<blockquote>\n<p>This<br>\nlooks a bit hacky (I don't see a way to generalise this to multiple<br>\nterms to evaluate) and uses lots of functions that Code_Thingol does not<br>\nexport.</p>\n</blockquote>\n<p>The first half of this sentence is the reason for the second half ;-).</p>\n<blockquote>\n<p>If we had to do it manually, we would define constants for the arguments<br>\nand feed them to the export_code command. However, in an automated<br>\nsystem, our asynchronous testing command then would become a theory<br>\ntransformation that pollutes the name space if many test cases are run.<br>\nIs there a simpler solution? For example, making a bunch of definitions<br>\nsolely for the invocation of the code generator that are forgotton<br>\nafterwards again?</p>\n</blockquote>\n<p>AFAIK, quickcheck achieves a similar effect by forking the theory,<br>\nadding definitions (or even axiomatizations), generating code and<br>\nthrowing it away afterwards.  If I understand right, your business is<br>\nalso about testing, so this should also be applicable to your scenario.</p>\n<p>Hope this helps,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/JfvCb2pdGtQnV5P-8T0RqRNj/signature.asc\">signature.asc</a></p>",
        "id": 294274348,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660918254
    },
    {
        "content": "<p>From: Andreas Lochbihler &lt;<a href=\"mailto:andreas.lochbihler@inf.ethz.ch\">andreas.lochbihler@inf.ethz.ch</a>&gt;<br>\nHi Florian,</p>\n<p>We have been unable to find these temporary definitions in Quickcheck. The three <br>\ngenerators random, exhaustive and narrowing package everything that is needed for testing <br>\nin in a single term. Then, they call some version of Code_Thingol.dynamic_value which uses <br>\nCode_Target.ensure_value to get the intermediate representation of the generated code. <br>\nFinally, they run the code either with the usual mechanism from Code_Runtime or with <br>\nNarrowing_Generators.value.</p>\n<p>In principle, we could also stuff all our data into a large single term and then decompose <br>\nit in the generated test driver again. Do you recommend that we follow this way? Or do you <br>\nthink that separate definitions are superior?</p>\n<p>Cheers,<br>\nAndreas</p>",
        "id": 294274447,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660918284
    },
    {
        "content": "<p>From: Florian Haftmann &lt;<a href=\"mailto:florian.haftmann@informatik.tu-muenchen.de\">florian.haftmann@informatik.tu-muenchen.de</a>&gt;<br>\nHi Andreas,</p>\n<blockquote>\n<blockquote>\n<p>AFAIK, quickcheck achieves a similar effect by forking the theory,<br>\nadding definitions (or even axiomatizations), generating code and<br>\nthrowing it away afterwards.  If I understand right, your business is<br>\nalso about testing, so this should also be applicable to your scenario.<br>\nWe have been unable to find these temporary definitions in Quickcheck.<br>\nThe three generators random, exhaustive and narrowing package everything<br>\nthat is needed for testing in in a single term. Then, they call some<br>\nversion of Code_Thingol.dynamic_value which uses<br>\nCode_Target.ensure_value to get the intermediate representation of the<br>\ngenerated code. Finally, they run the code either with the usual<br>\nmechanism from Code_Runtime or with Narrowing_Generators.value.</p>\n</blockquote>\n</blockquote>\n<p>this was my slip, I have been referring to the predicate compiler<br>\nquickcheck.</p>\n<blockquote>\n<p>In principle, we could also stuff all our data into a large single term<br>\nand then decompose it in the generated test driver again. Do you<br>\nrecommend that we follow this way? Or do you think that separate<br>\ndefinitions are superior?</p>\n</blockquote>\n<p>The approach with a big tuple seems suitable, indeed.</p>\n<p>Hope this helps,<br>\n    Florian<br>\n<a href=\"/user_uploads/14278/Xc5L3MYw-A1FRtPop7bfWNcl/signature.asc\">signature.asc</a></p>",
        "id": 294274457,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660918291
    },
    {
        "content": "<p>From: Andreas Lochbihler &lt;<a href=\"mailto:andreas.lochbihler@inf.ethz.ch\">andreas.lochbihler@inf.ethz.ch</a>&gt;<br>\nHi,</p>\n<p>We are trying to implement an evaluation system for Isabelle2013-2 that can generate code <br>\nin different target languages, run generated functions on some input data, and process the <br>\nresult. Our goal is to automate testing of adaptations of the code generator setup <br>\n(code_printing). To that end, we would like the code generator to generate the function to <br>\ntest and the test data.</p>\n<p>Unfortunately, the test data is not an Isabelle constant, the most prominent example are <br>\nliteral numbers like \"42 :: code_numeral\". However, export_code and its ML equivalent only <br>\naccept constants, not general terms like \"42\". Therefore, we'd like to know how we can <br>\ngenerate code for such terms.</p>\n<p>We had a look at how \"value [code]\" achieves to evaluate arbitrary terms. After studying <br>\nthe sources, it seems to us that Code_Thingol.ensure_value does the necessary wrapping by <br>\nintroducing a code dependency \"dummy_pattern = &lt;term to evaluate&gt;\", then builds the code <br>\ngraph and removes \"dummy_pattern\" and the dependency again. This looks a bit hacky (I <br>\ndon't see a way to generalise this to multiple terms to evaluate) and uses lots of <br>\nfunctions that Code_Thingol does not export. So, I wonder whether that is one way to go.</p>\n<p>If we had to do it manually, we would define constants for the arguments and feed them to <br>\nthe export_code command. However, in an automated system, our asynchronous testing command <br>\nthen would become a theory transformation that pollutes the name space if many test cases <br>\nare run. Is there a simpler solution? For example, making a bunch of definitions solely <br>\nfor the invocation of the code generator that are forgotton afterwards again?</p>\n<p>Or are there simpler solutions that we have overlooked?</p>\n<p>Thanks in advance for any suggestions and ideas,<br>\nAndreas</p>",
        "id": 294276636,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660919004
    }
]