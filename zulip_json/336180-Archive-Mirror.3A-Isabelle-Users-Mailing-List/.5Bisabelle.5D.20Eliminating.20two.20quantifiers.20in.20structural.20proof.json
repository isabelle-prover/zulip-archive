[
    {
        "content": "<p>From: Edward Schwartz &lt;<a href=\"mailto:edmcman@cmu.edu\">edmcman@cmu.edu</a>&gt;<br>\nHi,</p>\n<p>I am new to Isabelle, and am stuck on a fairly trivial part of my<br>\nproof.  I have an assumption \"\\forall x y. P x y\".  I'd simply like to<br>\nshow (P a b) for two terms I have (a and b).  Surprisingly, I am<br>\nhaving trouble doing this in a structural way.</p>\n<p>With one quantified variable, there is no problem:</p>\n<p>lemma single_proof : \"(\\&lt;forall&gt;x. P x) \\&lt;Longrightarrow&gt; P a\"<br>\nproof (erule allE)<br>\n  fix c<br>\n  assume A: \"P c\"<br>\n  from A show \"P c\" by assumption<br>\nqed</p>\n<p>My understanding of what is happening is that allE removes the<br>\nquantifier, and so we really just prove /\\ c. P c ==&gt; P c.  It seems<br>\nlike a better proof would be of /\\ c. P ?c ==&gt; P c.  Is there any way<br>\nto do this instead?</p>\n<p>lemma double : \"(\\&lt;forall&gt;x y. P x y) \\&lt;Longrightarrow&gt; P a b\"<br>\napply (erule allE, erule allE)<br>\napply assumption<br>\ndone</p>\n<p>Here is a way to do the proof with tactics.  Unfortunately, in my<br>\nlarger proof, the erule commands do not find the correct assumption,<br>\nand so I must specify P manually, which is <em>very</em> ugly.</p>\n<p>lemma double_proof : \"(\\&lt;forall&gt;x y. P x y) \\&lt;Longrightarrow&gt; P a b\"<br>\nproof (erule allE)<br>\n  fix c<br>\n  assume \"\\&lt;forall&gt;y. P c y\"<br>\n  have \"P c b\"<br>\n  proof (erule allE) (* error: proof command failed *)</p>\n<p>Finally, I try to do a structural proof, eliminating one quantifier at<br>\na time, and fail.  I've tried many variations, but can't seem to<br>\nunderstand how to do this.  If someone could show how to finish this<br>\nproof, and explain why it works, I would greatly appreciate it.</p>\n<p>Overall, Isabelle/HOL seems to make it very difficult to instantiate<br>\nfree variables in foralls.  In Coq, this is very easy, since \\forall<br>\nx. P x is actually a function that accepts a variable v and returns<br>\nproof that (P v).  What am I missing?</p>\n<p>Thanks,</p>\n<p>Ed</p>",
        "id": 294222431,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898198
    },
    {
        "content": "<p>From: Edward Schwartz &lt;<a href=\"mailto:edmcman@cmu.edu\">edmcman@cmu.edu</a>&gt;<br>\nHi all,</p>\n<p>I made a few breakthroughs in understand Isar:</p>\n<ol>\n<li>\n<p>\"proof\" is not the same thing as \"proof -\".  In particular, proof<br>\nlooks for a classical logic introduction rule that matches the current<br>\ngoal.  It will not work with goals like \"A ==&gt; B\" as I had.  \"proof -\"<br>\nworks on these.  This is really confusing, and if any Isabelle devs<br>\nread this, please consider changing it!</p>\n</li>\n<li>\n<p>Here are the modified proofs of my examples:</p>\n</li>\n</ol>\n<p>The first example can be rewritten where the assumption is more general:</p>\n<p>lemma single_proof : \"(\\&lt;forall&gt;x. P x) \\&lt;Longrightarrow&gt; P a\"<br>\nproof -<br>\n  assume A: \"\\&lt;forall&gt;x. P x\"<br>\n  fix c<br>\n  from A show \"P c\" ..<br>\nqed</p>\n<p>And here is the two variable example:</p>\n<p>lemma double_proof : \"(\\&lt;forall&gt;x y. P x y) \\&lt;Longrightarrow&gt; P a b\"<br>\nproof -<br>\n  assume H: \"\\&lt;forall&gt;x y. P x y\"<br>\n  fix a b<br>\n  from H have \"\\&lt;forall&gt;y. P a y\" ..<br>\n  thus \"P a b\" ..<br>\nqed</p>\n<p>This is a big improvement over my previous attempts, but still seems<br>\noverly verbose for just instantiating bound variables.  Is there a<br>\nquicker way that works on multiple bound variables at the same time?</p>\n<p>Thanks again,</p>\n<p>Ed</p>",
        "id": 294222452,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898210
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nTry to use the meta-quantifier !! instead of \\&lt;forall&gt; whenever you can, and in<br>\nyour examples you can. Now if you have an assumption A: \"!!x y. P x y\" you can<br>\ninstantiate the quantifiers very easily: just write A[of \"t1\" \"t2\"]. Then it is<br>\nhardly more verbose than Coq. Note that the instantiation order is not the order<br>\nof quantification but the order in which x and y occur in P (from left to<br>\nright). In fact, if you inspect A in the proof (eg via command thm) you see that<br>\nthe !! have disappeared and x/y became ?x/?y.</p>\n<p>Unfortunately the \"of\" operator only works for !!, and !! can only occur at the<br>\n\"outermost\" level, ie not inside HOL formulas. But in many situations that suffices.</p>\n<p>Tobias</p>",
        "id": 294222460,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898219
    },
    {
        "content": "<p>From: Alfio Martini &lt;<a href=\"mailto:alfio.martini@acm.org\">alfio.martini@acm.org</a>&gt;<br>\nHi Edward,</p>\n<p>I am not sure if this is what you what, but in Isar is fairly natural to do<br>\nsuch proofs. I use it to teach natural deduction to students.<br>\nHere goes three proofs of this conjecture:</p>\n<p>theorem th11a:<br>\n   assumes prem: \"∀x. ∀y. P x y\"<br>\n   shows \"P a b\"<br>\n     proof -<br>\n       from prem have \"∀y. P a y\" by (rule spec)<br>\n       thus \"P a b\" by (rule spec)<br>\n     qed</p>\n<p>theorem th11b:<br>\n   assumes prem: \"∀x. ∀y. P x y\"<br>\n   shows \"P a b\"<br>\n     proof -<br>\n       from prem have \"∀y. P a y\" by (rule allE)<br>\n       thus \"P a b\" by (rule allE)<br>\n     qed</p>\n<p>theorem th11c:<br>\n   assumes prem: \"∀x. ∀y. P x y\"<br>\n   shows \"P a b\"<br>\n     proof -<br>\n       from prem have \"∀y. P a y\" by (rule spec[where x =a])<br>\n       from this show  \"P a b\" by (rule spec[where x=b])<br>\n     qed</p>\n<p>I assume you hardly have to use the qualifieres (e(limination),<br>\nd(estruction)) when<br>\nworking in Isar. I use this style only when I am playing with linear<br>\nscripts.</p>\n<p>All the Best!</p>",
        "id": 294222469,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898223
    },
    {
        "content": "<p>From: Alfio Martini &lt;<a href=\"mailto:alfio.martini@acm.org\">alfio.martini@acm.org</a>&gt;<br>\nForgot this one:</p>\n<p>theorem th11d:<br>\n   \"∀x. ∀y. P x y ==&gt; P a b\"<br>\n     proof -<br>\n       assume  \"∀x. ∀y. P x y\"<br>\n       from this have \"∀y. P a y\" by (rule spec[where x =a])<br>\n       from this show  \"P a b\" by (rule spec[where x=b])<br>\n     qed</p>",
        "id": 294222484,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898235
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThis is an important observation.  The \"erule\" and \"drule\" rule <br>\napplication forms are never required in structure proof.  Instead you <br>\nindicate the forward deduction explicitly via the 'then' language element, <br>\nand then just use a normal \"rule\" step, which is often not spelled out but <br>\nleft implicit.</p>\n<p>Roughly speaking a tactic script with \"apply (erule r)\" corresponds to an <br>\nIsar proof text fragment \"then show proof (rule r)\", and \"apply (drule r)\" <br>\ncorresponds to \"then have proof (rule r)\".</p>\n<p>Note that the abbreviations \"thus == then show\" and \"hence == then have\" <br>\nare merely historical accidents.  They require fewer bytes in memory, but <br>\nmore typing by the user and more explanations to newcomers.  The reason is <br>\nthat the chaining or not chaining for elementary 'show' and 'have' <br>\nelements are often changed during the proof development.  And there are <br>\nfurther combinators like 'also' and 'moreover' that can be combined with <br>\n'have' or 'show', and other goal elements like 'obtain' that can <br>\nparticipate in the chaining of facts in the same manner.</p>\n<p>So there is a large combinatorial space of</p>\n<p>(then | from | with | ... | also | finally | moreover | ultimately)<br>\n     (have | show | obtain | interpret ...)</p>\n<p>which is better spelled out as such explicitly, without the somewhat <br>\npointless shortcuts 'hence' and 'thus' getting in the way.</p>\n<p>Makarius</p>",
        "id": 294222874,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898455
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nYet more examples on this thread, using native natural deduction <br>\nstatements in Isabelle/Pure, without any auxiliary HOL connectives getting <br>\nin the way:</p>\n<p>lemma<br>\n   assumes \"⋀x y. P x y\"<br>\n   shows \"P a b\"<br>\nproof -<br>\n   from <code>P a b</code> show ?thesis .<br>\nqed</p>\n<p>Using the Pure quantifier in the assumption, you get arbitrary instances <br>\nof the proposition for free, using unification behind the scenes.  The <br>\nbackquote notation is a \"literal fact reference\", stating an instance of <br>\nsomething you have already visibly in the proof context.</p>\n<p>Here is the same, without the initial goal statement getting between you <br>\nand the understanding of natural deduction reasoning in a local context:</p>\n<p>notepad<br>\nbegin</p>\n<p>assume \"⋀x y. P x y\"</p>\n<p>note <code>P a b</code></p>\n<p>have \"P a b\" by fact<br>\nend</p>\n<p>So you build up a context with some general fact, and then project <br>\ninstances from it.  The backquote and \"by fact\" form are operationally <br>\nequalivalent, but the latter works via a local result with nested goal <br>\nstate.  Both forms have there uses in practical applications.</p>\n<p>Makarius</p>",
        "id": 294222888,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660898461
    }
]