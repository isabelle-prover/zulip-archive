[
    {
        "content": "<p>From: Christian Sternagel &lt;<a href=\"mailto:c-sterna@jaist.ac.jp\">c-sterna@jaist.ac.jp</a>&gt;<br>\nDear Brian,</p>\n<p>I'm currently experimenting with HOLCF (and reading your thesis in <br>\nparallel), and I have to say, really nice work!</p>\n<p>Some tiny things I noticed:</p>\n<hr>\n<p>Domain Package:</p>\n<ul>\n<li>\n<p>syntax annotations are allowed for constructors but do not work if <br>\ngiven separately with \"notation\", e.g.,</p>\n<p>domain 'a list = Nil | Cons (lazy 'a) (lazy \"'a list\") (infixr \":\" 65)</p>\n</li>\n</ul>\n<p>works, but</p>\n<p>notation Cons (infixr \":\" 65)</p>\n<p>doesn't (due to being a continuous function)</p>\n<p>Fixrec Package:</p>\n<ul>\n<li>\n<p>does not allow mixfix annotations (due to continuous function type), e.g.,</p>\n<p>fixrec append :: \"'a list -&gt; 'a list -&gt; 'a list\" (infixr \"++\" 65) where<br>\n   \"Nil ++ ys = ys\" |<br>\n   \"(Cons$x$xs) ++ ys = Cons$x$(xs ++ ys)\"</p>\n</li>\n</ul>\n<p>does not work. We have to introduce an intermediate abbreviation:</p>\n<p>abbreviation append_syn :: \"'a list =&gt; 'a list =&gt; 'a list\" (infixr <br>\n\"++\" 65) where<br>\n     \"xs ++ ys = append$xs$ys\"</p>\n<p>General:</p>\n<ul>\n<li>\n<p>definitions do not allow \"natural\" equations like \"f$x$y = P x y\", we <br>\nhave to use \"f = Lambda x y. P x y\" instead.</p>\n</li>\n<li>\n<p>a space after the unicode symbol for \"Lambda\" is mandatory, otherwise <br>\nwe get an inner syntax error</p>\n</li>\n</ul>\n<hr>\n<p>Shouldn't it be possible to reuse the same machinery that allows to give <br>\nmixfix annotations for domain constructors at all other locations that <br>\nallow for mixfix annotations?</p>\n<p>Concerning usage of HOLCF in jEdit (I guess, this is for Makarius): <br>\ncould a translation from $ to the unicode cdot be added to the default <br>\n\"translation table\", since typing \"&lt;space&gt; c d o t\" and then moving back <br>\nin order to remove the space is slightly odd.</p>\n<p>The more I read about HOLCF and its intended use to verify functional <br>\nprograms, the more I feel that it is a pity that code generation does <br>\nnot work for it. Currently if we want to verify Haskell code, we have to <br>\ntake the sources, translate them (manually?) into Isabelle, and verify <br>\nthe desired properties. However the original sources are still used for <br>\ncompilation and if those change, we might not even notice. It would be <br>\nmuch more reliable to generate Haskell code (e.g., the Standard Prelude) <br>\nfrom its Isabelle/HOLCF formalization automatically.</p>\n<p>cheers</p>\n<p>chris</p>",
        "id": 294162594,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660853689
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nThere is Haskabelle for translating Haskelle to HOL. But data types become eager<br>\nin the process. One would need a similar translation to HOLCF.</p>\n<p>Of course I agree that code generation for HOLCF would be very nice to have. We<br>\nhad this on the agenda at some point - maybe we should get back to it.</p>\n<p>Tobias</p>",
        "id": 294162700,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660853726
    },
    {
        "content": "<p>From: Till Mossakowski &lt;<a href=\"mailto:till@informatik.uni-bremen.de\">till@informatik.uni-bremen.de</a>&gt;<br>\nwe have implemented a translation of Haskell into Isabelle HOLCF as part <br>\nof the Heterogeneous Tool Set, see <a href=\"http://www.dfki.de/cps/hets\">www.dfki.de/cps/hets</a>. This has been <br>\ndone some years ago and probably would need to be adapted to the latest <br>\nIsabelle version, though.</p>\n<p>Best, Till</p>",
        "id": 294162753,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660853754
    },
    {
        "content": "<p>From: Brian Huffman &lt;<a href=\"mailto:huffman@in.tum.de\">huffman@in.tum.de</a>&gt;<br>\nOn Wed, Jun 27, 2012 at 7:36 AM, Christian Sternagel<br>\n&lt;<a href=\"mailto:c-sterna@jaist.ac.jp\">c-sterna@jaist.ac.jp</a>&gt; wrote:</p>\n<blockquote>\n<p>Dear Brian,</p>\n<p>I'm currently experimenting with HOLCF (and reading your thesis in<br>\nparallel), and I have to say, really nice work!</p>\n</blockquote>\n<p>Thanks!</p>\n<blockquote>\n<p>Some tiny things I noticed:</p>\n<hr>\n<p>Domain Package:</p>\n<ul>\n<li>syntax annotations are allowed for constructors but do not work if given<br>\nseparately with \"notation\", e.g.,</li>\n</ul>\n<p>domain 'a list = Nil | Cons (lazy 'a) (lazy \"'a list\") (infixr \":\" 65)<br>\nworks, but<br>\n notation Cons (infixr \":\" 65)<br>\ndoesn't (due to being a continuous function)</p>\n</blockquote>\n<p>Yes, you would need to define this syntax using an abbreviation, like<br>\nyou do below for your fixrec functions.</p>\n<p>Way back when we used to define functions with separate \"consts\",<br>\n\"syntax\", and \"defs\" commands, HOLCF used to provide a replacement<br>\n\"syntax\" command that knew about the continuous function type.<br>\nUnfortunately things are less consistent now, when each command is<br>\nresponsible for handling its own syntax declarations.</p>\n<blockquote>\n<p>Fixrec Package:</p>\n<ul>\n<li>does not allow mixfix annotations (due to continuous function type), e.g.,</li>\n</ul>\n<p>fixrec append :: \"'a list -&gt; 'a list -&gt; 'a list\" (infixr \"++\" 65) where<br>\n   \"Nil ++ ys = ys\" |<br>\n   \"(Cons$x$xs) ++ ys = Cons$x$(xs ++ ys)\"</p>\n<p>does not work. We have to introduce an intermediate abbreviation:</p>\n<p>abbreviation append_syn :: \"'a list =&gt; 'a list =&gt; 'a list\" (infixr \"++\" 65)<br>\nwhere<br>\n   \"xs ++ ys = append$xs$ys\"</p>\n</blockquote>\n<p>Like most other function definition commands in Isabelle now, Fixrec<br>\nuses a standard Isar specification parser (Specification.read_spec) to<br>\nprocess its input; it handles both parsing and type inference. This<br>\nparser of course expects infix functions to have ordinary function<br>\ntypes. Adding support for infix with continuous function types would<br>\nprobably require a complete reimplementation of specification.ML.</p>\n<blockquote>\n<p>General:</p>\n<ul>\n<li>definitions do not allow \"natural\" equations like \"f$x$y = P x y\", we have<br>\nto use \"f = Lambda x y. P x y\" instead.</li>\n</ul>\n</blockquote>\n<p>This shouldn't be surprising, since definitions like \"f$x$y = P x y\"<br>\nare not sound in general; continuity checks are required.</p>\n<p>Equations like this work fine with Fixrec. (Although you might want to<br>\ndeclare the equation with [simp del] if you don't want it unfolded<br>\nautomatically.)</p>\n<blockquote>\n<ul>\n<li>a space after the unicode symbol for \"Lambda\" is mandatory, otherwise we<br>\nget an inner syntax error</li>\n</ul>\n</blockquote>\n<p>You also need spaces after alphanumeric quantifiers like \"ALL\",  \"EX\",<br>\n\"THE\", and \"SOME\", right? The same reasoning applies here, because<br>\nIsabelle's lexer considers \\&lt;Lambda&gt; to be a letter; \\&lt;lambda&gt; is an<br>\noddball in that the lexer considers it to be a non-letter.</p>\n<blockquote>\n<hr>\n<p>Shouldn't it be possible to reuse the same machinery that allows to give<br>\nmixfix annotations for domain constructors at all other locations that allow<br>\nfor mixfix annotations?</p>\n</blockquote>\n<p>Not easily. (See above about specification parser.) It used to be<br>\neasier in the old days with a single \"syntax\" command.</p>\n<blockquote>\n<p>Concerning usage of HOLCF in jEdit (I guess, this is for Makarius): could a<br>\ntranslation from $ to the unicode cdot be added to the default \"translation<br>\ntable\", since typing \"&lt;space&gt; c d o t\" and then moving back in order to<br>\nremove the space is slightly odd.</p>\n</blockquote>\n<p>I don't expect that all Isabelle users will want \"$\" to be replaced by<br>\n\"\\&lt;cdot&gt;\", and anyway, shouldn't the input translations for jEdit be<br>\ncustomizable? It seems ridiculous to have to ask a developer to change<br>\nthe distribution every time somebody wants to add a new input<br>\ntranslation.</p>\n<p>In ProofGeneral, I have it set up to replace \",.\" with \"\\&lt;cdot&gt;\"; this<br>\nshortcut works very well for me.</p>\n<blockquote>\n<p>The more I read about HOLCF and its intended use to verify functional<br>\nprograms, the more I feel that it is a pity that code generation does not<br>\nwork for it. Currently if we want to verify Haskell code, we have to take<br>\nthe sources, translate them (manually?) into Isabelle, and verify the<br>\ndesired properties. However the original sources are still used for<br>\ncompilation and if those change, we might not even notice. It would be much<br>\nmore reliable to generate Haskell code (e.g., the Standard Prelude) from its<br>\nIsabelle/HOLCF formalization automatically.</p>\n</blockquote>\n<p>John Matthews and I have occasionally discussed an old idea that could<br>\nhelp with all of the problems that you mentioned: Have HOLCF use<br>\nordinary function types (\"=&gt;\" instead of \"-&gt;\") in many more places,<br>\ne.g. constructor functions for domains, and user-defined fixrec<br>\nfunctions. (The continuous function type would still be needed for<br>\nsome higher-order constructions.) At the same time, the various HOLCF<br>\npackages would need to generate continuity theorems for each new<br>\nconstant. With ordinary function types, code generation would work,<br>\ninfix declarations would work, and you wouldn't even need to type all<br>\nthose \\&lt;cdot&gt;s.</p>\n<ul>\n<li>Brian</li>\n</ul>",
        "id": 294162983,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660853845
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nSorry, this does not make any sense.  Things are <em>more</em> consistent now, <br>\nbecause the full responsibility is to the packages, which fulfill that <br>\neasily by handing over to standard Isabelle operations to introduce terms <br>\nwith mixfix syntax and specifications in the standard way.  So it all <br>\nworks out uniformly in the post-Isabelle2005 era.</p>\n<p>In contrast, the old scheme where 'consts' where separate had several <br>\nconceptual problems.  The one that might still be remembered is the \"unify <br>\nconsts\" problem: since an earlier 'consts' declaration would already be <br>\npolymorphic, a subsequent 'defs' (or derived form) would often get an <br>\nunexpected type, or different types for different equations. <br>\nHistorically, this has led to some packages trying to \"repair\" <br>\ntype-inference in different ways.  So old 'primrec', 'recdef', 'inductive' <br>\ncould give the user different versions of type-inference.</p>\n<p>As already observed, abbreviations handle alternative syntax views better, <br>\nbut users need to write them down themselves.</p>\n<p>Some packages like 'inductive_set' allow the user to include such <br>\nabbreviations simultaneously into the specification -- they are recognized <br>\nby the Pure == form.  Thus old idioms like pretending that \"(x, y) : R\" is <br>\nactually a judgement \"x -R-&gt; y\" could be supported with reasonable add-on <br>\nfunctionality to that particular package.  This is not exceedingly <br>\nelegant, but better than the old scheme based on 'translations', which <br>\ndoes not quite fit into the local theory specification concept.</p>\n<p>Makarius</p>",
        "id": 294218725,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660896290
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nIn principle the 'definition' package has a filter to convert between the <br>\nspecification given by the user, and the actual definition of the strict <br>\nform \"f == RHS\".  It is rather simplistic, though, so it can probably not <br>\nbe stretched that far.</p>\n<p>How about non-recursive 'fixrec'?  That would be analogous to using 'fun' <br>\nin HOL to get pattern matching, instead of trying to add this <br>\nfunctionality to the basic 'definition' package.</p>\n<p>Makarius</p>",
        "id": 294218736,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660896296
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThis is a consequence of the way greek letters were added to the <br>\nidentifier syntax in 2003.  \\&lt;lambda&gt; was treated as a special case, and <br>\nyou loose in all other situations, such as \\&lt;Lambda&gt; here, or \\&lt;mu&gt;, <br>\n\\&lt;iota&gt; etc. that occurr occasionally in applications.</p>\n<p>I have some ideas in the pipeline to address this problem and some others <br>\nwrt. sub/superscripts within identifiers, but I did not manage to try that <br>\nout yet, to see how it impacts existing theories.  There is some renewed <br>\nmotivation to do it soon, because I don't want to imitate slightly odd <br>\nidentifier treatment of Proof General in Isabelle/jEdit.</p>\n<p>Makarius</p>",
        "id": 294218750,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660896302
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThis is specific to HOLCF.  Any global modification of the input method is <br>\napt to cause annoyances in other situations, where $ or \\&lt;cdot&gt; are used <br>\ndifferently / independently.</p>\n<p>Until some better configuration for Isabelle/jEdit input methods becomes <br>\navailable, you can add the following line to your <br>\n$ISABELLE_HOME_USER/etc/symbols file:</p>\n<p>\\&lt;cdot&gt;                 code: 0x0022c5  abbrev: $</p>\n<p>Note that etc/symbols allows to change the \"code\" assignment as well, but <br>\nthis should be done with great care, or not at all, to avoid chaos in the <br>\ncommunication with other users.</p>\n<p>Makarius</p>",
        "id": 294218762,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660896308
    }
]