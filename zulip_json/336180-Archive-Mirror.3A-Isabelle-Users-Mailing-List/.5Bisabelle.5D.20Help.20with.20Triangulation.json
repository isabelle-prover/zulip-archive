[
    {
        "content": "<p>From: Michal Wallace &lt;<a href=\"mailto:michal.wallace@gmail.com\">michal.wallace@gmail.com</a>&gt;<br>\nJose,</p>\n<p>Thank you for the detailed proof outline. It's very interesting to me, and<br>\nyou may well be right that it would lead to a more useful and natural<br>\nproof, but I'm afraid I'm a couple decades behind you in my mathematical<br>\nstudies, and I have trouble parsing most of the words on the wikipedia<br>\npages you link.</p>\n<p>The highest level math course I ever took was calculus, and that was 20+<br>\nyears ago. I've read various books and watched videos on different higher<br>\nmath subjects along the way, but when I open (for example) your first link:<br>\n<a href=\"https://en.wikipedia.org/wiki/CW_complex\">https://en.wikipedia.org/wiki/CW_complex</a>, I'm quickly confronted with many<br>\nwords I don't understand. If I look those words up, I have the same<br>\nproblem. (Attaching map leads to<br>\n<a href=\"https://en.wikipedia.org/wiki/Adjunction_space\">https://en.wikipedia.org/wiki/Adjunction_space</a> leads to<br>\n<a href=\"https://en.wikipedia.org/wiki/Continuous_function#Continuous_functions_between_topological_spaces\">https://en.wikipedia.org/wiki/Continuous_function#Continuous_functions_between_topological_spaces</a><br>\nleads to <a href=\"https://en.wikipedia.org/wiki/Ball_(mathematics)\">https://en.wikipedia.org/wiki/Ball_(mathematics)</a> (which I skipped<br>\nover back on the CW page, thinking I probably knew what it meant, but now<br>\nI'm not sure, and so on and so on.)</p>\n<p>That isn't to say that I'm a big dummy head and could never understand any<br>\nof this. :)  Just about everywhere one looks in math and programming, one<br>\nfinds these big complicated graphs of ideas that have to be explored in<br>\norder to get anything done. It's easy to get lost.</p>\n<p>Currently, I'm also pretty lost when it comes to Isabelle. As a software<br>\ndeveloper, I've dealt with this many times: I'm encountering a new code<br>\nbase which seems tangled and complicated. Presumably it was all small and<br>\nsimple at one point (maybe way back when the first LCF prototypes were<br>\nmade) and now, many years of ideas and improvements and probably false<br>\nstarts are scattered everywhere. (For example, Larry ported Polytope.thy<br>\n(and the triangulation stuff in it) from HOL-Light, and the author of<br>\nHOL-Light has since added proofs for both the polyhedron formula and pick's<br>\ntheorem, and both of those proofs re-implement their own separate take on<br>\ntriangulation.</p>\n<p>Unfortunately, HOL-Light lacks a nice syntax like Isar, so for me to port<br>\nthose proofs directly would require learning a whole lot about<br>\nHOL-Light.... That might be fun, too, but there's only so many rabbit holes<br>\none can go down at once. :)</p>\n<p>In any case, I can get my head around Triangulations, and I can see a<br>\npretty clear path from what I've proved so far, to proving Pick's theorem<br>\nand the polyhedron formula, and the only thing I have to focus on learning<br>\nis \"how to express my ideas in Isabelle\"... which is the main thing I want<br>\nto learn right now.</p>\n<p>My hope is that when I'm done, I'll be able to publish my proof as a paper<br>\nthat a pretty wide audience can understand, which not only proves some<br>\nthings about polyhedra, but also shows other programmers who might be<br>\ninterested a thing or two about Isabelle and why it's neat, and maybe even<br>\nshows some math folks how you can use Isabelle to write proofs that are not<br>\nonly human readable and computer checked, but also directly executable.</p>\n<p>More importantly, my hope is that when I'm done, I'll be a little better at<br>\nproving things in Isabelle, so that maybe the next time I formalize<br>\nsomething, I can focus more on learning new math. When I get there, I might<br>\njust take another look at your outline here, and see how far I can get<br>\nalong the path you laid out. (I'd certainly be curious to compare the two<br>\napproaches in the end.)</p>",
        "id": 294739301,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661190928
    },
    {
        "content": "<p>From: Jeremy Dawson &lt;<a href=\"mailto:Jeremy.Dawson@anu.edu.au\">Jeremy.Dawson@anu.edu.au</a>&gt;<br>\nOn 08/14/2018 11:40 PM, Michal Wallace wrote:</p>\n<blockquote>\n<p>Unfortunately, HOL-Light lacks a nice syntax like Isar, so for me to port<br>\nthose proofs directly would require learning a whole lot about<br>\nHOL-Light.... That might be fun, too, but there's only so many rabbit holes<br>\none can go down at once.:)</p>\n<p>Hi Michal,</p>\n</blockquote>\n<p>Isar may be a nice syntax, in the sense that you can look at a page of <br>\nit and not see many semicolons or parentheses or square brackets, but <br>\nit's not nice otherwise.  Just like English text would be nicer without <br>\nany punctuation.  You have to learn to understand the page of text.</p>\n<p>With HOL Light, I understand it is written in O'Caml, which is a <br>\nsensibly designed and well-documented language.  And I assume HOL Light <br>\nis also well documented - if it's not, then choose HOL4, which is.</p>\n<blockquote>\n<p>My hope is that when I'm done, I'll be able to publish my proof as a paper<br>\nthat a pretty wide audience can understand, which not only proves some<br>\nthings about polyhedra, but also shows other programmers who might be<br>\ninterested a thing or two about Isabelle and why it's neat, and maybe even<br>\nshows some math folks how you can use Isabelle to write proofs that are not<br>\nonly human readable and computer checked, but also directly executable.</p>\n</blockquote>\n<p>Forget that.  No-one will want to read a proof document that includes <br>\nevery step that the computer needs to complete its proof.</p>\n<p>I don't say there aren't exceptions, but do your readers the courtesy of <br>\nwriting a document for them which explains the proof in the level of <br>\ndetail they need.  Mostly the computer uses far more detailed steps, <br>\nwhich the reader won't want.  (Unless he/she really does want to check <br>\nthe computer has done it right).  Of course this may vary between <br>\nfields, but I've had to write proofs which involved tens of thousands of <br>\nelementary steps.</p>\n<p>Which means that a proof in HOL Light or HOL4 or Coq (usually structured <br>\nwith more rather than fewer intermediate lemmas) will be what the reader <br>\nwants.</p>\n<p>And of course you may be interested in whether your computer-based <br>\nproofs will still run in 10 or 20 years' time.</p>\n<p>Hope this gives you food for thought.</p>\n<p>Cheers,</p>\n<p>Jeremy</p>",
        "id": 294739455,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661190967
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nJeremy, I think you're quite missing the point about the difference between Isar and ML. It's not about whether the syntax is pretty or not or how much punctuation it requires. It is that an Isar proof presents the user with a structured outline of the argument including intermediate assertions, while a more traditional ML proof is a computer program that generates the required result but is completely opaque about the mathematical argument itself. One can look at a long Isar proof and follow the argument without using a computer, which is completely impossible in the case of a long proof coded in ML.</p>\n<p>As for whether the proof will run in 20 years' time: it's interesting to compare the differences between successive versions of the libraries in HOL Light or Coq compared with Isabelle. We are constantly streamlining our proofs and even changing definitions, because we can: any errors are immediately flagged in exactly the critical place. With those other systems, a proof once written is almost never changed, unless it is replaced by an entirely new proof. That's how we have managed to keep the 2 million lines of proofs in the AFP working since 2004.</p>\n<p>Larry</p>",
        "id": 294739479,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661190979
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nI must emphasize that the isabelle-users mailing list is for current<br>\nIsabelle releases (e.g. Isabelle2018, Isabelle2017, Isabelle2016), but<br>\nnot 20-30 years back in time as these attitudes suggest.</p>\n<p>The Archive of Formal Proofs is the practical proof that we managed to<br>\naddress certain problems of proof composition and maintenance from the<br>\npast. From there we should continue to move forwards, not backwards to<br>\nnostalgic ML \"proof scripts\".</p>\n<p>Users who do like that old style are invited to use HOL Light or HOL4:<br>\nthey are fine systems with their own mailing list.</p>\n<p>Makarius</p>",
        "id": 294739541,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191004
    },
    {
        "content": "<p>From: Lars Hupel &lt;<a href=\"mailto:hupel@in.tum.de\">hupel@in.tum.de</a>&gt;</p>\n<blockquote>\n<p>And of course you may be interested in whether your computer-based<br>\nproofs will still run in 10 or 20 years' time.</p>\n</blockquote>\n<p>Luckily, the AFP has a track record of 14 years continuous maintenance <br>\nof formal material.</p>\n<p>Cheers<br>\nLars</p>",
        "id": 294739553,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191010
    },
    {
        "content": "<p>From: Jeremy Dawson &lt;<a href=\"mailto:Jeremy.Dawson@anu.edu.au\">Jeremy.Dawson@anu.edu.au</a>&gt;<br>\nI accept that.  My remark was prompted by the attitude of the \"owners\" <br>\nof Isabelle to proofs dating from earlier than 14 years ago.<br>\n(To be fair, this is no doubt attributable to the \"owners\" of Isabelle <br>\n14 years ago than to the \"owners\" of Isabelle now).</p>\n<p>Obviously the concern would be that the same attitudes resurface.</p>\n<p>Cheers,</p>\n<p>Jeremy</p>",
        "id": 294739596,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191029
    },
    {
        "content": "<p>From: Jeremy Dawson &lt;<a href=\"mailto:Jeremy.Dawson@anu.edu.au\">Jeremy.Dawson@anu.edu.au</a>&gt;<br>\nHi Larry,</p>\n<p>I don't think so - my remark about pretty syntax was purely a response <br>\nto what was said about pretty syntax.</p>\n<p>I understand that Isar is meant to produce readable proofs.  I <br>\nquestioned whether it achieves this, because<br>\n(1) they're (in many cases) too long and detailed to read<br>\n(2) the meaning of many of the words in Isar is totally obscure to <br>\nsomeone who has only the documentation to rely on (and for those that <br>\naren't totally obscure, it's because they're analogous to things <br>\nexplained in the earlier documentation, which unfortunately seems to <br>\nhave now been abandoned - and which I believe you wrote, so I should <br>\nthank you wholeheartedly for that)</p>\n<p>As a matter of fact I've wondered whether the increased readability of <br>\nIsar proofs is mainly because the text of intermediate steps gets <br>\nincluded in the text of the document - ie, if one did a proof in ML with <br>\nextensive use of subgoal_tac, whether it would be just as good as an <br>\nIsar proof.</p>\n<p>Of course this is all quite irrelevant in the case of a proof like one I <br>\nonce had which had I think over 60000 elementary steps (ie, uses of <br>\nrtac, etac, atac etc) which no-one is ever going to write or read in ML <br>\nIsar or anything else.  What no-one has ever been willing to tell me is <br>\nhow Isar aficionados handle this sort of proof.</p>\n<p>Sorry for the length of this - but I do understand the concept of <br>\nreadable proofs.</p>\n<p>Cheers,</p>\n<p>Jeremy</p>",
        "id": 294739614,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191039
    },
    {
        "content": "<p>From: José Manuel Rodriguez Caballero &lt;<a href=\"mailto:josephcmac@gmail.com\">josephcmac@gmail.com</a>&gt;</p>\n<blockquote>\n<p>Jeremy Dawson wrote:<br>\nSorry for the length of this - but I do understand the concept of<br>\nreadable proofs.</p>\n</blockquote>\n<p>My answer will be according to my personal experience and it may be<br>\ndifferent from the conventional definition of readable proofs.</p>\n<p>In January of this year, I began to learn Coq and I gave the impression<br>\nthat it was a sort of video-game: it is very hard to understand a proof in<br>\nCoq from a printed page of it, you need a computer to reproduce it step by<br>\nstep. When I learned Isabelle from the manuals (it take me almost week), I<br>\ngave the impression that I was reading an ordinary text book in<br>\nmathematics. So, a readable proof is for me a proof which follow the same<br>\nstructure as a traditional mathematical proof from a textbook, e.g., e.g.,<br>\nAlgebra by Serge Lang.</p>\n<p>Jeremy Dawson wrote:</p>\n<blockquote>\n<p>I understand that Isar is meant to produce readable proofs.  I<br>\nquestioned whether it achieves this, because<br>\n(1) they're (in many cases) too long and detailed to read<br>\n(2) the meaning of many of the words in Isar is totally obscure to<br>\nsomeone who has only the documentation to rely on (and for those that<br>\naren't totally obscure, it's because they're analogous to things<br>\nexplained in the earlier documentation, which unfortunately seems to<br>\nhave now been abandoned - and which I believe you wrote, so I should<br>\nthank you wholeheartedly for that)</p>\n</blockquote>\n<p>Concerning (1), what I do is to read just the more interesting parts, like<br>\nin any text-book of mathematics. The journal of American Mathematical<br>\nMonthly rejected me a manuscript because it was too long and detailed to<br>\nread:</p>\n<p>The Editor wrote: we do not think that the <em>Monthly</em> is the right place for</p>\n<blockquote>\n<p>this manuscript; the paper is a dense read and it is unlikely that the<br>\ntypically <em>Monthly</em> reader will follow the paper most of the way through.<br>\nThere are thirteen lemmas required to get to the main result, and this does<br>\nnot seem appropriate for a <em>Monthly</em> article, which should be a friendly<br>\nread and even appealing to non-specialists. The paper appears to represent<br>\ngood work, but we suggest that it be submitted instead to a standard<br>\nresearch journal.</p>\n</blockquote>\n<p>So, if someone formalize my paper, it will be unreadable in Isar in the<br>\nsense (1), because my original approach was like that. The solution to (1)<br>\ndoes not belong to computer science, but to mathematics: the need for a<br>\nsimpler proof. This was what I did in another paper, which was published in<br>\nJournal of Number Theory, because I obtained the same result in a simpler<br>\nway, using another mathematical approach to the same problem.</p>\n<p>Concerning (2), I do not see Isar as obscure and I learned Isar just from<br>\nthe documentation. If the people which will use Isabelle/Isar are<br>\nmathematician, they read even more obscure papers every day. As<br>\nmathematician (I have a Master degree), to learn Isabelle was easier than<br>\nto learn any course of pure mathematics.</p>\n<p>If a mathematical proof in a textbook is readable and its formalization in<br>\nIsar is not readable, the problem is not Isar, but the person who<br>\nformalized that proof.  Sometimes this happens when people formalizing a<br>\nproof in Isabelle do not have a global idea of the theory that they are<br>\nformalizing. This is the reason why multi-disciplinary collaboration is<br>\nimportant in this field. In particular, some theorems can be proved in<br>\nseveral ways and the person who is formalizing this theorem, because of<br>\nlack of knowledge, choose the less readable way.</p>\n<p>For example, if you wants to formalize the proof of the prime number<br>\ntheorem, you have two options: either you use elementary number theory<br>\n(Erdos-Selberg's approach), which is unreadable in the sense of (1) or you<br>\nuse complex analysis (Hadamard - de la Vallee Poussin's approach), which is<br>\nreadable in the sense of (1).</p>\n<p>Kind Regards,<br>\nJose M.</p>",
        "id": 294739621,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191041
    },
    {
        "content": "<p>From: Michal Wallace &lt;<a href=\"mailto:michal.wallace@gmail.com\">michal.wallace@gmail.com</a>&gt;<br>\nIsar's syntax enables readable proofs, but it doesn't ensure that proofs<br>\nare readable.<br>\nThat requires a lot of work on the part of the author, including:</p>\n<p>- picking clear names/notation<br>\n  - breaking proofs down into smaller, easier to understand parts<br>\n  - adding text, comments and section headers</p>\n<p>It's certainly true that in many cases, this work has not been done. The<br>\nfile I've been working with the most:</p>\n<p><a href=\"https://isabelle.in.tum.de/dist/library/HOL/HOL-Analysis/Polytope.html\">https://isabelle.in.tum.de/dist/library/HOL/HOL-Analysis/Polytope.html</a></p>\n<p>is essentially a port of:</p>\n<p><a href=\"https://github.com/jrh13/hol-light/blob/master/Multivariate/polytope.ml\">https://github.com/jrh13/hol-light/blob/master/Multivariate/polytope.ml</a></p>\n<p>The two have diverged a bit, but at one point there was a one-to-one<br>\nmapping between the lemmas, and while the Isabelle<br>\nversion is still very very dense and nearly comment-free, it's (at least to<br>\nme) far more readable than the original.</p>\n<p>OTOH, I found the latest entry to the AFP to be extremely readable:</p>\n<p><a href=\"https://www.isa-afp.org/entries/Minsky_Machines.html\">https://www.isa-afp.org/entries/Minsky_Machines.html</a></p>\n<p>Most of the lemmas are short, and pretty much all of them are explained in<br>\nprose up front.</p>\n<p>As for your 60000 elementary steps....</p>\n<p>Some people actually do want that. One thing that draws people to<br>\n<a href=\"http://metamath.org\">metamath.org</a>,<br>\nfor example, is that every single step is shown... The only rules are<br>\nsyntax definition and substitution, and the people that<br>\nlike metamath consider that an extremely important feature. On the other<br>\nhand, they have the good taste to break each<br>\nproof down into small chunks, so you rarely (?) see a proof that's more<br>\nthan a screenful of text.</p>\n<p>I suppose if I were confronted with a proof that long in Isabelle, and I<br>\nknew many of the steps could be automated, I<br>\nwould probably start breaking off little chunks at the start or end of the<br>\nproof into their own lemmas, or<br>\npossibly try to pick out useful mid-steps and try to get sledgehammer to<br>\nreplace chunks in the middle.</p>\n<p>(Well, okay... with 60,000 lines, I would probably write a program that<br>\nwould attempt to do this for me...)</p>\n<p>I have a smaller but similar problem in front of me right now: over in<br>\nHOL-Analysis.Polytope.thy,<br>\nthere's a lemma that's 459 lines long (simplicial_subdivision_aux), and I<br>\nhave to decide between<br>\ntrying to understand it and then refactoring it, or just trying to start<br>\nfrom scratch.</p>\n<p>I haven't made up my mind yet, but even as big and complicated as it seems<br>\nto me, the code folding,<br>\nability to inspect the proof state at each point, and the ability to<br>\nctrl-click on any word to see its definition<br>\ncertainly make it seem much more approachable even without someone to guide<br>\nme through it.</p>\n<p>You seem to be feeling a lot of frustration with Isabelle. I can't say I'm<br>\nnot feeling similar frustrations, but<br>\nin my experience, that frustration is just a thing that happens when you<br>\ntry to really understand any<br>\nbig complicated system. The way through it is to be patient, ask questions,<br>\nexperiment, study what<br>\nother people have done (or what other people have <em>asked</em>, either here or<br>\non stack overflow), and<br>\njust trust that eventually things that were confusing at first will<br>\neventually start to make sense.</p>\n<p>Also... My impression (and I could be wrong about this) is that most of the<br>\nusers of Isabelle are not just<br>\ngoing it alone, but are academics working closely with and being taught by<br>\nother people who are<br>\nintimately familiar with the system already. Nobody's written a \"Learn You<br>\nan Isar for Great Good\" and<br>\nthere's not (yet) been a huge influx of curious outsiders blazing trails<br>\nfor everyone else. So that<br>\nmeans people like you and me (who seem to be sometimes frustrated<br>\noutsiders) have on opportunity<br>\nto be the trailblazers -- the ones who subject ourselves to getting lost<br>\nfor a while, knowing<br>\nthat when we eventually do find our way, we can make it easier for the next<br>\nperson.</p>\n<p>I can see that sounding pretty trite/condescending, and if so, sorry...<br>\nIt's just an attitude that I<br>\nfind keeps me sane and cheerful whenever I have to deal with new and often<br>\noverwhelming complexity. :)</p>",
        "id": 294739633,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191047
    },
    {
        "content": "<p>From: Jeremy Dawson &lt;<a href=\"mailto:Jeremy.Dawson@anu.edu.au\">Jeremy.Dawson@anu.edu.au</a>&gt;<br>\nOn 08/15/2018 03:12 PM, José Manuel Rodriguez Caballero wrote:</p>\n<blockquote>\n<p>Concerning (2), I do not see Isar as obscure and I learned Isar just <br>\nfrom the documentation. If the people which will use Isabelle/Isar are <br>\nmathematician, they read even more obscure papers every day. </p>\n</blockquote>\n<p>Well, there are different sort of \"obscurity\".  I guess you will have <br>\nheard of a certain style of mathematical proof described, <br>\ncontemptuously, as \"handwaving\".  Is a \"handwaving\" proof, not <br>\ncontaining a single mathematical symbol, more or less \"obscure\" than a <br>\nproper proof?  (That's a rhetorical question).</p>\n<p>As</p>\n<blockquote>\n<p>mathematician (I have a Master degree), to learn Isabelle was easier <br>\nthan to learn any course of pure mathematics.</p>\n<p>Great.  But my experience is that it's at least ten times harder than <br>\nHOL4 or the old Isabelle, or Coq (with the caveat I know only a small <br>\namount of using Coq).  And what's most noteworthy is that lots of people <br>\nwill spend a lot of time replying to my posts, but they will never <br>\nanswer questions about what Isar commands actually do to the state of a <br>\npartly completed proof.</p>\n</blockquote>\n<p>Cheers,</p>\n<p>Jeremy</p>",
        "id": 294739642,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191053
    },
    {
        "content": "<p>From: José Manuel Rodriguez Caballero &lt;<a href=\"mailto:josephcmac@gmail.com\">josephcmac@gmail.com</a>&gt;</p>\n<blockquote>\n<p>Michal wrote:<br>\nAlso... My impression (and I could be wrong about this) is that most of the<br>\nusers of Isabelle are not just<br>\ngoing it alone, but are academics working closely with and being taught by<br>\nother people who are<br>\nintimately familiar with the system already. Nobody's written a \"Learn You<br>\nan Isar for Great Good\" and<br>\nthere's not (yet) been a huge influx of curious outsiders blazing trails<br>\nfor everyone else.</p>\n</blockquote>\n<p>Another motivation to learn Isar for an outsider is to avoid the authority<br>\nfallacy and to discover by oneself his mistakes if there are any. Indeed, I<br>\nknow someone who claimed a solution of many mathematical open problems,<br>\nincluding the Riemann Hypothesis and the experts did not read his papers,<br>\nbecause they assumed that the author was wrong. My advice to him was this:<br>\ntry to formalize your proof in Isar and if you succeed, all mathematicians<br>\nwill take you seriously. Here is the link to the claim of solution of the<br>\nRiemann Hypothesis (I did not read this paper for the same reason that I am<br>\ncriticizing): <a href=\"https://arxiv.org/pdf/1804.04700.pdf\">https://arxiv.org/pdf/1804.04700.pdf</a></p>\n<p>In the case of the young Norwegian genius Niels Abel, who discovered that<br>\nthe 5th equation cannot be solved in radicals, when he sent his proof to<br>\nGauss, who was very famous at that time, laughing, Gauss did not read it,<br>\nthinking that Niels Abel was just another crank.</p>\n<p>Michal wrote:</p>\n<blockquote>\n<p>So that<br>\nmeans people like you and me (who seem to be sometimes frustrated<br>\noutsiders) have on opportunity<br>\nto be the trailblazers -- the ones who subject ourselves to getting lost<br>\nfor a while, knowing<br>\nthat when we eventually do find our way, we can make it easier for the next<br>\nperson.</p>\n</blockquote>\n<p>In my case, although I am an outsider in the sense that I had not the<br>\nopportunity to work in Isabelle in an academic program yet, I do not feel<br>\nfrustrated with Isabelle. On the contrary, I think that Isabelle is very<br>\neasy to learn and very practical in order to formally verify my own<br>\nmathematical results before publication. In that way, the reviewing process<br>\nin the journal is quickly.</p>\n<p>I do not think that people using Isar are a kind of trailblazers, because<br>\nIsar is just a formalization of the traditional way to write in<br>\nmathematics. Since Euclid, mathematicians are doing Isar, maybe with other<br>\nwords (in written in Ancient Greek). If you want to be a trailblazer in the<br>\nway people do mathematics, write a code in UniMath, which is a revolution<br>\nin mathematics: <a href=\"https://github.com/UniMath/UniMath\">https://github.com/UniMath/UniMath</a></p>\n<p>As I already said, one of my dreams is that Isabelle will use homotopy type<br>\ntheory someday, because the homotopy type theory in Coq lacks something so<br>\nfundamental as Isar.</p>\n<p>Kind Regards,<br>\nJose M.</p>",
        "id": 294739676,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191066
    },
    {
        "content": "<p>From: Lars Hupel &lt;<a href=\"mailto:hupel@in.tum.de\">hupel@in.tum.de</a>&gt;<br>\nThe maintenance situation in Isabelle is way ahead of other <br>\nsub-disciplines in computer science. If you insist on nothing to change <br>\never, you'll get stasis.</p>\n<p>(Relatedly, I really don't like the insinuation that Isabelle developers <br>\ndon't care about old things, because that's very much not the case.)</p>",
        "id": 294739691,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191071
    },
    {
        "content": "<p>From: Jeremy Dawson &lt;<a href=\"mailto:Jeremy.Dawson@anu.edu.au\">Jeremy.Dawson@anu.edu.au</a>&gt;<br>\nOn 08/15/2018 06:44 PM, Lars Hupel wrote:</p>\n<blockquote>\n<blockquote>\n<p>I accept that.  My remark was prompted by the attitude of the \"owners\"<br>\nof Isabelle to proofs dating from earlier than 14 years ago.<br>\n(To be fair, this is no doubt attributable to the \"owners\" of Isabelle<br>\n14 years ago than to the \"owners\" of Isabelle now).</p>\n<p>Obviously the concern would be that the same attitudes resurface.</p>\n</blockquote>\n<p>The maintenance situation in Isabelle is way ahead of other <br>\nsub-disciplines in computer science. If you insist on nothing to change <br>\never, you'll get stasis.</p>\n<p>Hi Lars,</p>\n</blockquote>\n<p>No I don't insist on that.  Backward compatibility is what the situation <br>\ncalls for.  Like how you can read 15-year old pdf documents.</p>\n<blockquote>\n<p>(Relatedly, I really don't like the insinuation that Isabelle developers <br>\ndon't care about old things, because that's very much not the case.)</p>\n</blockquote>\n<p>I actually know something about this - all my Isabelle proofs work with <br>\nIsabelle 2005 or earlier (because they are (almost) all from before <br>\nthen, build upon work from before then, or are an adaptation of work <br>\nfrom before then).  Makarius Wenzel suggested I rewrite the lot. Not <br>\nsuprisingly, that is not what I'm paid to do.</p>\n<p>Cheers,</p>\n<p>Jeremy</p>",
        "id": 294739835,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191121
    },
    {
        "content": "<p>From: Lars Hupel &lt;<a href=\"mailto:hupel@in.tum.de\">hupel@in.tum.de</a>&gt;</p>\n<blockquote>\n<p>No I don't insist on that.  Backward compatibility is what the situation<br>\ncalls for.  Like how you can read 15-year old pdf documents.</p>\n</blockquote>\n<p>Apples and oranges. PDF is a standardized format with significant<br>\nindustry buy-in. Isar isn't.</p>\n<p>(Apart from that, you can also still read Isabelle proof documents. You<br>\njust can't change them easily. Incidentally, the same situation as for<br>\nPDFs.)</p>\n<blockquote>\n<p>I actually know something about this - all my Isabelle proofs work with<br>\nIsabelle 2005 or earlier (because they are (almost) all from before<br>\nthen, build upon work from before then, or are an adaptation of work<br>\nfrom before then).  Makarius Wenzel suggested I rewrite the lot. Not<br>\nsuprisingly, that is not what I'm paid to do.</p>\n</blockquote>\n<p>Same argument applies. People developing Isabelle are not paid to<br>\nmaintain 100% backwards compatibility.</p>",
        "id": 294739842,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661191127
    },
    {
        "content": "<p>From: Michal Wallace &lt;<a href=\"mailto:michal.wallace@gmail.com\">michal.wallace@gmail.com</a>&gt;<br>\nI am working on formalizing Euler’s relation between the number of<br>\nn-dimensional faces of a polytope (aka the polyhedron formula), and then<br>\nhopefully using this to derive Pick’s theorem for the area of polygons<br>\nwhose vertices fall on integer lattice points in the plane.</p>\n<p>I intend to approach both proofs using arguments based on induction over a<br>\ntriangulation.</p>\n<p>There are a couple theorems relating to triangulations in<br>\nHOL/Analysis/Polytope.thy but I suspect I will need to generalize and<br>\nrefactor them a bit if they are to be useful for me.</p>\n<p>For the first proof, in each step, I start with a convex polytope and want<br>\nto make a single cut that separates one of its vertices, leaving me with<br>\ntwo convex polytopes.</p>\n<p>For the second proof, I want to start with an arbitrary simple polygon (not<br>\nnecessarily convex), and end up with a bijection between lattice points in<br>\nthe polygon and vertices in the triangulation. Here, instead of one cut<br>\ngoing all the way through the polygon at each step, I need to make several<br>\nsmall cuts as I add each new vertex to the triangulation.</p>\n<p>Basically, I seem to need some fine grained control over how the<br>\ntriangulation is performed.</p>\n<p>Here is what I’m currently thinking:</p>\n<p>1.</p>\n<p>A “cell_complex” is a recursive data type, where each interior node<br>\n   represents a (generic) cut, and each leaf represents a polytope.<br>\n   2.</p>\n<p>A “triangulation” is a subtype of “cell_complex” where each leaf is a<br>\n   simplex.<br>\n   3.</p>\n<p>A “cut” is a type parameter to those type, so cuts can be hyperplanes in<br>\n   one case, and lists of line segments in the other, and so other people can<br>\n   apply the idea to their own ends.<br>\n   4.</p>\n<p>A ‘ cut strategy is a function of type:: polytope =&gt; ‘cut triangulation<br>\n   =&gt; ‘cut<br>\n   5.</p>\n<p>Finally, I provide some generic function (polytope =&gt; ‘cut strategy =&gt;<br>\n   ‘cut triangulation) takes care of the actual construction.</p>\n<p>My hope is that with this strategy, I will be able to:</p>\n<p>1.</p>\n<p>Reason inductively about relationships either the polytope or the<br>\n   resulting triangulation:<br>\n   1.</p>\n<p>Proof 1 : Euler’s relation holds for polytopes in dimension D if it<br>\n      holds in all dimensions &lt; D and it holds for the two parts after making a<br>\n      cut [1]<br>\n      2.</p>\n<p>Proof 2: certain relationships between the numbers of edges, interior<br>\n      points, and boundary points hold for the triangulation itself,<br>\nas each new<br>\n      point is added. [2]<br>\n      2.</p>\n<p>I will be able to execute the algorithms on actual polytopes that I<br>\n   construct in code, and produce nice little diagrams for the final paper.</p>\n<p>I’m a programmer by trade, so I’m pretty confident in my ability to handle<br>\npart 2. I’m not so certain about part 1.</p>\n<p>So… I think I’m basically asking for a sanity check on this approach. Does<br>\nit make sense? Are there things I should be looking at that already do<br>\nsomething like this? Am I going to run into trouble mixing ideas from<br>\nprogramming and geometry like this? Should I try to refactor the theorems<br>\nin Polytope.thy or just start from scratch?</p>\n<p>Or is there a better way of approaching this altogether?</p>\n<p>Thanks!</p>\n<p>For reference, the informal proofs I’m working from are:</p>\n<p>Helge Tverberg, “How to cut a convex polytope into simplices”</p>\n<p><a href=\"https://vdocuments.site/documents/how-to-cut-a-convex-polytope-into-simplices.html\">https://vdocuments.site/documents/how-to-cut-a-convex-polytope-into-simplices.html</a></p>\n<p>W.W. Funkenbusch, “From Euler’s Formula to Pick’s Theorem, using an Edge<br>\nTheorem”</p>\n<p><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.919&amp;rep=rep1&amp;type=pdf\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.919&amp;rep=rep1&amp;type=pdf</a></p>",
        "id": 294742449,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661192102
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nThanks for your email. My name is at the top of Polytope.thy, but I'm afraid I don't know much about polytopes. I just ported this material from HOL Light. Pick’s theorem is also available in HOL Light, and from my perspective, the easiest way to reach it is by porting John Harrison's proof. That's because I'm very familiar with HOL Light's tactics, so this may not work for you. Nevertheless, there must be many valuable clues in the file <a href=\"http://pick.ml\">pick.ml</a> &lt;<a href=\"https://github.com/jrh13/hol-light/blob/master/100/pick.ml\">https://github.com/jrh13/hol-light/blob/master/100/pick.ml</a>&gt;, and its prerequisites have already been reported.</p>\n<p>Larry</p>",
        "id": 294742496,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661192127
    },
    {
        "content": "<p>From: José Manuel Rodriguez Caballero &lt;<a href=\"mailto:josephcmac@gmail.com\">josephcmac@gmail.com</a>&gt;<br>\nBoth Euler's formula its application to Pick's theorem are explained in a<br>\nvery pedagogical way in chapter 12 of the following book:</p>\n<p>Aigner, Martin, et al. <em>Proofs from the Book</em>. Vol. 274. Berlin: Springer,<br>\n2010. (You may find a link after a quickly search in google)</p>\n<p>Concerning your question</p>\n<p>Proof 1 : Euler’s relation holds for polytopes in dimension D if it</p>\n<blockquote>\n<p>holds in all dimensions &lt; D and it holds for the two parts after<br>\nmaking a<br>\n      cut [1] So… I think I’m basically asking for a sanity check on this<br>\napproach. Does<br>\nit make sense? Are there things I should be looking at that already do<br>\nsomething like this? Am I going to run into trouble mixing ideas from<br>\nprogramming and geometry like this?</p>\n</blockquote>\n<p>This is the hard way to prove it. The easy way is to interprete Euler's<br>\nformula as a theorem in Graph Theory and then to deduce its application to<br>\na polytope as a trivial corollary (see the book that I cited to find the<br>\ndetails). Dimension plays no essential role, because it is just a theorem<br>\nabout a graph.</p>\n<p>Concerning you observation:</p>\n<p>I’m a programmer by trade, so I’m pretty confident in my ability to handle</p>\n<blockquote>\n<p>part 2. I’m not so certain about part 1.</p>\n</blockquote>\n<p>In my case, I'm a mathematician by trade (Master degree), and the<br>\nprogramming part is what I am learning right now thanks to the people of<br>\nthis mailing list. By the way, I'm open to consider any PhD position where<br>\nI can apply my mathematical skills to Isabelle or another proof assistant.</p>\n<p>Kind Regards,<br>\nJose M.</p>\n<p>Message: 1</p>\n<blockquote>\n<p>Date: Sat, 11 Aug 2018 18:13:15 -0400<br>\nFrom: Michal Wallace &lt;<a href=\"mailto:michal.wallace@gmail.com\">michal.wallace@gmail.com</a>&gt;<br>\nSubject: [isabelle] Help with Triangulation<br>\nTo: <a href=\"mailto:isabelle-users@cl.cam.ac.uk\">isabelle-users@cl.cam.ac.uk</a><br>\nMessage-ID:<br>\n        &lt;CAE6HCjn7tjCY6W48v_JdzgndOGEdhcUdrCons6wGZ3U1yJgU<br>\n<a href=\"mailto:gw@mail.gmail.com\">gw@mail.gmail.com</a>&gt;<br>\nContent-Type: text/plain; charset=\"UTF-8\"</p>\n<p>I am working on formalizing Euler’s relation between the number of<br>\nn-dimensional faces of a polytope (aka the polyhedron formula), and then<br>\nhopefully using this to derive Pick’s theorem for the area of polygons<br>\nwhose vertices fall on integer lattice points in the plane.</p>\n<p>I intend to approach both proofs using arguments based on induction over a<br>\ntriangulation.</p>\n<p>There are a couple theorems relating to triangulations in<br>\nHOL/Analysis/Polytope.thy but I suspect I will need to generalize and<br>\nrefactor them a bit if they are to be useful for me.</p>\n<p>For the first proof, in each step, I start with a convex polytope and want<br>\nto make a single cut that separates one of its vertices, leaving me with<br>\ntwo convex polytopes.</p>\n<p>For the second proof, I want to start with an arbitrary simple polygon (not<br>\nnecessarily convex), and end up with a bijection between lattice points in<br>\nthe polygon and vertices in the triangulation. Here, instead of one cut<br>\ngoing all the way through the polygon at each step, I need to make several<br>\nsmall cuts as I add each new vertex to the triangulation.</p>\n<p>Basically, I seem to need some fine grained control over how the<br>\ntriangulation is performed.</p>\n<p>Here is what I’m currently thinking:</p>\n<p>1.</p>\n<p>A “cell_complex” is a recursive data type, where each interior node<br>\n   represents a (generic) cut, and each leaf represents a polytope.<br>\n   2.</p>\n<p>A “triangulation” is a subtype of “cell_complex” where each leaf is a<br>\n   simplex.<br>\n   3.</p>\n<p>A “cut” is a type parameter to those type, so cuts can be hyperplanes in<br>\n   one case, and lists of line segments in the other, and so other people<br>\ncan<br>\n   apply the idea to their own ends.<br>\n   4.</p>\n<p>A ‘ cut strategy is a function of type:: polytope =&gt; ‘cut triangulation<br>\n   =&gt; ‘cut<br>\n   5.</p>\n<p>Finally, I provide some generic function (polytope =&gt; ‘cut strategy =&gt;<br>\n   ‘cut triangulation) takes care of the actual construction.</p>\n<p>My hope is that with this strategy, I will be able to:</p>\n<p>1.</p>\n<p>Reason inductively about relationships either the polytope or the<br>\n   resulting triangulation:<br>\n   1.</p>\n<p>Proof 1 : Euler’s relation holds for polytopes in dimension D if it<br>\n      holds in all dimensions &lt; D and it holds for the two parts after<br>\nmaking a<br>\n      cut [1]<br>\n      2.</p>\n<p>Proof 2: certain relationships between the numbers of edges, interior<br>\n      points, and boundary points hold for the triangulation itself,<br>\nas each new<br>\n      point is added. [2]<br>\n      2.</p>\n<p>I will be able to execute the algorithms on actual polytopes that I<br>\n   construct in code, and produce nice little diagrams for the final paper.</p>\n<p>I’m a programmer by trade, so I’m pretty confident in my ability to handle<br>\npart 2. I’m not so certain about part 1.</p>\n<p>So… I think I’m basically asking for a sanity check on this approach. Does<br>\nit make sense? Are there things I should be looking at that already do<br>\nsomething like this? Am I going to run into trouble mixing ideas from<br>\nprogramming and geometry like this? Should I try to refactor the theorems<br>\nin Polytope.thy or just start from scratch?</p>\n<p>Or is there a better way of approaching this altogether?</p>\n<p>Thanks!</p>\n<p>For reference, the informal proofs I’m working from are:</p>\n<p>Helge Tverberg, “How to cut a convex polytope into simplices”</p>\n<p><a href=\"https://vdocuments.site/documents/how-to-cut-a-convex-\">https://vdocuments.site/documents/how-to-cut-a-convex-</a><br>\npolytope-into-simplices.html</p>\n<p>W.W. Funkenbusch, “From Euler’s Formula to Pick’s Theorem, using an Edge<br>\nTheorem”</p>\n<p><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1</a>.<br>\n475.919&amp;rep=rep1&amp;type=pdf</p>\n</blockquote>",
        "id": 294742515,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661192139
    },
    {
        "content": "<p>From: José Manuel Rodriguez Caballero &lt;<a href=\"mailto:josephcmac@gmail.com\">josephcmac@gmail.com</a>&gt;<br>\nBoth Euler's formula its application to Pick's theorem are explained in a<br>\nvery pedagogical way in chapter 12 of the following book:</p>\n<p>Aigner, Martin, et al. <em>Proofs from the Book</em>. Vol. 274. Berlin: Springer,<br>\n2010. (You may find a link after a quickly search in google)</p>\n<p>Concerning your question</p>\n<p>Proof 1 : Euler’s relation holds for polytopes in dimension D if it</p>\n<blockquote>\n<p>holds in all dimensions &lt; D and it holds for the two parts after<br>\nmaking a<br>\n      cut [1] So… I think I’m basically asking for a sanity check on this<br>\napproach. Does<br>\nit make sense? Are there things I should be looking at that already do<br>\nsomething like this? Am I going to run into trouble mixing ideas from<br>\nprogramming and geometry like this?</p>\n</blockquote>\n<p>This is the hard way to prove it. The easy way is to interprete Euler's<br>\nformula as a theorem in Graph Theory and then to deduce its application to<br>\na polytope as a trivial corollary (see the book that I cited to find the<br>\ndetails). Dimension plays no essential role, because it is just a theorem<br>\nabout a graph.</p>\n<p>Concerning you observation:</p>\n<p>I’m a programmer by trade, so I’m pretty confident in my ability to handle</p>\n<blockquote>\n<p>part 2. I’m not so certain about part 1.</p>\n</blockquote>\n<p>In my case, I'm a mathematician by trade (Master degree), and the<br>\nprogramming part is what I am learning right now thanks to the people of<br>\nthis mailing list. By the way, I'm open to consider any PhD position where<br>\nI can apply my mathematical skills to Isabelle or another proof assistant.</p>\n<p>Kind Regards,<br>\nJose M.</p>\n<p>Message: 1</p>\n<blockquote>\n<p>Date: Sat, 11 Aug 2018 18:13:15 -0400<br>\nFrom: Michal Wallace &lt;<a href=\"mailto:michal.wallace@gmail.com\">michal.wallace@gmail.com</a>&gt;<br>\nSubject: [isabelle] Help with Triangulation<br>\nTo: <a href=\"mailto:isabelle-users@cl.cam.ac.uk\">isabelle-users@cl.cam.ac.uk</a><br>\nMessage-ID:<br>\n        &lt;CAE6HCjn7tjCY6W48v_JdzgndOGEdhcUdrCons6wGZ3U1yJgUgw@mail.<br>\n<a href=\"http://gmail.com\">gmail.com</a>&gt;<br>\nContent-Type: text/plain; charset=\"UTF-8\"</p>\n<p>I am working on formalizing Euler’s relation between the number of<br>\nn-dimensional faces of a polytope (aka the polyhedron formula), and then<br>\nhopefully using this to derive Pick’s theorem for the area of polygons<br>\nwhose vertices fall on integer lattice points in the plane.</p>\n<p>I intend to approach both proofs using arguments based on induction over a<br>\ntriangulation.</p>\n<p>There are a couple theorems relating to triangulations in<br>\nHOL/Analysis/Polytope.thy but I suspect I will need to generalize and<br>\nrefactor them a bit if they are to be useful for me.</p>\n<p>For the first proof, in each step, I start with a convex polytope and want<br>\nto make a single cut that separates one of its vertices, leaving me with<br>\ntwo convex polytopes.</p>\n<p>For the second proof, I want to start with an arbitrary simple polygon (not<br>\nnecessarily convex), and end up with a bijection between lattice points in<br>\nthe polygon and vertices in the triangulation. Here, instead of one cut<br>\ngoing all the way through the polygon at each step, I need to make several<br>\nsmall cuts as I add each new vertex to the triangulation.</p>\n<p>Basically, I seem to need some fine grained control over how the<br>\ntriangulation is performed.</p>\n<p>Here is what I’m currently thinking:</p>\n<p>1.</p>\n<p>A “cell_complex” is a recursive data type, where each interior node<br>\n   represents a (generic) cut, and each leaf represents a polytope.<br>\n   2.</p>\n<p>A “triangulation” is a subtype of “cell_complex” where each leaf is a<br>\n   simplex.<br>\n   3.</p>\n<p>A “cut” is a type parameter to those type, so cuts can be hyperplanes in<br>\n   one case, and lists of line segments in the other, and so other people<br>\ncan<br>\n   apply the idea to their own ends.<br>\n   4.</p>\n<p>A ‘ cut strategy is a function of type:: polytope =&gt; ‘cut triangulation<br>\n   =&gt; ‘cut<br>\n   5.</p>\n<p>Finally, I provide some generic function (polytope =&gt; ‘cut strategy =&gt;<br>\n   ‘cut triangulation) takes care of the actual construction.</p>\n<p>My hope is that with this strategy, I will be able to:</p>\n<p>1.</p>\n<p>Reason inductively about relationships either the polytope or the<br>\n   resulting triangulation:<br>\n   1.</p>\n<p>Proof 1 : Euler’s relation holds for polytopes in dimension D if it<br>\n      holds in all dimensions &lt; D and it holds for the two parts after<br>\nmaking a<br>\n      cut [1]<br>\n      2.</p>\n<p>Proof 2: certain relationships between the numbers of edges, interior<br>\n      points, and boundary points hold for the triangulation itself,<br>\nas each new<br>\n      point is added. [2]<br>\n      2.</p>\n<p>I will be able to execute the algorithms on actual polytopes that I<br>\n   construct in code, and produce nice little diagrams for the final paper.</p>\n<p>I’m a programmer by trade, so I’m pretty confident in my ability to handle<br>\npart 2. I’m not so certain about part 1.</p>\n<p>So… I think I’m basically asking for a sanity check on this approach. Does<br>\nit make sense? Are there things I should be looking at that already do<br>\nsomething like this? Am I going to run into trouble mixing ideas from<br>\nprogramming and geometry like this? Should I try to refactor the theorems<br>\nin Polytope.thy or just start from scratch?</p>\n<p>Or is there a better way of approaching this altogether?</p>\n<p>Thanks!</p>\n<p>For reference, the informal proofs I’m working from are:</p>\n<p>Helge Tverberg, “How to cut a convex polytope into simplices”</p>\n<p><a href=\"https://vdocuments.site/documents/how-to-cut-a-convex-polyto\">https://vdocuments.site/documents/how-to-cut-a-convex-polyto</a><br>\npe-into-simplices.html</p>\n<p>W.W. Funkenbusch, “From Euler’s Formula to Pick’s Theorem, using an Edge<br>\nTheorem”</p>\n<p><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475</a><br>\n.919&amp;rep=rep1&amp;type=pdf</p>\n</blockquote>",
        "id": 294742526,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661192145
    },
    {
        "content": "<p>From: Manuel Eberl &lt;<a href=\"mailto:eberlm@in.tum.de\">eberlm@in.tum.de</a>&gt;<br>\nI'm not so sure about the \"trivial\" part. Connecting the graph-theoretic<br>\nnotions of vertices, edges, and faces to the geometric ones in a formal<br>\nsetting is probably not /that/ easy. In fact, it may well be the most<br>\ndifficult part of the entire proof.</p>\n<p>Manuel</p>",
        "id": 294742536,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661192151
    },
    {
        "content": "<p>From: José Manuel Rodriguez Caballero &lt;<a href=\"mailto:josephcmac@gmail.com\">josephcmac@gmail.com</a>&gt;</p>\n<blockquote>\n<p>Manuel Eberl said<br>\nI'm not so sure about the \"trivial\" part. Connecting the graph-theoretic<br>\nnotions of vertices, edges, and faces to the geometric ones in a formal<br>\nsetting is probably not /that/ easy. In fact, it may well be the most<br>\ndifficult part of the entire proof.</p>\n</blockquote>\n<p>The Euler's formula that Michal needs in order to derive Pick's theorem as<br>\na corollary is the following graph theoretic statement: V - E + F = 2 for<br>\nany connected planar graph, where V is the number of vertices, E the number<br>\nof edges and F the number of faces. Indeed, this is the approach followed<br>\nin the reference cited by Michal in his email: Funkenbusch W. W. From<br>\nEuler’s formula to Pick’s formula using an edge theorem. The American<br>\nMathematical Monthly. 1974 Jun 1;81(6):647-8.<br>\n<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.919&amp;rep=rep1&amp;type=pdf\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.919&amp;rep=rep1&amp;type=pdf</a></p>\n<p>So, what Micha calls the Euler’s relation between the number of n-dimensional<br>\nfaces of a polytope is not used in Funkenbusch's paper. Of course, if Micha<br>\nis interested in formalized such an n-dimensional formula anyway, he needs<br>\nto generalize my advise to dimension n, because I just sent him the<br>\nreference for n = 3, which is the only case required for proving Pick's<br>\ntheorem. A claim of new proof of this result is here (I did not check it<br>\nbecause I do not like this approach): <a href=\"https://arxiv.org/pdf/1612.01271.pdf\">https://arxiv.org/pdf/1612.01271.pdf</a></p>\n<p>I do not retract about my claim in the previous email: the more natural way<br>\nto prove Euler's formula is using graph theory and its generalization to<br>\npolytopes is trivial in the sense that no deep mathematical result is<br>\nneeded, although you may write a little bit of code in Isabelle just to<br>\nformalize the geometric intuition. The only detail is that you need a<br>\ngeneralization of graph named CW-complex. Any undirected graph (loops<br>\nand/or multiple edges allowed) has a geometric realization as a<br>\n1-dimensional CW-complex.</p>\n<p>According to Alexander Grothendieck, all your mathematical proofs become<br>\ntrivial provided that you have the right definitions. It is important to<br>\nnotice that the Euler characteristic of a CW-complex depends only of this<br>\nhomotopy type. So, the more natural setting to formalize this theorem<br>\nshould be homotopy type theory, where you do not even need real numbers<br>\n!!!!, but you can do it in Isabelle as well. Indeed, I recommend to<br>\nformalize the proof in Isabelle as follows (I'm following my own approach<br>\nwith looking at any textbooks, maybe there are simpler approaches in<br>\nliterature):</p>\n<p>Step 1. You define a CW-complex in Isabelle (combinatorial/algebraic<br>\nstaff). <a href=\"https://en.wikipedia.org/wiki/CW_complex\">https://en.wikipedia.org/wiki/CW_complex</a></p>\n<p>Step 2. You define cellular homology in Isabelle (combinatorial/algebraic<br>\nstaff). <a href=\"https://en.wikipedia.org/wiki/Cellular_homology\">https://en.wikipedia.org/wiki/Cellular_homology</a></p>\n<p>Step 3. You define the Euler's characteristic as the alternated sum of the<br>\nranks of the homology groups.</p>\n<p>Step 4. You prove the Gauss-Bonnet theorem, either in its general form:<br>\n<a href=\"https://en.wikipedia.org/wiki/Gauss%E2%80%93Bonnet_theorem\">https://en.wikipedia.org/wiki/Gauss%E2%80%93Bonnet_theorem</a></p>\n<p>or just its particular case for polytopes (due to Rene Descartes):<br>\n<a href=\"https://en.wikipedia.org/wiki/Angular_defect#Descartes.27_theorem\">https://en.wikipedia.org/wiki/Angular_defect#Descartes.27_theorem</a></p>\n<p>Step 5. You apply the Gauss-Bonnet theorem (or just its particular case for<br>\npolytopes) to an n-dimensional hypercube in order to show that its Euler<br>\ncharacteristic is 1. This computation is trivial.</p>\n<p>Step 6. You show that any convex polytope is homeomorphic to an hypercube<br>\nof the same dimension. This is trivial too.</p>\n<p>Step 7. In virtue of the definition of cellular homology and the result<br>\nproved in step 5, the Euler characteristic of any convex polytope is 1. We<br>\ncan also say that this happens because the Euler characteristic is a<br>\ntopological property, i.e., it is invariant with respect to homeomorphisms.</p>\n<p>Step 8. You express your n-dimensional convex polytope as a CW-complex and<br>\nyou apply the definition of Euler's characteristic from step 3.</p>\n<p>Step 9. You deduce that the number of k-dimensional faces in your convex<br>\npolytope is equal to the rank of its k-th homology group. This follows from<br>\nthe definition of the cellular homology.</p>\n<p>Step 10. You obtain that the alternated sum of the k-dimensional faces of<br>\nyour polytope is 1. This is the generalized Euler's formula, also named the<br>\nEuler-Poincare's formula. QED</p>\n<p>Why the original Euler's formula involves the number 2 whereas its<br>\ngeneralization involves the number 1? This is because, Euler's formula, in<br>\nits original form V - E + F = 2, is not about a 3D convex polytope, but<br>\nabout its surface (in the general case, we prefer to use the word boundary<br>\nin place of the word surface). Notice that we can express V - E + F = 2 as<br>\nfollows:</p>\n<p>V - E + F - T = 1,</p>\n<p>where T = 1 is the number of 3-dimensional faces of the corresponding<br>\nCW-complex, i.e., the polytope itself.</p>\n<p>If you watch the following video, the above mentioned results will be<br>\neasier to understand: <a href=\"https://www.youtube.com/watch?v=1wtq5A7VMsA\">https://www.youtube.com/watch?v=1wtq5A7VMsA</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"1wtq5A7VMsA\" href=\"https://www.youtube.com/watch?v=1wtq5A7VMsA\"><img src=\"https://uploads.zulipusercontent.net/0dcd3cdea9be90406204d285f9efc12370e2b6c7/68747470733a2f2f692e7974696d672e636f6d2f76692f31777471354137564d73412f64656661756c742e6a7067\"></a></div><p>Also, the following book may be useful for such a formalization:<br>\nHatcher A. Algebraic topology. 清华大学出版社有限公司; 2005.<br>\n<a href=\"https://pi.math.cornell.edu/~hatcher/AT/AT.pdf\">https://pi.math.cornell.edu/~hatcher/AT/AT.pdf</a></p>\n<p>A topological formulation of Euler-Poincare's formula in terms of<br>\nCW-complexes is more useful for mathematician and physicists than the<br>\nparticular case about polytopes. For example, to apply this formula to<br>\nquantum mechanics or general relativity you need the topological version,<br>\nbecause the space where these people are working may be non-Euclidean, but<br>\nthe topological version still holds.</p>\n<p>Good luck,<br>\nJose M.</p>\n<blockquote>\n<p>This is the hard way to prove it. The easy way is to interprete Euler's</p>\n<blockquote>\n<p>formula as a theorem in Graph Theory and then to deduce its application<br>\nto<br>\na polytope as a trivial corollary (see the book that I cited to find the<br>\ndetails). Dimension plays no essential role, because it is just a theorem<br>\nabout a graph.<br>\nI'm not so sure about the \"trivial\" part. Connecting the graph-theoretic<br>\nnotions of vertices, edges, and faces to the geometric ones in a formal<br>\nsetting is probably not /that/ easy. In fact, it may well be the most<br>\ndifficult part of the entire proof.<br>\nManuel</p>\n</blockquote>\n</blockquote>",
        "id": 294742684,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661192201
    }
]