[
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nBack to this thread after the initial round of discussion ...</p>\n<p>First of all, I don't see much of a technical problem here, but mainly a <br>\nsocial one.  A bit too many things not explicitly spelled out; a bit too <br>\nmany rumors and private mailing threads about \"Isabelle/HOL is <br>\ninconsistent\", already since summer 2014.</p>\n<p>For years we have tried to establish isabelle-dev (also isabelle-users) as <br>\na professional channel for open discussion about presumed problems, <br>\npotential solutions, proposals for changes etc.  That works out half way, <br>\nand needs more efforts.</p>\n<p>On other mailing lists (e.g. Coq-club) I see routinely the discussion of <br>\ngenuine logical breakdowns without much excitement about it.  The Coq/HoTT <br>\nimplementation even seems to require patching Coq to disable critical <br>\nchecks, for the elite of users who really know what there are doing at the <br>\nbleeding edge ...</p>\n<p>The present thread is essentially about the paper \"A Consistent Foundation <br>\nfor Isabelle/HOL\" by O. Kuncar and A. Popescu, ITP 2015.</p>",
        "id": 294652739,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166776
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:tjark.weber@it.uu.se\">tjark.weber@it.uu.se</a>&gt;<br>\nBeyond the specific def/overloading issue, there is a more fundamental<br>\nproblem. Isabelle (and other proof assistants) have evolved in a social<br>\ncontext where users typically act in good faith.</p>\n<p>It is a fact that is neither widely advertised nor, as far as I can<br>\ntell, well-understood outside a small community that Isabelle theories<br>\nare not actually machine-checked proofs. (Sure, theories may contain<br>\nproofs that can be checked by Isabelle. But if someone gives you an<br>\nIsabelle theory and claims that it proves, e.g, FLT, there is no<br>\nmachine that could decide this claim for you.)</p>\n<p>This can be addressed in various ways, of course. You give several<br>\npages of \"methodological recommendations\" in your white paper,<br>\nessentially attempting to identify a safe subset of Isabelle/Isar. HOL<br>\nZero and proof terms are other approaches, with different drawbacks.</p>\n<p>Surely satisfactory solutions will be developed eventually, when people<br>\nperceive this problem as sufficiently important.</p>\n<p>Best,<br>\nTjark</p>",
        "id": 294652849,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166822
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nThe length of this dicussion puzzles me. Typedef can introduce inconsistencies, <br>\nnobody wants this behaviour and nobody needs this behaviour. There is a <br>\nperfectly clear way to rule out this whole class of unwanted behaviours: do not <br>\nallow certain cycles. This solution, including code, has been on the table for a <br>\nyear now. By now not just mere users but also certification agencies are <br>\nworried. This is a pressing issue and it is not rocket science.</p>\n<p>Everything else is secondary. It is nice that Andrei's and Ondrej's paper <br>\nestablishes certain logical properties of their improved system, and it is <br>\ninteresting to discuss these properties, but the most important thing is the <br>\nactual addition of a cycle check to the code.</p>\n<p>Tobias<br>\n<a href=\"/user_uploads/14278/pgAxg46SJ0cNhEBD0hsBggHM/smime.p7s\">smime.p7s</a></p>",
        "id": 294652934,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166844
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nTo get beyond the black-and-white of the Inconsistency Club vs. Consistency<br>\nClub, here are some more shades and dimensions.</p>\n<p>The subsequent classification of reliability and robustness of proof<br>\nassistants follows the tradition of the \"LCF-approach\", which has two main<br>\ningredients:</p>\n<p>(1) a programming language with strong type-safety properties (the<br>\n   \"meta-language\" ML)</p>\n<p>(2) an implementation of the logical core as abstract datatype thm<br>\n   within ML</p>\n<p>The key ML modules should be reasonable small, to make them obviously<br>\ncorrect (whatever that means precisely). Arbitrary derived tools may be put<br>\non top of that, without breaking things: all inferences going through the<br>\nthm module are \"correct-by-construction\".</p>\n<p>Both ingredients of the LCF approach are equally important. E.g. a<br>\nfully-formalized and proven implementation of the thm module that is exposed<br>\nto an unsafe ML environment still leads to an unreliable system, if the user<br>\nis able to poke around arbitrarily.</p>\n<p>To better capture the \"True LCF-nature\" of proof assistants 35 years after<br>\nLCF, lets consider qualities in following categories:</p>\n<p>[small] overall size of critical code modules.</p>\n<p>[ML] The implementation/extension language of the prover.</p>\n<p>[thm] The actual inference kernel, to derive theorems within a given<br>\n   theory.</p>\n<p>[defs] additional guarantees for \"definitional theories\", whatever that<br>\n   means precisely.</p>\n<p>[context] treatment of formal context (theory or proof context with formal<br>\n   declarations, additional tool data etc.).</p>\n<p>[logic] well-understood (by experts) and easy to understand (by users).</p>\n<p>[formalized] key aspects are formally specified or even proven (the logical<br>\n   calculus, models of the prover, the actual prover implementation etc.).</p>\n<p>The rating uses small natural numbers in unary notation: 0, +, ++, +++. More<br>\npluses mean somehow better. The scale is open-ended, but I will not go<br>\nbeyond +++ right now. 0 means neither good nor bad, just zero.</p>\n<p>The results below are based on my own understanding of these systems -- I've<br>\nstudied sources of all of them. The architects and engineers of the<br>\nmentioned systems are invited to improve on these estimates.</p>\n<p><strong> LCF </strong></p>\n<p>I only know the Cambridge LCF code base, by L. Paulson from around 1985.<br>\nOriginal LCF is hard to get by -- M. Gordon once showed a stack of printed<br>\nLISP + ML listings of it.</p>\n<p>[small]      +++<br>\n   [ML]         +++<br>\n   [thm]        +++<br>\n   [defs]       0<br>\n   [context]    0<br>\n   [logic]      ++<br>\n   [formalized] 0</p>\n<p>[small] + [ML] + [thm] define the game of \"LCF-style proof assistant\".<br>\nOriginal ML is embedded into LISP, and there is no system access, no<br>\nnon-sense like mutable strings or funny holes in the type-system.</p>\n<p>[defs] No definitions; the LCF logic is used axiomatically.</p>\n<p>[context] management is implicit in ML; there is no way to switch contexts<br>\nnor go back to older contexts.</p>\n<p>[logic] LCF as a logic is theoretically nice and clean, but not so easy to<br>\nunderstand for regular users.</p>\n<p><strong> HOL88 </strong></p>\n<p>HOL88 is like LCF, with the addition of checked definitional principles as<br>\npart of the kernel. Thus it goes beyond the original \"LCF-approach\" in a<br>\nsignificant way. Everything else is similar to LCF.</p>\n<p>[small]      +++<br>\n   [ML]         +++<br>\n   [thm]        +++<br>\n   [defs]       +++<br>\n   [context]    0<br>\n   [logic]      ++<br>\n   [formalized] 0</p>\n<p>[logic] Note that I don't give +++ for the logic here. The original \"Simple<br>\nType Theory\" is really nice and simple, especially in the exposition by W.<br>\nFarmer, \"The seven virtues of STT\"<br>\n<a href=\"http://www.sciencedirect.com/science/article/pii/S157086830700081X\">http://www.sciencedirect.com/science/article/pii/S157086830700081X</a></p>\n<p>In contrast, Gordon-HOL adds the important concepts of parametric<br>\npolymorphism and typedefs, together with considerable complexity. A proof of<br>\ndegraded simplicity is the historic misunderstanding about extra type<br>\nvariables in the body of definitions that don't occur in the type of the<br>\ndefined term. (In Isabelle-jargon this is called \"hidden polymorphism\", and<br>\nis causing horror and shudder to many veterans.)</p>\n<p><strong> HOL4 </strong></p>\n<p>HOL4 is the current incarnation of the HOL-line after HOL88, starting with<br>\nHOL90. It uses a self-hosting SML platform, instead of ML inside LISP.</p>\n<p>[small]      ++<br>\n   [ML]         ++<br>\n   [thm]        +++<br>\n   [defs]       +++<br>\n   [context]    0<br>\n   [logic]      +++<br>\n   [formalized] +</p>\n<p>[small] less small than the pioneering implementations, but still within<br>\nreason.</p>\n<p>[ML] I am giving only ++, since HOL4 resides in the raw toplevel of a<br>\nstandalone SML implementation. This allows to do various system-level<br>\nnon-sense, e.g. use interrupt signals (CTRL-C on TTY) or threads to disrupt<br>\nthe internal state of some modules (which expect strictly sequentional<br>\nexecution).</p>\n<p>[thm] + [defs] at its full height, especially after the formal treatment in<br>\n<a href=\"http://www.cl.cam.ac.uk/~rk436/itp14.pdf\">http://www.cl.cam.ac.uk/~rk436/itp14.pdf</a></p>\n<p>[context] is implicit in the ML environment (hidden mutable references).<br>\nImplementation not thread-safe; global assumption of sequentialism.<br>\nOtherwise as in LCF.</p>\n<p>[logic] I am giving +++ instead of ++ for HOL88, since the formal treatment<br>\nhas lead to various clarification of obscure details in the original book<br>\nchapters by A. Pitts in the HOL88 book.</p>\n<p>[formalized] See again <a href=\"http://www.cl.cam.ac.uk/~rk436/itp14.pdf\">http://www.cl.cam.ac.uk/~rk436/itp14.pdf</a> and more<br>\nrecent ongoing work. Looking forward to see results applied to actual HOL4,<br>\nor rather HOL5?</p>\n<p><strong> HOL-Light </strong></p>\n<p>This is the famous fork from the HOL family by John Harrison.</p>\n<p>[small]      +++<br>\n   [ML]         +<br>\n   [thm]        +++<br>\n   [defs]       +++<br>\n   [context]    0<br>\n   [logic]      ++<br>\n   [formalized] +</p>\n<p>[small] very small size of key modules.</p>\n<p>[ML] HOL-Light uses OCaml instead of SML. OCaml is much less safe than SML,<br>\ne.g. strings are mutable, ints overflow at unspecified word size without any<br>\nexception, various other oddities and deviations from original ML make it<br>\nhard to understand mathematically (e.g possibility for circular datatypes).<br>\nSignals allow to inject arbitrary ML exceptions into user code, not just<br>\ninterrupts. (I am not taking Obj.magic non-sense into account here, since<br>\nits absence can be easily detected by looking at the source.)</p>\n<p>There is still one + instead of 0, since OCaml is safer than C/C++.</p>\n<p>[thm], [defs], [context], [logic], [formalized] similar to HOL4.</p>\n<p><strong> Isabelle/HOL </strong></p>\n<p>Here \"Isabelle/HOL\" refers to the main product that end-users experience<br>\nwhen downloading Isabelle. Its sophisticated architecture based on Isabelle<br>\nas a framework for building logic-based tools needs to be kept in mind, when<br>\ntrying understand it thoroughly.</p>\n<p>[small]      +<br>\n   [ML]         +++<br>\n   [thm]        ++<br>\n   [defs]       +<br>\n   [context]    +++<br>\n   [logic]      +<br>\n   [formalized] 0</p>\n<p>[small] The assembly of Isabelle/ML modules is quite substantial just for<br>\nIsabelle/Pure, and more is added in the Isabelle/HOL library. Nonetheless,<br>\nthere are certain principles of building up in stages to manage complexity.</p>\n<p>[ML] extra-safe SML, since we do our own management of the ML compiler and<br>\nML environments, including proper treatment of signals and threads in the<br>\nrun-time system. Isabelle/ML could in principle do more to isolate user<br>\ncode from raw system access and other potential non-sense, but that would<br>\nmean ++++.</p>\n<p>[thm] roughly like in the HOL family, but extra features are hardwired into<br>\nthe inference kernel, such as higher-order unification or type-class<br>\ninferences. It is also not immediately clear, which modules contribute to<br>\nthe thm implementation and which not.</p>\n<p>[defs] constant definitions are fully checked (in Isabelle2014 and<br>\nIsabelle2015). HOL typedefs are not fully unchecked and thus \"axiomatic\" in<br>\nthe terminology of Isabelle: users are responsible to refrain from non-sense<br>\nwith overloading involving type constructors.</p>\n<p>[context] Type theory and Proof.context serve as immutable containers for<br>\nlogical reasoning, independently of implicit assumptions about time and<br>\nspace. This provides structural integrity that is not present in other<br>\nLCF-style proof assistant. E.g. it is possible to reason in parallel in<br>\ndifferent contexts undisturbed. Going back (\"undo\") to older states is<br>\ntrivial: in fact the user is working simultaneous in many different<br>\ncontexts, when editing a theory document.</p>\n<p>[logic] only one +, since type-classes add considerable complexity. The<br>\ntraditional idea is that this is just a front-end to plain HOL, with a<br>\nhypotheticla dictionary-construction, or something else still to be<br>\ndiscussed.</p>\n<p>[formalized] Nothing substantial yet. I don't expect a verified Isabelle<br>\nimplementation anytime soon, due to the sheer size and complexity of<br>\ncritical modules. It would be nice to transfer results from other HOL<br>\ngroups, e.g. by exporting to an independent checker in CakeML, OpenTheory<br>\netc.</p>\n<p><strong> Coq </strong></p>\n<p>Coq is strictly speaking not an LCF-style nor HOL-style system, but G. Huet<br>\nand L. Paulson were working together on Cambridge-LCF around 1985, and there<br>\nare undeniable family traces.</p>\n<p>[small]      +<br>\n   [ML]         +++<br>\n   [thm]        ++<br>\n   [defs]       ++<br>\n   [context]    +<br>\n   [logic]      +<br>\n   [formalized] +</p>\n<p>[small] critical Coq modules are about as big as in Isabelle -- I usually<br>\nestimate it to be slightly bigger than Isabelle, but this is open to<br>\ndiscussion.</p>\n<p>[ML] OCaml is used, but in a more sophisticated manner than in HOL-Light, to<br>\nmake up for the inherent weaknesses of the language. E.g. there are proper<br>\nintegers (not machine words) and proper strings (not mutable byte arrays).<br>\nCoq also manages its own byte-code interpreter, and more.</p>\n<p>[thm] Not an LCF-style abstract datatype, but separate checking, potentially<br>\nby an external program. At the level of abstraction of these notes, it is<br>\ndifficult to relate this to the other systems.</p>\n<p>[defs] Serious checking of definitions, with serious complexity built-in.</p>\n<p>[context] Just one context for theory and proofs. More explicit than in<br>\nclassic HOL family, but less versatile than in Isabelle. Tool context is<br>\nswapped in-and-out on a single global instance.  Not thread-safe.</p>\n<p>[logic] True<br>\n[message truncated]</p>",
        "id": 294652945,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166849
    },
    {
        "content": "<p>From: Freek Wiedijk &lt;<a href=\"mailto:freek@cs.ru.nl\">freek@cs.ru.nl</a>&gt;<br>\nMakarius:</p>\n<p>I think the newest OCaml support immutable strings?<br>\nAnd if in the kernel you would use nums instead of ints,<br>\nthen the second problems would be gone too?  (It would be<br>\ninteresting to know how much of a hassle this last change<br>\nwould be.  And maybe you only would need to go through<br>\nnums when you actually calculate with ints in the kernel?<br>\nDoes this even happen, and if so, in which functions?)</p>\n<p>Freek</p>",
        "id": 294652960,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166860
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Sun, 20 Sep 2015, Freek Wiedijk wrote:</p>\n<blockquote>\n<blockquote>\n<p>OCaml is much less safe than SML, e.g. strings are mutable, ints <br>\noverflow at unspecified word size without any exception,</p>\n</blockquote>\n<p>I think the newest OCaml support immutable strings?</p>\n</blockquote>\n<p>This would be very good news indeed.</p>\n<blockquote>\n<p>And if in the kernel you would use nums instead of ints, then the second <br>\nproblems would be gone too?</p>\n</blockquote>\n<p>The Coq guys are doing that.</p>\n<p>In Poly/ML we have int = num by default -- at the bottom there is either <br>\nthe GMP library or an old custom-made implementation.  Both can fail in <br>\ntheir own right, but it is better to have the idea of proper integers <br>\nsomehow implemented than unspecified machine word arithmetic.</p>\n<p>In a discussion with J. Harrison on the HOL mailing list some years ago <br>\nabout proper integers in LCF-style kernels, we eventually agreed that the <br>\nmost robust approach would be to have just 64bit integers with explicit <br>\nchecking (overflow exception), and not bignums.</p>\n<p>Note that ML code using infamous catch-all patterns \"e1 handle _ =&gt; e2\" <br>\nwould become erratic in situations of spurious overflow!  The Isabelle <br>\ncode base is clear of that (thanks to static checking and warnings in <br>\nPoly/ML), but I still see it routinely in other provers.</p>\n<blockquote>\n<p>And maybe you only would need to go through nums when you actually <br>\ncalculate with ints in the kernel? Does this even happen, and if so, in <br>\nwhich functions?</p>\n</blockquote>\n<p>SML allows in principle to work with fixed-size integers (with overflow <br>\nexception) or unbounded integers side-by-side.  An ultra-safe kernel would <br>\nuse the former, and applications the latter.</p>\n<p>We actually used to have such a situation in the past, not on our own <br>\nchoice, but due to SML/NJ imposing it on us.  It was very annoying to have <br>\nlimited int here, and bigint there (e.g. for computer-algebra <br>\napplications).  Eventually, I made some efforts to collapse the zoo of int <br>\ntypes just to one big int, and we have lived happily ever after.</p>\n<p>Makarius</p>",
        "id": 294652986,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166873
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Thu, 17 Sep 2015, Ramana Kumar wrote:</p>\n<blockquote>\n<p>Yesterday, I showed my colleagues that it is possible to prove False in <br>\nIsabelle2015 without any warnings or errors and without any use of <br>\naxiomatization or oracles.</p>\n</blockquote>\n<p>This is a confusion produced by the paper: example 2 is in opposition to <br>\nthe axiomatic nature of \"typedef\" in all published versions of <br>\nIsabelle/HOL.  See the documentation in the isar-ref manual -- it is <br>\nusually up-to-date and authoritative, although sometimes a bit terse.</p>\n<p>Of course, one could argue if it is a good idea to treat typedef like <br>\nthat. This would lead to the very start of a serious discussion -- one <br>\nwithout rumors and unnecessary confusion caused by worrying about <br>\npublicity or \"bad press\".</p>\n<blockquote>\n<p>The trick was, of course, Ondrej's example, but updated to use <br>\n\"overloading\" rather than the deprecated \"defs\" keyword.</p>\n</blockquote>\n<p>Both are mostly the same.  The old \"defs\" command is declared legacy, <br>\nsince it complicates critical system interfaces.  It is a bit like MS-DOS, <br>\nwhere you still have old CP/M system calls for no good reason, other than <br>\nold customs.</p>\n<blockquote>\n<p>Many of them were surprised, and wanted to know why, when I said that a <br>\npatch did exist, it has not been incorporated. I think rumours about <br>\n\"Isabelle developers\" are unavoidable at that point.</p>\n</blockquote>\n<p>In the last 1.5 years, Ondrej has produced various interesting border <br>\ncases. I incorporated changes quickly that where valid counter-examples of <br>\nexpected and documented behaviour -- he also helped in working out missing <br>\ndetails.</p>\n<p>The proposed changes of the present paper are genuine feature additions <br>\nthat go beyond the known and documented model of Isabelle/HOL.  This is <br>\nwhy I reduced the priority to a reasonable level. And in fact, we are <br>\ntalking here about a few months latency of TODO-list pipeline -- things <br>\nroutinely take much longer than that.  Isabelle is not a research <br>\nprototype that can be changed arbitrarily at a high rate.</p>\n<p>The key question is how users, even power users, can get a more realistic <br>\nfeeling what the system can do and what not.  Maybe we should make a <br>\nsystematic collection of odd situations, like <br>\n<a href=\"https://github.com/clarus/falso\">https://github.com/clarus/falso</a> for Coq.</p>\n<p>Many years ago, system failure happened occasionally in everyday use, so <br>\npower users knew what to expect.  Actual breakdown is now so rare in real <br>\nwork that users think the system is unbreakable, and start spreading false<br>\nclaims to the outside world.</p>\n<p>Makarius</p>",
        "id": 294652999,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166880
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nOn 20/09/2015 16:02, Makarius wrote:</p>\n<blockquote>\n<p>On Thu, 17 Sep 2015, Ramana Kumar wrote:</p>\n<blockquote>\n<p>Yesterday, I showed my colleagues that it is possible to prove False in<br>\nIsabelle2015 without any warnings or errors and without any use of<br>\naxiomatization or oracles.</p>\n</blockquote>\n<p>This is a confusion produced by the paper: example 2 is in opposition to the<br>\naxiomatic nature of \"typedef\" in all published versions of Isabelle/HOL.  See<br>\nthe documentation in the isar-ref manual -- it is usually up-to-date and<br>\nauthoritative, although sometimes a bit terse.</p>\n<p>Of course, one could argue if it is a good idea to treat typedef like that. This<br>\nwould lead to the very start of a serious discussion</p>\n</blockquote>\n<p>I'm afraid that most of the people who have spoken up have looked at the issue <br>\nin the light of example 2 and have already decided that this is a no-brainer. <br>\nTheir contributions were based on that conclusion. And in some cases also on <br>\nOndrej's experiments that showed that neither the distribution nor the AFP <br>\ncontains any such circularity, neither intentional nor accidental. Hence we have <br>\nnot heard any views asking for such circularities to be accepted. But maybe you <br>\nwant to convince us otherwise.</p>\n<p>Tobias</p>\n<blockquote>\n<p>-- one without rumors and<br>\nunnecessary confusion caused by worrying about publicity or \"bad press\".</p>\n<blockquote>\n<p>The trick was, of course, Ondrej's example, but updated to use \"overloading\"<br>\nrather than the deprecated \"defs\" keyword.</p>\n</blockquote>\n<p>Both are mostly the same.  The old \"defs\" command is declared legacy, since it<br>\ncomplicates critical system interfaces.  It is a bit like MS-DOS, where you<br>\nstill have old CP/M system calls for no good reason, other than old customs.</p>\n<blockquote>\n<p>Many of them were surprised, and wanted to know why, when I said that a patch<br>\ndid exist, it has not been incorporated. I think rumours about \"Isabelle<br>\ndevelopers\" are unavoidable at that point.</p>\n</blockquote>\n<p>In the last 1.5 years, Ondrej has produced various interesting border cases. I<br>\nincorporated changes quickly that where valid counter-examples of expected and<br>\ndocumented behaviour -- he also helped in working out missing details.</p>\n<p>The proposed changes of the present paper are genuine feature additions that go<br>\nbeyond the known and documented model of Isabelle/HOL.  This is why I reduced<br>\nthe priority to a reasonable level. And in fact, we are talking here about a few<br>\nmonths latency of TODO-list pipeline -- things routinely take much longer than<br>\nthat.  Isabelle is not a research prototype that can be changed arbitrarily at a<br>\nhigh rate.</p>\n<p>The key question is how users, even power users, can get a more realistic<br>\nfeeling what the system can do and what not.  Maybe we should make a systematic<br>\ncollection of odd situations, like <a href=\"https://github.com/clarus/falso\">https://github.com/clarus/falso</a> for Coq.</p>\n<p>Many years ago, system failure happened occasionally in everyday use, so power<br>\nusers knew what to expect.  Actual breakdown is now so rare in real work that<br>\nusers think the system is unbreakable, and start spreading false<br>\nclaims to the outside world.</p>\n<p>Makarius</p>\n<p><a href=\"/user_uploads/14278/kzBRSuz4sN-tgmdEYXxQjoXe/smime.p7s\">smime.p7s</a></p>\n</blockquote>",
        "id": 294653030,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166892
    },
    {
        "content": "<p>From: \"\\\"Mark Adams\\\"\" &lt;<a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a>&gt;<br>\nHi Makarius,</p>\n<p>Wouldn't it be highly relevant to include HOL Zero in the systems you<br>\nconsider in your list?</p>\n<p>Shouldn't you be considering pretty printing?  In most systems, you can<br>\ncreate all sorts of confusing stuff by exploiting flaws, as we've already<br>\ndiscussed in the past.</p>\n<p>And the risk of a trojan horse inference kernel or pretty printer hasn't<br>\nbeen considered.</p>\n<p>But then I don't think you were attempting to be complete.</p>\n<blockquote>\n<p>Makarius:</p>\n<blockquote>\n<p>OCaml is much less safe than SML, e.g. strings are<br>\nmutable</p>\n</blockquote>\n<p>Freek:<br>\nI think the newest OCaml support immutable strings?</p>\n</blockquote>\n<p>Yes OCaml 4.02 does support immutable strings, but it's not yet considered<br>\nto fully incorporated into the language proper.  Unless you do something<br>\nspecific, you're still using mutable strings.</p>\n<p>Note that HOL Zero manages to avoid the problem by making copies of strings<br>\nat the interface to the kernel.  There are 21 instances of this in the<br>\nkernel.</p>\n<blockquote>\n<blockquote>\n<p>Makarius:<br>\nints overflow at unspecified word size without<br>\nany exception,</p>\n</blockquote>\n<p>Freek:<br>\nAnd if in the kernel you would use nums instead of ints,<br>\nthen the second problems would be gone too?  (It would<br>\nbe interesting to know how much of a hassle this last<br>\nchange would be.  And maybe you only would need to<br>\ngo through nums when you actually calculate with ints in<br>\nthe kernel? Does this even happen, and if so, in which<br>\nfunctions?)</p>\n</blockquote>\n<p>HOL Light 'new_basic_type_definition' uses 'length' which returns a possibly<br>\noverflowing int.  So if the predicate in the supplied theorem had enough<br>\ntype variables (2^30 in a 32-bit OS) then the returned theorem would be<br>\nwrong.  This is of course almost impossible to do in practice.</p>\n<p>Note that HOL Zero avoids the risk entirely by using 'big_int' (which can be<br>\narbitrarily big).  This requires two utilities used in the kernel, that are<br>\nimplemented in 14 lines of code.</p>\n<blockquote>\n<blockquote>\n<p>Makarius:<br>\n.. various other oddities and deviations from original ML<br>\nmake it hard to understand mathematically (e.g possibility for<br>\ncircular datatypes).  Signals allow to inject arbitrary ML<br>\nexceptions into user code, not just interrupts. (I am not taking<br>\nObj.magic non-sense into account here, since its absence<br>\ncan be easily detected by looking at the source.)</p>\n</blockquote>\n</blockquote>\n<p>HOL Zero avoids these risks as far as I know.  But if you could find a way<br>\nand demonstrate it, perhaps exploiting exception injection, you could earn<br>\nyourself the $100 bounty..  HOL Zero avoids the Obj.magic problem by<br>\noverwriting the module.</p>\n<p>Note that it's not good enough to grep the source to look for Obj.magic -<br>\nyou can use obfuscated OCaml code to create an OCaml source code file<br>\ncontaining an Obj.magic, and then read this into the OCaml session.</p>\n<p>Mark.</p>",
        "id": 294653045,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166902
    },
    {
        "content": "<p>From: \"\\\"Mark Adams\\\"\" &lt;<a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a>&gt;<br>\nI should mention that a lot of the issues and ideas mentioned in this thread<br>\nare discussed in my recent paper:</p>\n<p><a href=\"http://www.proof-technologies.com/flyspeck/qed_paper.pdf\">www.proof-technologies.com/flyspeck/qed_paper.pdf</a></p>\n<p>Mark.</p>\n<p>on 19/9/15 10:39 AM, Tjark Weber &lt;<a href=\"mailto:tjark.weber@it.uu.se\">tjark.weber@it.uu.se</a>&gt; wrote:</p>",
        "id": 294653056,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166905
    },
    {
        "content": "<p>From: Chantal Keller &lt;<a href=\"mailto:chantal.keller@wanadoo.fr\">chantal.keller@wanadoo.fr</a>&gt;<br>\nDear Ramana,</p>\n<p>As far as I am aware, the more convincing attempt at checking proofs<br>\ncoming from provers of the HOL community is Holide<br>\n&lt;<a href=\"https://who.rocq.inria.fr/Ali.Assaf/research/translating-hollight-dedukti-pxtp-2015.pdf\">https://who.rocq.inria.fr/Ali.Assaf/research/translating-hollight-dedukti-pxtp-2015.pdf</a>&gt;.<br>\nIt is still costly though, both to produce proofs and check them, but<br>\nthis cost has been reduced a lot these last years compared to previous<br>\nwork. It is based on OpenTheory.</p>\n<p>I do not know how it compares to the work David mentioned on seL4.</p>\n<p>Best,<br>\nChantal.</p>",
        "id": 294653070,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166910
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:tjark.weber@it.uu.se\">tjark.weber@it.uu.se</a>&gt;<br>\nTo elaborate, and to answer questions that I received via private<br>\nemail: The main difficulty here is that Isabelle theories are written<br>\nin a rich and powerful language (that may contain, e.g., embedded ML<br>\ncode), to the point that the observable behavior of Isabelle when it<br>\nchecks (or more accurately, processes) the theory cannot be trusted.</p>\n<p>Of course, other theorem provers with powerful proof languages also<br>\nsuffer from this problem.</p>\n<p>Best,<br>\nTjark</p>",
        "id": 294653178,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166959
    },
    {
        "content": "<p>From: Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nWhat we usually do to check a proof development is run “Isabelle build” and look at the output. Of course, Isabelle (and any system based on the LCF paradigm) allows arbitrary code execution. This should be borne in mind in connection with any idea that the use of a proof assistant eliminates the need to trust the person making the proof. None of us are developing software that has the remotest claim to satisfying any sort of security requirement.</p>\n<p>Larry Paulson</p>",
        "id": 294653228,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166965
    },
    {
        "content": "<p>From: Buday Gergely &lt;<a href=\"mailto:gbuday@karolyrobert.hu\">gbuday@karolyrobert.hu</a>&gt;<br>\nLarry Paulson wrote:</p>\n<p>Proof Carrying Code promised that the delivered code was accompanied by a proof that shows some security properties of the code. Its home page is outdated, does anybody know how far they went achieving this aim?</p>\n<ul>\n<li>Gergely</li>\n</ul>",
        "id": 294653256,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661166978
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\n(Back to this still open thread.)</p>\n<p>Last Monday I started to look at the actual sources and the patch that was <br>\nmentioned in the paper, and learned a few more things that I will explain <br>\nlater, when writing up a full overview of my present understanding of it.</p>\n<p>Since reading ML sources and changesets is always a constructive process for <br>\nme, I've produced various changesets over several days (being off-list), <br>\nleading up to 64a5bce1f498 with the following NEWS entry:</p>\n<ul>\n<li>The 'typedef' command has been upgraded from a partially checked<br>\n\"axiomatization\", to a full definitional specification that takes the<br>\nglobal collection of overloaded constant / type definitions into<br>\naccount. Type definitions with open dependencies on overloaded<br>\ndefinitions need to be specified as \"typedef (overloaded)\". This<br>\nprovides extra robustness in theory construction. Rare INCOMPATIBILITY.</li>\n</ul>\n<p>As well as the following updated section in the isar-ref manual (formerly <br>\n\"Typedef axiomatization\"):</p>\n<p>section ‹Semantic subtype definitions \\label{sec:hol-typedef}›</p>\n<p>text ‹<br>\n   \\begin{matharray}{rcl}<br>\n      @{command_def (HOL) \"typedef\"} &amp; : &amp; @{text \"local_theory →<br>\n    proof(prove)\"} \\\\<br>\n    \\end{matharray}</p>\n<p>A type definition identifies a new type with a non-empty subset of an<br>\n    existing type. More precisely, the new type is defined by exhibiting an<br>\n    existing type @{text τ}, a set @{text \"A :: τ set\"}, and proving @{prop<br>\n    \"∃x. x ∈ A\"}. Thus @{text A} is a non-empty subset of @{text τ}, and<br>\n    the new type denotes this subset. New functions are postulated that<br>\n    establish an isomorphism between the new type and the subset. In<br>\n    general, the type @{text τ} may involve type variables @{text \"α⇩1, …,<br>\n    α⇩n\"} which means that the type definition produces a type constructor<br>\n    @{text \"(α⇩1, …, α⇩n) t\"} depending on those type arguments.</p>\n<p>@{rail ‹<br>\n      @@{command (HOL) typedef} @{syntax \"overloaded\"}? abs_type '=' rep_set<br>\n      ;<br>\n      @{syntax_def \"overloaded\"}: ('(' @'overloaded' ')')<br>\n      ;<br>\n      abs_type: @{syntax typespec_sorts} @{syntax mixfix}?<br>\n      ;<br>\n      rep_set: @{syntax term} (@'morphisms' @{syntax name} @{syntax name})?<br>\n    ›}</p>\n<p>To understand the concept of type definition better, we need to recount<br>\n    its somewhat complex history. The HOL logic goes back to the <code>Simple\n    Theory of Types'' (STT) of A. Church @{cite \"church40\"}, which is\n    further explained in the book by P. Andrews @{cite \"andrews86\"}. The\n    overview article by W. Farmer @{cite \"Farmer:2008\"} points out the\n    </code>seven virtues'' of this relatively simple family of logics. STT has<br>\n    only ground types, without polymorphism and without type definitions.</p>\n<p>\\medskip M. Gordon @{cite \"Gordon:1985:HOL\"} augmented Church's STT by<br>\n    adding schematic polymorphism (type variables and type constructors) and<br>\n    a facility to introduce new types as semantic subtypes from existing<br>\n    types. This genuine extension of the logic was explained semantically by<br>\n    A. Pitts in the book of the original Cambridge HOL88 system @{cite<br>\n    \"pitts93\"}. Type definitions work in this setting, because the general<br>\n    model-theory of STT is restricted to models that ensure that the<br>\n    universe of type interpretations is closed by forming subsets (via<br>\n    predicates taken from the logic).</p>\n<p>\\medskip Isabelle/HOL goes beyond Gordon-style HOL by admitting<br>\n    overloaded constant definitions @{cite \"Wenzel:1997:TPHOL\" and<br>\n    \"Haftmann-Wenzel:2006:classes\"}, which are actually a concept of<br>\n    Isabelle/Pure and do not depend on particular set-theoretic semantics of<br>\n    HOL. Over many years, there was no formal checking of semantic type<br>\n    definitions in Isabelle/HOL versus syntactic constant definitions in<br>\n    Isabelle/Pure. So the @{command typedef} command was described as<br>\n    ``axiomatic'' in the sense of \\secref{sec:axiomatizations}, only with<br>\n    some local checks of the given type and its representing set.</p>\n<p>Recent clarification of overloading in the HOL logic proper @{cite<br>\n    \"Kuncar-Popescu:2015\"} demonstrate how the dissimilar concepts of<br>\n    constant definitions versus type definitions may be understood<br>\n    uniformly. This requires an interpretation of Isabelle/HOL that<br>\n    substantially reforms the set-theoretic model of A. Pitts @{cite<br>\n    \"pitts93\"}, by taking a schematic view on polymorphism and interpreting<br>\n    only ground types in the set-theoretic sense of HOL88. Moreover,<br>\n    type-constructors may be explicitly overloaded, e.g.\\ by making the<br>\n    subset depend on type-class parameters (cf.\\ \\secref{sec:class}). This<br>\n    is semantically like a dependent type: the meaning relies on the<br>\n    operations provided by different type-class instances.</p>\n<p>\\begin{description}</p>\n<p>\\item @{command (HOL) \"typedef\"}~@{text \"(α⇩1, …, α⇩n) t = A\"} defines<br>\n    a new type @{text \"(α⇩1, …, α⇩n) t\"} from the set @{text A} over an<br>\n    existing type. The set @{text A} may contain type variables @{text<br>\n    \"α⇩1, …,α⇩n\"}as specified on the LHS, but no term variables.<br>\n    Non-emptiness of @{text A} needs to be proven on the spot, in order to<br>\n    turn the internal conditional characterization into usable theorems.</p>\n<p>The ``@{text \"(overloaded)\"}'' option allows the @{command \"typedef\"}<br>\n    specification to depend on constants that are not (yet) specified and<br>\n    thus left open as parameters, e.g.\\ type-class parameters.</p>\n<p>Within a local theory specification, the newly introduced type<br>\n    constructor cannot depend on parameters or assumptions of the context:<br>\n    this is syntactically impossible in HOL. The non-emptiness proof may<br>\n    formally depend on local assumptions, but this has little practical<br>\n    relevance.</p>\n<p>For @{command (HOL) \"typedef\"}~@{text \"t = A\"} the newly introduced type<br>\n    @{text t} is accompanied by a pair of morphisms to relate it to the<br>\n    representing set over the old type.  By default, the injection from type<br>\n    to set is called @{text Rep_t} and its inverse @{text Abs_t}: An<br>\n    explicit @{keyword (HOL) \"morphisms\"} specification allows to provide<br>\n    alternative names.</p>\n<p>The logical characterization of @{command typedef} uses the predicate of<br>\n    locale @{const type_definition} that is defined in Isabelle/HOL. Various<br>\n    basic consequences of that are instantiated accordingly, re-using the<br>\n    locale facts with names derived from the new type constructor. Thus the<br>\n    generic theorem @{thm type_definition.Rep} is turned into the specific<br>\n    @{text \"Rep_t\"}, for example.</p>\n<p>Theorems @{thm type_definition.Rep}, @{thm type_definition.Rep_inverse},<br>\n    and @{thm type_definition.Abs_inverse} provide the most basic<br>\n    characterization as a corresponding injection/surjection pair (in both<br>\n    directions).  The derived rules @{thm type_definition.Rep_inject} and<br>\n    @{thm type_definition.Abs_inject} provide a more convenient version of<br>\n    injectivity, suitable for automated proof tools (e.g.\\ in declarations<br>\n    involving @{attribute simp} or @{attribute iff}). Furthermore, the rules<br>\n    @{thm type_definition.Rep_cases}~/ @{thm type_definition.Rep_induct},<br>\n    and @{thm type_definition.Abs_cases}~/ @{thm type_definition.Abs_induct}<br>\n    provide alternative views on surjectivity.  These rules are already<br>\n    declared as set or type rules for the generic @{method cases} and<br>\n    @{method induct} methods, respectively.</p>\n<p>\\end{description}</p>\n<p>This may still require more polishing before the winter release of <br>\nIsabelle2016, but there is time for that.</p>\n<p>My impression is that part of the discussion so far was encumbered by anxiety <br>\nthat this add-on feature won't make it into the next release. Now that there is <br>\nno more pressure in this respect, we can sort out remaining low-level and <br>\nhigh-level problems in a relaxed manner.</p>\n<p>In the next round I will comment more on the ITP paper and the notes on the <br>\noriginal patch ...</p>\n<p>Makarius</p>",
        "id": 294653888,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167210
    },
    {
        "content": "<p>From: Peter Lammich &lt;<a href=\"mailto:lammich@in.tum.de\">lammich@in.tum.de</a>&gt;<br>\nNow Isabelle has a feature, which is (IMHO) essential for a theorem<br>\nprover, and which many users (including me) deemed already present in<br>\nolder Isabelle's, and were surprised that it wasn't.</p>\n<p>A leap ahead for Isabelle!</p>",
        "id": 294653909,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167221
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nNow we are back to the actual social problems: Why do Isabelle power users <br>\nhave an inadequate idea what the system does and what not, despite the <br>\nofficial documentation.</p>\n<p>We need to work harder on this thread, to move forward.</p>\n<p>Makarius</p>",
        "id": 294653915,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167223
    },
    {
        "content": "<p>From: Andrei Popescu &lt;<a href=\"mailto:A.Popescu@mdx.ac.uk\">A.Popescu@mdx.ac.uk</a>&gt;<br>\nHi Makarius, </p>\n<p>Many thanks for this great news! Declaring the Isabelle/HOL typedef to be definitional is well-justified and surely welcomed by the users.  <br>\nThis definitional status, achieved on a tricky foundational terrain in the presence of constant overloading, benefits from the previous work <br>\non taming overloading by yourself, Steven Obua  and Florian Haftmann (among others).  </p>\n<p>I am looking forward to the relaxed discussion in front of us.     :-)  </p>\n<p>All the best, <br>\n   Andrei</p>",
        "id": 294653929,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167229
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nHere is now my virtual review of the ITP paper behind this thread. It came <br>\nout a bit longer than anticipated, although I included only half of the <br>\nthoughts that came to me, while reading it 3 times.</p>\n<p>Makarius</p>\n<hr>\n<p>Title: A Consistent Foundation for Isabelle/HOL<br>\nAuthors: Ondřej Kunčar, Andrei Popescu<br>\n<a href=\"http://www21.in.tum.de/~kuncar/documents/kuncar-popescu-itp2015.pdf\">http://www21.in.tum.de/~kuncar/documents/kuncar-popescu-itp2015.pdf</a></p>\n<p>Overall evaluation: accept<br>\nReviewer's confidence: high</p>\n<p>Review:</p>\n<p>The paper revisits the question how overloaded definitions (of constants and<br>\ntype constructores) may be understood within the HOL logic. This work<br>\nconsists of three parts:</p>\n<p>(1) Technical treatment of the HOL logic, with a notion of \"definitional<br>\n   theory\" and its well-formedness, interpretation of this extended HOL logic<br>\n   in a substantially reformed version of the original HOL88 interpretation<br>\n   due to A. Pitts.</p>\n<p>(2) A proposed change to the Isabelle2014 code base, to upgrade its<br>\n   'typedef' mechanism to perform the additional well-formedness checks<br>\n   described in the paper. The text refers to<br>\n<a href=\"http://www21.in.tum.de/~kuncar/documents/patch.html\">http://www21.in.tum.de/~kuncar/documents/patch.html</a> which provides some<br>\n   changesets and one page of explanations how this fits into the setup of<br>\n   the paper.</p>\n<p>(3) General motivation and discussion of perceived problems of<br>\n   Isabelle/HOL, which the paper sets out to resolve. This part is apt to<br>\n   cause confusion in various ways, both to users and non-users of Isabelle.<br>\n   The style of presentation considerably subtracts from this otherwise fine<br>\n   paper.</p>\n<p>Part (1)</p>\n<hr>\n<p>These are sections 3, 4, 5 in the paper. Section 5 is the main contribution.<br>\nThe classic HOL logic of HOL88 (due to M. Gordon and semantics by A. Pitts)<br>\nis taken as starting point. There is a nice explanation in 4.3, why<br>\noverloaded definitions of constants or types does not work out in the<br>\ninterpretation of A. Pitts (HOL88 book from 1993). Thus a new interpretation<br>\nis introduced as follows:</p>\n<p>* Types are not immediately interpreted away into sets, but preserved as<br>\n   syntactic entities to keep sufficient structure that allows well-founded<br>\n   recursion. The paper calls this \"a natural syntactic-semantic blend, which<br>\n   avoids stunt performance in set theory\".</p>\n<p>* Type interpretation starts out on ground types. Polymorphism is<br>\n   interpreted only in the final stage, treating it as strictly schematic<br>\n   over all ground interpretations.</p>\n<p>* Models for ground interpretation are constructed in stages, following<br>\n   the well-founded dependency relation of the given collection of<br>\n   definitions. Here types and constants are interpreted simultaneously for<br>\n   each stage, while in the HOL88 semantics by A. Pitts all types are<br>\n   interpreted before all constants.</p>\n<p>This model construction is fit together with other recent work by the first<br>\nauthor [19], opening the perspective of fully checked definitional theories<br>\nin Isabelle/HOL. More about this in part (2).</p>\n<p>Taking the little space of a paper in LNCS proceedings into account, the<br>\ntechnical treatment of the problem is worked out very carefully. Numerous<br>\nfine points and additional side-conditions are included in the<br>\nconsiderations.</p>\n<p>Nonetheless, there is a potential for confusion due to slight deviation of<br>\nterminology and concepts, compared to papers on the subject e.g. by<br>\nWenzel/Haftmann and the Isabelle documentation (isar-ref manual).</p>\n<p>In particular: Section 3.4 defines a \"definitional theory\" as a set of<br>\noverloaded definitions (for constants or types) such that certain <em>local</em><br>\nsyntactic conditions hold. Section 4.2 defines a \"well-formed definitional<br>\ntheory\" as a definitional theory with well-founded dependency relation as<br>\n<em>global</em> condition. Section 4.5 establishes the main theorem that a<br>\nwell-formed definitional theory is consistent -- by demonstrating that it<br>\nhas a model in the above sense, and concluding that False cannot be derived<br>\nin the inference system -- due to soundness of the interpretation.</p>\n<p>In contrast, the specifications of a \"definitional theory\" of the paper<br>\nwould be called in the Isabelle documentation \"unchecked definitions\",<br>\n\"definitional axioms\", or \"axiomatizations\", to emphasize the missing aspect<br>\nof global well-formedness that this paper is mainly about. A \"well-formed<br>\ndefinitional theory\" of the paper would be just called \"definitional theory\"<br>\nin Isabelle terminology, and much stronger properties intended than just<br>\nconsistency. Instead of merely ensuring the existence of a model, the<br>\nrequirement is to preserve derivability of old propositions precisely, and<br>\nallow to reduce new derivations of new propositions into old derivations by<br>\n\"expanding\" definitions in some way. If and how this works depends on<br>\nfine-points of the underlying definitional mechanisms: for overloaded<br>\nconstant definitions in Isabelle/Pure this works [13, 35], but for type<br>\ndefinitions the situation is a-priori quite different, e.g. see [13] section<br>\n4.3. The deeper reason for this are the distinctive categories of terms and<br>\ntypes in HOL, and the lack of equational reasoning on types.</p>\n<p>A suitable semantic treatment is required to re-unify the view on terms and<br>\ntypes, as is done in the present paper. But this leads to weaker results.<br>\nThe paper does briefly mention \"a suitable notion of conservativeness\" as<br>\nfuture work, but due to lack of further explanations, many readers will<br>\nprobably miss key point behind this.</p>\n<p>There is another aspect of \"consistency\" versus \"conservativity\" that is<br>\neasily missed in the paper. Section 3.5 states \"Isabelle/HOL theory<br>\ndevelopment proceeds by: 1 ... 2 ... 3 ...\". The three kinds of operations<br>\nensure that every stage of theory development is \"definitional\" in the sense<br>\nof the paper -- and \"well-formedness\" can be established later. But what<br>\nhappens when the user starts adding non-definitional axioms in between?<br>\nStrictly speaking, the main result does not apply and the whole theory<br>\nlooses its good definitional properties.</p>\n<p>In contrast, the traditional explanation of (constant) definitions in<br>\nIsabelle is more modular in that respect: given an arbitrary base theory ---<br>\none that somehow makes sense to the user in a particular application, even<br>\nafter making unchecked axiomatizations --- definitions merely introduce<br>\nnames for existing entities and thus preserve the key properties of the base<br>\ntheory. This agnostic approach of \"definitional theory extensions\"<br>\n(occording to Isabelle terminolgy) is particularly important from the<br>\nperspective of the Isabelle/Pure framework, where the interpretation of<br>\nobject-logics is not yet known.</p>\n<p>For HOL applications one might argue that genuine axiomatic extensions are<br>\nnot done in practice these days. Nonetheless some exotic applications like<br>\nHOLZF (by Obua) do exist. Without stronger results under which conditions<br>\ntypedefs \"make sense\" or \"are OK\" (using words from the paper), such<br>\nambitious users would have to revisit the whole model theory of HOL again.</p>\n<p>Part (2)</p>\n<hr>\n<p>The patch to Isabelle2014 is rather minimal: the existing infrastructure to<br>\ncheck overloaded constant definitions (going back to Isabelle2007, and<br>\nslightly improved by O. Kuncar [19] is generalized to cover type definitions<br>\nas well. So Isabelle/Pure is upgraded to provide a general service for<br>\n\"definitional specification items\" that are identified in the name space for<br>\nconstants or types, but without looking at actual content.</p>\n<p>While the explanations for the patch states \"the situation is from a<br>\ntechnical (implementation) point view a little bit more complicated\", the<br>\noutcome is actually simpler than in the paper. Being forced to strip away<br>\naccidental aspects of the HOL object-logic does occasionally have<br>\nadvantages.</p>\n<p>For example, the delicate notion of \"build-in types\" vs. \"non-built-in<br>\ntypes\" is absent in the implementation. The notes on the patch provide some<br>\nexplanations, why it works out nonetheless. It would be nice to see this<br>\nrefinement applied to the main work of part (1), to trim it further down to<br>\nthe very essence of symbolic specifications with schematic polymorphism and<br>\noverloading.</p>\n<p>The proposed change to Isabelle2014 is called \"correction patch\", as if<br>\nsomething would be broken that is fixed by the change. This misunderstanding<br>\nleads directly into the general discussion of this work below.</p>\n<p>Part (3)</p>\n<hr>\n<p>These are sections 1 \"Introduction\", section 2 \"Related Work\", section 6<br>\n\"Conclusion\", i.e. the important pieces that put the technical contribution<br>\ninto proper perspective. This is what most people read, and what attendants<br>\nof a conference presentation who are busy with their e-mails or smart-phone<br>\nusually take home. Unfortunately, the story being told here do not quite fit<br>\nto Isabelle.</p>\n<p>The misunderstanding already starts in the first paragraph, where<br>\nIsabelle/HOL is included into the \"umbrella term\" of \"HOL-based provers\".<br>\nHOL4, HOL-Light, ProofPower, HOL Zero are fine systems, but Isabelle/HOL is<br>\nnot as closely related to them as the \"HOL\" name might suggest. In many<br>\nrespects Isabelle is actually closer to Coq.</p>\n<p>Technically, the key misunderstanding is the role of \"the kernel\" (in the<br>\nwords of the paper). HOL88 as the predecessor of all the other HOL systems<br>\npioneered an add-on to the original LCF kernel design to have checked<br>\ndefinitions as primitive rules. In contrast, Isabelle is closer to LCF in<br>\nseparating logical inferences and a-priori unchecked (axiomatic) theory<br>\nspecifications: there is no notion of definitions in the inference kernel of<br>\nIsabelle. Since this is a bit impractical for big applications, more and<br>\nmore checks on theory content have been added over the years (e.g. 2004,<br>\n2005, 2007, 2010, 2014), but that process was never formally closed. And<br>\nthis is what the paper is actually about: complete emulation of HOL88-style<br>\ndefinitions in Isabelle/HOL (by providing additional services in the<br>\nIsabelle/Pure framework).</p>\n<p>We can now revisit the critical examples in t<br>\n[message truncated]</p>",
        "id": 294653984,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167254
    },
    {
        "content": "<p>From: Andrei Popescu &lt;<a href=\"mailto:a.popescu@mdx.ac.uk\">a.popescu@mdx.ac.uk</a>&gt;<br>\nHi Makarius,</p>\n<p>Many thanks for your comments, and for the acceptance decision which will make the rebuttal phase very relaxed.</p>\n<p>I'll send the rebuttal comments tomorrow.</p>\n<p>All the best,<br>\n  Andrei</p>",
        "id": 294654008,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167267
    },
    {
        "content": "<p>From: Andrei Popescu &lt;<a href=\"mailto:a.popescu@mdx.ac.uk\">a.popescu@mdx.ac.uk</a>&gt;<br>\nHi Makarius,</p>\n<p>I thank you very much for looking at the technical contribution of the paper beyond matters of terminology and \"attitude.\"<br>\nI find your summary of our technical contribution to be excellent.</p>\n<p>In order to discuss your comments concerning our \"attitude,\" I would first like to state my own view<br>\non the situation, which is not entirely divergent from your view.</p>\n<p>Isabelle/HOL is not a standard object logic of Isabelle/Pure, in the usual sense of object logics represented in a logical framework.<br>\nThe culprit is typedef, which is implemented in an ad hoc manner, and not as an object-logic judgment. This is necessary<br>\ndue to the nature of typedef. But this is already a warning that whatever guarantees one provides at the generic level of<br>\nIsabelle/Pure may simply not be good enough for Isabelle/HOL.</p>\n<p>By contrast, the constant definition mechanism from Isabelle/Pure is imported to Isabelle/HOL following a uniform<br>\n\"object-logic inside meta-logic\" shallow embedding scheme. This scheme also applies, for example, to the representation of<br>\nbindings and the function space.</p>\n<p>In your ‘97 paper you prove the following very nice result:<br>\nIn Isabelle/Pure, under suitable orthogonality and well-foundedness conditions, the addition of overloaded<br>\nconstant definitions to any theory T is \"meta-safe,\" in that it is syntactically conservative and<br>\nanything provable in the extended theory can also be represented and proved in the original T in<br>\na canonical way, by “realizing” the new constants as terms in the old signature. This indeed is a very<br>\nstrong conservativity result, which also implies preservation of consistency. It  applies to the object logics<br>\nof Isabelle/Pure, which can be regarded as theories. As you also remind us in your review, another pleasant<br>\nfeature of this result is T not needing to be a definitional theory.</p>\n<p>But: Isabelle/HOL of course only partly benefits from this result. In fact, compared to Gordon-HOL,<br>\nwhich offers model-theoretic safety<br>\nfor both constant and type definitions, I would say that in these conditions Isabelle/HOL would be<br>\nonly half-way safe, and quite non-democratically so. On the one hand, there is this luxurious (meta-)safety<br>\nguarantee for constant definitions, and on the other hand there is <em>nothing</em> for typedef. Instead of stating this problem<br>\nas a <em>pressing open problem</em> (already in ‘97), you had decided to introduce this oxymoron: \"axiomatic typedef.\"<br>\nUnfortunately, nobody (except perhaps for Florian who used to “joke” about typedef being axiomatic) has noticed this<br>\nideological move away from the tradition of the HOL systems.</p>\n<p>(Here, I have a confession. When reading your paper, it simply did not cross my mind that you could have<br>\njust abandoned typedef :-( and instead I came up with the following explanation: Your approach is to prove as<br>\nmuch as you can in Isabelle/Pure for constants,<br>\nnamely, meta-safety, and in particular syntactic conservativity. Then you would move to the object level of Isabelle/HOL where<br>\ntypedef is model-theoretically safe, in particular syntactically conservative for definitional theories. Putting together these two<br>\nproperties, you would get consistency of definitional theories of Isabelle/HOL. As we know now,<br>\nthis almost works but not quite, since typedefs are allowed to depend on unresolved overloading.)</p>\n<p>Next I comment on your review:</p>\n<blockquote>\n<blockquote>\n<p>Technically, the key misunderstanding is the role of \"the kernel\" (in the<br>\nwords of the paper). HOL88 as the predecessor of all the other HOL systems<br>\npioneered an add-on to the original LCF kernel design to have checked<br>\ndefinitions as primitive rules. In contrast, Isabelle is closer to LCF in<br>\nseparating logical inferences and a-priori unchecked (axiomatic) theory<br>\nspecifications: there is no notion of definitions in the inference kernel of Isabelle.</p>\n</blockquote>\n</blockquote>\n<p>In the paper, we use the word \"kernel\" to mean \"logic kernel\" (as I hoped  would be clear from the paper's<br>\ngeneral context and from the usage of the phrase<br>\n“logic kernel” for one of the two occurrences of the word).<br>\nThe logic kernel consists of the inference rules and the definitional mechanisms, regardless of where they<br>\nare located in the implementation. A small logic kernel is an implementation-independent virtue of<br>\nIsabelle/HOL as well as of all the Gordon-HOL systems.</p>\n<blockquote>\n<blockquote>\n<p>Nonetheless, there is a potential for confusion due to slight deviation of<br>\nterminology and concepts, compared to papers on the subject e.g. by<br>\nWenzel/Haftmann and the Isabelle documentation (isar-ref manual).<br>\n...<br>\nIn contrast, the specifications of a \"definitional theory\" of the paper<br>\nwould be called in the Isabelle documentation \"unchecked definitions\",<br>\n\"definitional axioms\", or \"axiomatizations\", to emphasize the missing aspect<br>\nof global well-formedness that this paper is mainly about.</p>\n</blockquote>\n</blockquote>\n<p>For the journal version, we will switch to the terminology from the Isabelle documentation.<br>\nI believe \"definitional axioms\" is the most suggestive term here. And \"axiomatizations\" is too wide.</p>\n<blockquote>\n<blockquote>\n<p>A \"well-formed definitional theory\" of the paper would be just called \"definitional theory\"<br>\nin Isabelle terminology, and much stronger properties intended than just consistency.<br>\nInstead of merely ensuring the existence of a model, the requirement is to preserve derivability of old propositions precisely, and<br>\nallow to reduce new derivations of new propositions into old derivations by<br>\n\"expanding\" definitions in some way. If and how this works depends on<br>\nfine-points of the underlying definitional mechanisms: for overloaded<br>\nconstant definitions in Isabelle/Pure this works [13, 35], but for type<br>\ndefinitions the situation is a-priori quite different, e.g. see [13] section 4.3.<br>\nThe deeper reason for this are the distinctive categories of terms and<br>\ntypes in HOL, and the lack of equational reasoning on types.</p>\n</blockquote>\n</blockquote>\n<p>Indeed, consistency is a crucial, but rather weak property. With a bit of extra care, we could have stated our result<br>\nas more than consistency, namely, something similar to the preservation of standard models in the sense<br>\nof Gordon-HOL (which you revisit in your '97 paper).</p>\n<blockquote>\n<blockquote>\n<p>A suitable semantic treatment is required to re-unify the view on terms and<br>\ntypes, as is done in the present paper. But this leads to weaker results.<br>\nThe paper does briefly mention \"a suitable notion of conservativeness\" as<br>\nfuture work, but due to lack of further explanations, many readers will<br>\nprobably miss key point behind this.</p>\n</blockquote>\n</blockquote>\n<p>We do cite your paper there, so the reader can look up the relevant notion. However, I think that for most of the interesting theories,<br>\ntypedef cannot be safe in any sense<br>\neven remotely similar to what you prove for constant definitions. In fact, typedef cannot be proved to preserve consistency<br>\nfor non-definitional theories. This is shown by an example in your '97 paper, which I slightly generalize below:<br>\nGiven any finite consistent definitional theory T, we should always be able find a number N such that there exists a<br>\nset-theoretic model of T where no type has precisely N elements. So T + \"no type 'a has precisely N elements\" is consistent,<br>\nbut defining a type with N elements makes it inconsistent.</p>\n<blockquote>\n<blockquote>\n<p>There is another aspect of \"consistency\" versus \"conservativity\" that is<br>\neasily missed in the paper. Section 3.5 states \"Isabelle/HOL theory<br>\ndevelopment proceeds by: 1 ... 2 ... 3 ...\". The three kinds of operations<br>\nensure that every stage of theory development is \"definitional\" in the sense<br>\nof the paper -- and \"well-formedness\" can be established later. But what<br>\nhappens when the user starts adding non-definitional axioms in between?<br>\nStrictly speaking, the main result does not apply and the whole theory<br>\nlooses its good definitional properties.<br>\n...<br>\nFor HOL applications one might argue that genuine axiomatic extensions are<br>\nnot done in practice these days.</p>\n</blockquote>\n</blockquote>\n<p>You are right, our result is restricted to definitional theories.<br>\nBut typedef seems brittle in the face of amendments to the standard HOL model theory.<br>\nAnd such amendments are easily possible if one steps outside definitional theories.</p>\n<blockquote>\n<blockquote>\n<p>Nonetheless some exotic applications like<br>\nHOLZF (by Obua) do exist. Without stronger results under which conditions<br>\ntypedefs \"make sense\" or \"are OK\" (using words from the paper), such<br>\nambitious users would have to revisit the whole model theory of HOL again.</p>\n</blockquote>\n</blockquote>\n<p>IMO, Obua and other initiators of interesting experiments, besides forming an absolute minority of the users, are logical<br>\ngrown-ups who typically know what they are doing. And they are in plain wilderness in the first place, when proving consistency.</p>\n<blockquote>\n<blockquote>\n<p>In contrast, the traditional explanation of (constant) definitions in<br>\nIsabelle is more modular in that respect: given an arbitrary base theory ---<br>\none that somehow makes sense to the user in a particular application, even<br>\nafter making unchecked axiomatizations --- definitions merely introduce<br>\nnames for existing entities and thus preserve the key properties of the base<br>\ntheory. This agnostic approach of \"definitional theory extensions\"<br>\n(occording to Isabelle terminolgy) is particularly important from the<br>\nperspective of the Isabelle/Pure framework, where the interpretation of<br>\nobject-logics is not yet known.</p>\n</blockquote>\n</blockquote>\n<p>Agreed. But I am happy that the less generic Isabelle/HOL typedef feature now receives some consideration as well.</p>\n<blockquote>\n<blockquote>\n<p>For example, the delicate notion of \"build-in types\" vs. \"non-built-in<br>\ntypes\" is absent in the implementation. The notes on the patch provide some<br>\nexplanations, why it works out nonetheless. It would be nice to see this<br>\nrefinement applied to the main work of part (1), to trim it further down to<br>\nthe very essence of symbolic specifications with schematic polymorphism and<br>\noverload<br>\n[message truncated]</p>\n</blockquote>\n</blockquote>",
        "id": 294654187,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167329
    },
    {
        "content": "<p>From: Burkhart Wolff &lt;<a href=\"mailto:Burkhart.Wolff@lri.fr\">Burkhart.Wolff@lri.fr</a>&gt;<br>\nDear all, </p>\n<p>with respect to the debate around the paper by Ondřej Kunčar and Andrei Popescu: A Consistent Foundation for Isabelle/HOL (ITP 2015) <br>\nand the debate it created, I have the following remarks and informations to add:</p>\n<p>1) To be not misunderstood: I find this publication helpful and, after the quite nonchalant <br>\n    reactions of key members of the Isabelle Community, strictly speaking necessary.</p>\n<p>2) This paper creates outside the Isabelle community more echo than people might think.<br>\n    At the moment, I am as part of the EUROMILS project part of the team that attempts<br>\n    to get a common criteria (CC EAL5) evaluation for PikeOS through, where the models<br>\n    and proofs were done with Isabelle. I can tell that I had a lengthy debate with<br>\n    Evaluators and (indirectly) BSI representatives which became aware about this paper.</p>\n<p>And of course, there is the effect of a children's telephone game which distorts the <br>\n    story hopelessly.</p>\n<p>3) As part of the project, we wrote early a Recommandations-Whitepaper explaining the importance<br>\n    of conservative extensions and trying to define something like a “safe subset” of Isabelle. <br>\n    It is called:</p>\n<p>\"Using Isabelle/HOL in Certification Processes: A System Description and Mandatory Recommendations\" </p>\n<p>and is part one of the EUROMILS Deliverable <a href=\"http://www.euromils.eu/downloads/Deliverables/Y2/2015-EM-UsedFormalMethods-WhitePaper.pdf\">http://www.euromils.eu/downloads/Deliverables/Y2/2015-EM-UsedFormalMethods-WhitePaper.pdf</a> &lt;<a href=\"http://www.euromils.eu/downloads/Deliverables/Y2/2015-EM-UsedFormalMethods-WhitePaper.pdf\">http://www.euromils.eu/downloads/Deliverables/Y2/2015-EM-UsedFormalMethods-WhitePaper.pdf</a>&gt;,<br>\n   (pp. 1 .. 39)<br>\n    a paper that is submitted to the ANSI and the BSI as part of the Common Criteria Evaluation of the PikeOS operating system.<br>\n    It may be that these Mandatory recommendations were reused in future projects of this kind.</p>\n<p>In this paper, we ruled out the critical consts - defs combination as unsafe, and made sure that we did not use these constructs in<br>\n    our entire theories (as well as axioms, etc. Restraining strictly to conservative extension and avoiding obfuscation).</p>\n<p>4) I welcome to see more formally proved meta-theory of Isabelle’s specification constructs; the HOL4 community shows at the<br>\n    moment impressive progresses in this direction. May be that other open issues could be addressed as well. </p>\n<p>Best regards,</p>\n<p>Burkhart</p>",
        "id": 294654913,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167647
    },
    {
        "content": "<p>From: Peter Lammich &lt;<a href=\"mailto:lammich@in.tum.de\">lammich@in.tum.de</a>&gt;<br>\nIn the replied-to mail, I see more arguments that we should add proper<br>\ndependency checking to Isabelle/HOL as soon as possible.</p>\n<p>As far as I know, there is a patch of Kunčar, which exists for more than<br>\nhalf a year now, which</p>\n<p>* ensures that consts/defs only produce conservative extensions<br>\n  * Does not slow down Isabelle significantly<br>\n  * Works with whole AFP and Isabelle-Library, i.e., is does not break<br>\nexisting formalizations by being too restrictive.</p>\n<p>However, it seems to be rejected or not given high priority by some main<br>\nIsabelle developers. </p>\n<p>If we would have integrated this patch earlier, we could have said:<br>\nThere was an issue, but now it is fixed, and we even have a<br>\n(pen-and-paper) proof that it is sound now. So, anyone who reads the<br>\npaper would probably be happy, and the rumours spread would be somewhat<br>\nlike: \"The old Isabelle versions are unsound, you should update to<br>\nIsabelle-2015, this is provably sound now\"</p>\n<p>However, now we have: If you use overloading, you are basically on your<br>\nown, and have to ensure consistency yourself. Rules how to ensure<br>\nconsistent definitions are not included in the Isabelle documentation.<br>\nAnd the rumours about Isabelle unsoundness spread as described in the<br>\nreplied-to mail.</p>\n<p>So if we want to use Isabelle as a device to get very high confidence in<br>\nour proofs, any mechanism that allows you to prove False in some<br>\nintransparent ways should be considered a severe malfunction of the<br>\nsystem, and fixed as soon as possible. And tainting an essential<br>\nmechanism as axiomatic (as the documentation of defs does) is not a<br>\nsolution, but makes the system essentially unusable for getting<br>\nhigh-confidence theorems.</p>\n<p>In my opinion, we should even think of a mode of operation that forbids<br>\nto add any axioms beyond a certain default set of axioms (e.g. HOL),<br>\nsuch that we can establish the guarantee: \"Sound wrt. HOL\", without<br>\nmanually inspecting all theory files for axiomatic declarations (see<br>\nHOL-zero how to drive this idea to the extreme).</p>",
        "id": 294654965,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167665
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Wed, 16 Sep 2015, Peter Lammich wrote:</p>\n<blockquote>\n<p>As far as I know, there is a patch of Kunčar, which exists for more than<br>\nhalf a year now, which<br>\n * ensures that consts/defs only produce conservative extensions<br>\n * Does not slow down Isabelle significantly<br>\n * Works with whole AFP and Isabelle-Library, i.e., is does not break<br>\nexisting formalizations by being too restrictive.</p>\n<p>However, it seems to be rejected or not given high priority by some main<br>\nIsabelle developers.</p>\n</blockquote>\n<p>Can you quote precisely who said what?  Otherwise we get into a situation <br>\nof vague rumors and implicit accusations of unnamed people.</p>\n<blockquote>\n<p>If we would have integrated this patch earlier, we could have said:<br>\nThere was an issue, but now it is fixed, and we even have a<br>\n(pen-and-paper) proof that it is sound now. So, anyone who reads the<br>\npaper would probably be happy, and the rumours spread would be somewhat<br>\nlike: \"The old Isabelle versions are unsound, you should update to<br>\nIsabelle-2015, this is provably sound now\"</p>\n</blockquote>\n<p>The last sentence is the opposite of what I am trying to point out on <br>\nisabelle-users and on isabelle-dev for countless years. When there is an <br>\nincident of some sort, and change might improve the situation or make it <br>\nworse.  There is never a state where one could claim it to be \"fixed\".</p>\n<p>Makarius</p>",
        "id": 294654985,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167671
    },
    {
        "content": "<p>From: Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nI was under the impression that this patch had been adopted. I don’t believe that I saw any arguments against it.<br>\nLarry</p>",
        "id": 294654999,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167677
    },
    {
        "content": "<p>From: Lars Noschinski &lt;<a href=\"mailto:noschinl@in.tum.de\">noschinl@in.tum.de</a>&gt;<br>\nWe know that the current situation is bad -- at least, as long as one<br>\nwants to treat definitions as conservative extensions, which many of us<br>\nwant to do. I understand there is a patch with a sound theory behind it,<br>\nwhich prohibits unsound definitions, without breaking current applications.</p>\n<p>We may never achieve perfectness, there may be other issues, there may<br>\nbe an even deeper change which would be even better. But I would expect<br>\na critical (under the above assumptions) hole to be closed, as soon as<br>\nthe problem is understood -- and not blocked on the vague notion that<br>\nevery change may break something.</p>\n<p>-- Lars</p>",
        "id": 294655051,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167683
    },
    {
        "content": "<p>From: Peter Lammich &lt;<a href=\"mailto:lammich@in.tum.de\">lammich@in.tum.de</a>&gt;</p>\n<blockquote>\n<blockquote>\n<p>However, it seems to be rejected or not given high priority by some main<br>\nIsabelle developers.</p>\n</blockquote>\n<p>Can you quote precisely who said what?  Otherwise we get into a situation <br>\nof vague rumors and implicit accusations of unnamed people.</p>\n</blockquote>\n<p>Unfortunately, there seems to be a lot of rumours, and these issues have<br>\nnever been discussed openly. Also my knowledge is partially based on<br>\nrumours. Clear facts are the following:</p>\n<p>In their paper [2], Popescu and Kuncar refer to a patch<br>\n<a href=\"http://www21.in.tum.de/~kuncar/documents/patch.html\">http://www21.in.tum.de/~kuncar/documents/patch.html</a><br>\nand say: \"it is currently evaluated at the Isabelle headquarters\"</p>\n<p>Since the paper was written about 6 month ago, and nothing has yet<br>\nhappened in this direction [in my opinion, the patch should be<br>\nintegrated as soon as possible, and Isabelle2015-1 released immediately!<br>\n], I concluded what I said above.</p>\n<blockquote>\n<blockquote>\n<p>If we would have integrated this patch earlier, we could have said:<br>\nThere was an issue, but now it is fixed, and we even have a<br>\n(pen-and-paper) proof that it is sound now. So, anyone who reads the<br>\npaper would probably be happy, and the rumours spread would be somewhat<br>\nlike: \"The old Isabelle versions are unsound, you should update to<br>\nIsabelle-2015, this is provably sound now\"</p>\n</blockquote>\n<p>The last sentence is the opposite of what I am trying to point out on <br>\nisabelle-users and on isabelle-dev for countless years. When there is an <br>\nincident of some sort, and change might improve the situation or make it <br>\nworse.  There is never a state where one could claim it to be \"fixed\".</p>\n</blockquote>\n<p>This generic and vague statement can be used as an argument against any<br>\nchange, and against any argumentation why the change is necessary.</p>\n<p>Let me try anyway: Most users of Isabelle expect that they cannot prove<br>\nFalse, unless they use some well-known unsafe methods, such as<br>\naxiomatization and oracles. This is a primary design goal of Isabelle.<br>\nThis is supported, for example in [1], by the following statements:<br>\n  \"The logical core is implemented according to the well-known “LCF<br>\napproach”\"</p>\n<p>\"object-logics are specified by<br>\nstating their characteristic rules as new axioms. Any later additions in<br>\napplication the-<br>\nories are usually restricted to definitional specifications, and the<br>\ndesired properties are<br>\nbeing proven explicitly\"</p>\n<p>The fact that one actually can prove false by using \"defs\", which is<br>\ncommonly believed to be \"definitional specification\", is in strong<br>\ncontrast to this goal. So, any state in which <br>\n  1) all of Isabelle and AFP still works<br>\n  2) there are less possibilities to prove False in unexpected ways<br>\nis arguably an improvement, as it conforms more to a primary design<br>\ngoal. Even if this improvement makes some aspects worse, one has to<br>\nweigh up those disadvantages with the advantage of making the system<br>\nmore conforming to one of its primary design goals.</p>\n<p>References:<br>\n[1] Makarius Wenzel, Lawrence C. Paulson, Tobias Nipkow:<br>\n  The Isabelle Framework. TPHOLs 2008: 33-38</p>\n<p>[2] Ondrej Kuncar, Andrei Popescu:<br>\nA Consistent Foundation for Isabelle/HOL. ITP 2015: 234-252</p>",
        "id": 294655101,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167708
    },
    {
        "content": "<p>From: Peter Lammich &lt;<a href=\"mailto:lammich@in.tum.de\">lammich@in.tum.de</a>&gt;<br>\nOn Mi, 2015-09-16 at 16:10 +0100, Larry Paulson wrote:</p>\n<blockquote>\n<p>I was under the impression that this patch had been adopted. I don’t believe that I saw any arguments against it.<br>\nLarry</p>\n</blockquote>\n<p>If this should be true, we should make it as public as possible, to stop<br>\nany rumours about Isabelle unsoundness. The best way would be to release<br>\nIsabelle2015-1 immediately, even if it would only be (Isabelle2015 +<br>\npatch), and not based on the current state of the repository.</p>",
        "id": 294655107,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167713
    },
    {
        "content": "<p>From: Andrei Popescu &lt;<a href=\"mailto:A.Popescu@mdx.ac.uk\">A.Popescu@mdx.ac.uk</a>&gt;<br>\nDear All, </p>\n<p>As far as I know, the integration of Ondra's solution patch is in Makarius's TODO list. Before doing the integration, Makarius wanted to see a mathematical justification for why our solution is sound. <br>\nNow such a justification is provided in our ITP paper^[*], in conjunction with Ondra's CPP paper^[**]  -- it is not formal, but quite rigorous. So I see no major impediment to adopting our solution. Of course, it would be great if this were given a higher priority.  </p>\n<p>Just for the record, please also note that inconsistencies are not so infrequent in proof assistants: some of the prominent cases of such \"incidents\" are collected in our ITP paper, under the heading \"Inconsistency Club.\"</p>\n<p>[*] <a href=\"http://www.eis.mdx.ac.uk/staffpages/andreipopescu/pdf/ITP2015.pdf\">http://www.eis.mdx.ac.uk/staffpages/andreipopescu/pdf/ITP2015.pdf</a></p>\n<p>[**] <a href=\"http://www4.in.tum.de/~kuncar/documents/kuncar-cpp2015.pdf\">http://www4.in.tum.de/~kuncar/documents/kuncar-cpp2015.pdf</a> </p>\n<p>All the best, <br>\n   Andrei </p>\n<hr>\n<p>Please note that Middlesex University's preferred way of receiving all correspondence is via email in line with our Environmental Policy. All incoming post to Middlesex University is opened and scanned by our digital document handler, CDS, and then emailed to the recipient.</p>\n<p>If you do not want your correspondence to Middlesex University processed in this way please email the recipient directly. Parcels, couriered items and recorded delivery items will not be opened or scanned by CDS.  There are items which are \"exceptions\" which will be opened by CDS but will not be scanned a full list of these can be obtained by contacting the University.</p>",
        "id": 294655123,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167720
    },
    {
        "content": "<p>From: Lars Noschinski &lt;<a href=\"mailto:noschinl@in.tum.de\">noschinl@in.tum.de</a>&gt;<br>\nAs I understand it, there are/were two patches: One addressing a problem<br>\nin the implementation of the cyclicity check and a second one adding<br>\ndependencies on types as described in the ITP 2015 paper.</p>\n<p>To my knowledge, only the first one has been adopted.</p>\n<p>-- Lars</p>",
        "id": 294655135,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167726
    },
    {
        "content": "<p>From: Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nI’d like to point out again that users need to take responsibility for their own definitions. I regularly see proofs that are valueless because they are based on incorrect definitions.  </p>\n<p>To my mind, a soundness bug is when a valid expression or proof state is transformed into something wrong. The problem identified here are that Isabelle is failing to prohibit certain definitions that don’t make sense. There is no claim that Isabelle is doing anything wrong with these definitions. It’s hard to believe that a user could make such definitions accidentally.</p>\n<p>It would be interesting to find out how these problems were identified: whether they were looked for out of curiosity, or whether on the other hand they manifested themselves in the course of an actual proof.</p>\n<p>Larry Paulson</p>",
        "id": 294655143,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167732
    },
    {
        "content": "<p>From: Andrei Popescu &lt;<a href=\"mailto:a.popescu@mdx.ac.uk\">a.popescu@mdx.ac.uk</a>&gt;<br>\nDear Larry, </p>\n<p>You wrote: </p>\n<blockquote>\n<blockquote>\n<p>I'd like to point out again that users need to take responsibility for their own definitions. I regularly see proofs that are valueless because they are based on incorrect definitions.  <br>\nTo my mind, a soundness bug is when a valid expression or proof state is transformed into something wrong. The problem identified here are that Isabelle is failing to prohibit certain definitions that don't <br>\nmake sense. There is no claim that Isabelle is doing anything wrong with these definitions. It's hard to believe that a user could make such definitions accidentally.</p>\n</blockquote>\n</blockquote>\n<p>Your position here puzzles me now as much as it did the last time we talked about this. Let's forget about Isabelle/HOL for a second, and think of a logic L with axioms and deduction rules, but no definitions. <br>\nFurther, assume that L is known, or strongly believed to be consistent, in that it does not prove False. Now consider L_D, the logic L augmented with definitional mechanisms. This augmented logic should of course not prove False either! Writing meaningful definitions is the user's responsibility, but having the definitions consistent is the logic L_D's responsibility. Guaranteed consistency distinguishes definitions from arbitrary new axioms -- I learned this years ago from your papers and books.      </p>\n<p>You wrote: </p>\n<blockquote>\n<blockquote>\n<p>It would be interesting to find out how these problems were identified: whether they were looked for out of curiosity, or whether on the other hand they manifested themselves <br>\nin the course of an actual proof.</p>\n</blockquote>\n</blockquote>\n<p>Ondra discovered the typedef inconsistency, so he is the best person to answer this. </p>\n<p>All the best, <br>\n   Andrei </p>\n<hr>\n<p>Please note that Middlesex University's preferred way of receiving all correspondence is via email in line with our Environmental Policy. All incoming post to Middlesex University is opened and scanned by our digital document handler, CDS, and then emailed to the recipient.</p>\n<p>If you do not want your correspondence to Middlesex University processed in this way please email the recipient directly. Parcels, couriered items and recorded delivery items will not be opened or scanned by CDS.  There are items which are \"exceptions\" which will be opened by CDS but will not be scanned a full list of these can be obtained by contacting the University.</p>",
        "id": 294655156,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167738
    },
    {
        "content": "<p>From: \"\\\"Mark Adams\\\"\" &lt;<a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a>&gt;<br>\nI think there is an important distinction here between getting a definition<br>\nwrong and making the logic inconsistent.  Of course a user can always<br>\naccidentally make a wrong definition, and of course this is a big problem is<br>\nusage of theorem provers, but this is a red herring.  Users rightly expect<br>\nthat it should not be possible for definitions to make the logic<br>\ninconsistent.  This, surely, is one of the big selling points of using<br>\ndefinitional facilities as opposed to just adding axioms - they are (or<br>\nshould be) fundamentally conservative.  And this is why it was so important<br>\nto fix the bug in HOL's primitive constant definition facility in the late<br>\n1980s, where type variables occurring in the RHS were allowed not to occur<br>\nin the LHS.</p>\n<p>Mark Adams.</p>\n<p>on 16/9/15 5:25 PM, Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>I’d like to point out again that users need to take responsibility for<br>\ntheir<br>\nown definitions. I regularly see proofs that are valueless because they<br>\nare<br>\nbased on incorrect definitions.</p>\n<p>To my mind, a soundness bug is when a valid expression or proof state is<br>\ntransformed into something wrong. The problem identified here are that<br>\nIsabelle is failing to prohibit certain definitions that don’t make sense.<br>\nThere is no claim that Isabelle is doing anything wrong with these<br>\ndefinitions. It’s hard to believe that a user could make such definitions<br>\naccidentally.</p>\n<p>It would be interesting to find out how these problems were identified:<br>\nwhether they were looked for out of curiosity, or whether on the other<br>\nhand<br>\nthey manifested themselves in the course of an actual proof.</p>\n<p>Larry Paulson</p>\n<p>On 16 Sep 2015, at 16:39, Peter Lammich &lt;<a href=\"mailto:lammich@in.tum.de\">lammich@in.tum.de</a>&gt; wrote:</p>\n<blockquote>\n<p>On Mi, 2015-09-16 at 16:10 +0100, Larry Paulson wrote:</p>\n<blockquote>\n<p>I was under the impression that this patch had been adopted. I don’t<br>\nbelieve that I saw any arguments against it.<br>\nLarry</p>\n</blockquote>\n<p>If this should be true, we should make it as public as possible, to stop<br>\nany rumours about Isabelle unsoundness. The best way would be to release<br>\nIsabelle2015-1 immediately, even if it would only be (Isabelle2015 +<br>\npatch), and not based on the current state of the repository.</p>\n<p>--<br>\n Peter<br>\n</p>\n</blockquote>\n</blockquote>",
        "id": 294655180,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167750
    },
    {
        "content": "<p>From: Ramana Kumar &lt;<a href=\"mailto:rk436@cam.ac.uk\">rk436@cam.ac.uk</a>&gt;<br>\nLet me add to this discussion, just because I happen to have been<br>\ndiscussing it at Data61 yesterday too.</p>\n<p>Yesterday, I showed my colleagues that it is possible to prove False in<br>\nIsabelle2015 without any warnings or errors and without any use of<br>\naxiomatization or oracles. The trick was, of course, Ondrej's example, but<br>\nupdated to use \"overloading\" rather than the deprecated \"defs\" keyword.<br>\nMany of them were surprised, and wanted to know why, when I said that a<br>\npatch did exist, it has not been incorporated. I think rumours about<br>\n\"Isabelle developers\" are unavoidable at that point. We are also interested<br>\nin the opinion of qualifiers and regulators of the tools we use, and<br>\nBurkhart's original message is very interesting from that perspective.</p>\n<p>My own opinion now: I would like the patch intended to make it impossible<br>\nto prove False in Isabelle/HOL no matter what definitions one uses<br>\nincorporated as soon as possible. I'm surprised that that is a contentious<br>\nissue. I believe we have found the last of those problems now, because of<br>\nOndrej and Andrei's (on paper) consistency proof.</p>\n<p>In the longer term, I am very interested in mechanising the consistency<br>\nproof (as we have done for the basic HOL logic as used in HOL Light).<br>\nFurthermore, if there is enough community interest, I would be interested<br>\nin building a verified proof-checker for Isabelle/HOL. One crucial<br>\ningredient required from the Isabelle community here is the ability to<br>\nexport proofs in a low-level format (ideally OpenTheory, rather than some<br>\nother new format), but I believe you're already quite close to that with<br>\nthe option to produce proof terms.</p>\n<p>I think this story involving explicit proofs and small verified checkers is<br>\nthe ultimate one to sell to certification authorities, even while<br>\nday-to-day we also want our big tools to be sound.</p>",
        "id": 294655231,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167773
    },
    {
        "content": "<p>From: Jasmin Blanchette &lt;<a href=\"mailto:jasmin.blanchette@inria.fr\">jasmin.blanchette@inria.fr</a>&gt;<br>\nDear Larry, Andrei,</p>\n<blockquote>\n<p>Your position here puzzles me now as much as it did the last time we talked about this. Let's forget about Isabelle/HOL for a second, and think of a logic L with axioms and deduction rules, but no definitions. <br>\nFurther, assume that L is known, or strongly believed to be consistent, in that it does not prove False. Now consider L_D, the logic L augmented with definitional mechanisms. This augmented logic should of course not prove False either! Writing meaningful definitions is the user's responsibility, but having the definitions consistent is the logic L_D's responsibility. Guaranteed consistency distinguishes definitions from arbitrary new axioms -- I learned this years ago from your papers and books.</p>\n</blockquote>\n<p>I can only second this. After reading books like the Isabelle tutorial, which has Larry as a coauthor, I developed a certain understanding for what \"definitional\" and \"foundational\" means, and was for many years under the impression that there was a strong consensus in the proof assistant communities. In this context, I find Larry's comments rather puzzling. In fact, I agree with almost every single sentence he wrote, but</p>\n<p>To my mind, a soundness bug is when a valid expression or proof state is transformed into something wrong.</p>\n<p>violates the very notion of \"definitional\". At some point, we will have to make up our minds as to whether our definitions are definitions or just arbitrary axioms (and whether \"typedef\"s count as definition).</p>\n<p>Mark's comments, which I just read, also neatly summarizes what I thought until recently was a consensus also shared by Larry.</p>\n<p>Jasmin</p>",
        "id": 294655235,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167775
    },
    {
        "content": "<p>From: Holger Blasum &lt;<a href=\"mailto:hbl@sysgo.com\">hbl@sysgo.com</a>&gt;<br>\nHello Larry, list,</p>\n<p>I can give more detail for the case of EURO-MILS: We were made aware of <br>\n\"Isabelle Isar-Reference Manual (Version 2013-2, pp. 103): \"It is at<br>\nthe discretion of the user to avoid malformed theory specifications!\"[1]<br>\nHence first attempt was to rule out use of \"consts\"[2].<br>\nThis resulted in people even becoming more curious and playing <br>\nwith Kuncar/Popescu.<br>\nMoreover, it has been pointed out that even if we rule out \"consts\" and \"defs\" in our theories then it is still used e.g. in HOL.thy[3] (probably without <br>\noverloading, but it is hard to judge for me).</p>\n<p>The task at hand is not only convincing ourselves (arguably when proving some <br>\nproperty oneself one usually/sometimes gets a feeling for what is correct<br>\nand what not) but also others (who have limited resources).</p>\n<p>To give an example: in attached System_Is_Secure.thy the first <br>\nderivation of \"System_Is_Secure\" (theorem System_Is_Secure_1) <br>\nforces to make the assumptions of \"A\" and \"~A\" obvious. This makes <br>\nit harder to cheat ourselves or others.</p>\n<p>The second derivation of \"System_Is_Secure\" (theorem System_Is_Secure_2)<br>\nhides the assumptions and could be more easy be overlooked.</p>\n<p>My working understanding is (correct if that is wrong!) that fixing <br>\nIsabelle would rule out hidden derivations such as System_Is_Secure_2.</p>\n<p>[1] <a href=\"http://isabelle.in.tum.de/doc/isar-ref.pdf\">http://isabelle.in.tum.de/doc/isar-ref.pdf</a> p 121 <br>\nThe (unchecked) option disables global dependency checks for this def-<br>\ninition, which is occasionally useful for exotic overloading. It is at<br>\nthe discretion of the user to avoid malformed theory specifications!<br>\n[2] <a href=\"http://www.euromils.eu/downloads/Deliverables/Y2/2015-EM-UsedFormalMethods-WhitePaper.pdf\">http://www.euromils.eu/downloads/Deliverables/Y2/2015-EM-UsedFormalMethods-WhitePaper.pdf</a> Section 3.1 \"Constants. The Isabelle consts command is not used.\"<br>\n[3] <a href=\"http://afp.sourceforge.net/browser_info/current/HOL/HOL/HOL.html\">http://afp.sourceforge.net/browser_info/current/HOL/HOL/HOL.html</a><br>\nsearch for \"defs\"</p>\n<p>---------(inlined: System_Is_Secure.thy, also attached)<br>\ntheory System_Is_Secure<br>\n  imports Main<br>\n  begin</p>\n<p>consts A :: bool<br>\nconsts System_Is_Secure :: bool</p>\n<p>(* formulation with explicit assumptions, easy for reviewer to spot that user made too strong assumptions *)<br>\ntheorem System_Is_Secure_1: <br>\n  assumes \"A\" <br>\n  and \"~ A\"  <br>\n  shows System_Is_Secure<br>\nproof-<br>\n  from assms show ?thesis by simp<br>\nqed</p>\n<p>(* Kuncar/Popescu: A Consistent Foundation for Isabelle/HOL, ITP 2015 *)<br>\nconsts c :: bool<br>\ntypedef T = \"{True, c}\" by blast<br>\ndefs c_bool_def: \"c::bool == ~ (ALL(x::T) y. x = y)\"<br>\n lemma L: \"(ALL(x::T) y. x = y) &lt;-&gt; c\"<br>\nusing Rep_T Rep_T_inject Abs_T_inject by blast<br>\nlemma MyFalse: False<br>\nusing L unfolding c_bool_def by auto</p>\n<p>theorem MySystem_Is_Secure [simp]: System_Is_Secure<br>\nusing MyFalse by simp</p>\n<p>(* formulation with implicit assumptions, not that easy for reviewer to spot that user made too strong assumptions *)<br>\ntheorem System_Is_Secure_2: System_Is_Secure by simp</p>\n<p>end</p>\n<p>best,</p>",
        "id": 294655247,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167781
    },
    {
        "content": "<p>From: Holger Blasum &lt;<a href=\"mailto:hbl@sysgo.com\">hbl@sysgo.com</a>&gt;<br>\nSame posting as parent, this time with attachment attached.<br>\n<a href=\"/user_uploads/14278/TGqdSlkXSmxMgu5VxWO2He-N/System_Is_Secure.thy\">System_Is_Secure.thy</a></p>",
        "id": 294655259,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167788
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nOn 16/09/2015 17:48, Andrei Popescu wrote:</p>\n<blockquote>\n<p>Dear All,</p>\n<p>As far as I know, the integration of Ondra's solution patch is in Makarius's TODO list. Before doing the integration, Makarius wanted to see a mathematical justification for why our solution is sound.<br>\nNow such a justification is provided in our ITP paper^[*], in conjunction with Ondra's CPP paper^[**]  -- it is not formal, but quite rigorous. So I see no major impediment to adopting our solution.&gt;</p>\n</blockquote>\n<p>Let us hope you are right, although Makarius was dismissive of what you proved <br>\nin earlier discussions and wanted a conservativity result.</p>\n<p>Moreover, the check that Ondrej implemented is clearly necessary to ban these <br>\ncicularities.</p>\n<blockquote>\n<p>Of course, it would be great if this were given a higher priority.</p>\n</blockquote>\n<p>That is the whole point. This is not a minor issue with fonts but concerns and <br>\nendangers the very core of what we are doing.</p>\n<p>Tobias</p>\n<blockquote>\n<p>Just for the record, please also note that inconsistencies are not so infrequent in proof assistants: some of the prominent cases of such \"incidents\" are collected in our ITP paper, under the heading \"Inconsistency Club.\"</p>\n<p>[*] <a href=\"http://www.eis.mdx.ac.uk/staffpages/andreipopescu/pdf/ITP2015.pdf\">http://www.eis.mdx.ac.uk/staffpages/andreipopescu/pdf/ITP2015.pdf</a></p>\n<p>[**] <a href=\"http://www4.in.tum.de/~kuncar/documents/kuncar-cpp2015.pdf\">http://www4.in.tum.de/~kuncar/documents/kuncar-cpp2015.pdf</a></p>\n<p>All the best,<br>\n    Andrei</p>\n<hr>\n<p>Please note that Middlesex University's preferred way of receiving all correspondence is via email in line with our Environmental Policy. All incoming post to Middlesex University is opened and scanned by our digital document handler, CDS, and then emailed to the recipient.</p>\n<p>If you do not want your correspondence to Middlesex University processed in this way please email the recipient directly. Parcels, couriered items and recorded delivery items will not be opened or scanned by CDS.  There are items which are \"exceptions\" which will be opened by CDS but will not be scanned a full list of these can be obtained by contacting the University.</p>\n<p><a href=\"/user_uploads/14278/EU2LQZB1E-U78DWt_7-nAG86/smime.p7s\">smime.p7s</a></p>\n</blockquote>",
        "id": 294655267,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167794
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:tjark.weber@it.uu.se\">tjark.weber@it.uu.se</a>&gt;<br>\nRamana,</p>\n<p>Take a look at Stefan Berghofer's thesis. He already implemented a<br>\nproof checker for his proof terms (albeit not verified).</p>\n<p>The main issue, if I recall correctly, was that these proof terms could<br>\nbecome huge.</p>\n<p>Best,<br>\nTjark</p>",
        "id": 294655294,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167802
    },
    {
        "content": "<p>From: Ramana Kumar &lt;<a href=\"mailto:rk436@cam.ac.uk\">rk436@cam.ac.uk</a>&gt;<br>\nThanks Tjark.</p>\n<p>I am aware of Stefan's excellent work, and I'm sorry if I gave the<br>\nimpression that my proposal was novel in any sense. (Perhaps the part about<br>\nverifying the checker is new, but that's just icing for the purposes of<br>\nthis discussion.)</p>\n<p>My concern is whether the proof checker for proof terms is actually used or<br>\nnot. In an ideal world, I would think that for any substantial<br>\nformalisation, the proof terms would be the bulk of the evidence provided<br>\nto the certification authority or any other party interested to know why<br>\nthe claims being made are true, and those proof terms would be checked<br>\nregularly (say twice a year) by a small checker if the formalisation is<br>\nunder continued development. Does anyone actually do that? Is scalability<br>\nthe only issue?</p>\n<p>Apologies if this is veering too far from the original topic. I'm happy to<br>\ncontinue discussion on another thread if desired.</p>",
        "id": 294655334,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167805
    },
    {
        "content": "<p>From: Peter Lammich &lt;<a href=\"mailto:lammich@in.tum.de\">lammich@in.tum.de</a>&gt;<br>\nI feel like I should give a real example of what I think is consensus,<br>\nand why the current state in Isabelle/HOL is not satisfactory:</p>\n<p>If I manage to prove in Isabelle, e.g.,</p>\n<p>theorem fermats_theorem: <br>\n    \"∀n::nat&gt;2. ¬(∃a::nat&gt;0. ∃b::nat&gt;0. ∃c::nat&gt;0. a^n + b^n = c^n)\"</p>\n<p>then, to believe that I really proved Fermat, one only has to check that<br>\nthe definitions of the natural number library really match the expected<br>\noperations on naturals, and that my statement of the theorem really<br>\nmatches Fermat's theorem.</p>\n<p>However, in current Isabelle, one has to check every single definition,<br>\neven the unrelated ones, for consistency, to rule out, e.g., the<br>\nfollowing proof. Note that this proof, assuming Fermat really holds,<br>\ndoes not even introduce inconsistency into the logic ... it's just a<br>\nhidden axiomatization of Fermat:</p>\n<p>(* Hide and obfuscate this stuff well, such that it is not too<br>\n     easy to find for a human, but ensure that ATPs still find it<br>\n  *)<br>\n  definition \"P ≡ <br>\n      ∀n::nat&gt;2. ¬(∃a::nat&gt;0. ∃b::nat&gt;0. ∃c::nat&gt;0. a^n + b^n = c^n)\"</p>\n<p>consts c :: bool<br>\n  typedef T = \"{True,c}\" by blast</p>\n<p>lemma L: \"(∀(x::T) y. x = y) ⟷ c\"<br>\n    using Rep_T Rep_T_inject Abs_T_inject by (cases c) force+</p>\n<p>defs c_def: \"c ≡ if (∀x::T. ∀y. x=y) then P else ¬P\"</p>\n<p>(* Place this main statement prominently in your theories, and hail<br>\n    sledgehammer for being really powerful *)<br>\n  theorem fermats_theorem: <br>\n    \"∀n::nat&gt;2. ¬(∃a::nat&gt;0. ∃b::nat&gt;0. ∃c::nat&gt;0. a^n + b^n = c^n)\"<br>\n    using L P_def c_def by presburger (* This proof was found by<br>\nsledgehammer! *)</p>\n<p>So, with sledgehammer becoming more powerful, and having the possibility<br>\nof making inconsistent definitions, it's only a matter of time when<br>\nsledgehammer finds some nice proof for you, which exploits, in some<br>\nnon-obvious ways, the inconsistency of completely unrelated definitions.</p>",
        "id": 294655357,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167812
    },
    {
        "content": "<p>From: Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nThanks for giving this example.</p>\n<p>As people seem to have misunderstood my position, let me try again, because important points are being overlooked.</p>\n<p>Of course I think that this circularity check ought to be made. I was under the impression that this patch had been made already. Nevertheless, I do not believe that it poses any immediate problem for users.</p>\n<p>Over the whole of the 1990s, it was possible to introduce cyclic definitions in Isabelle, and this possibility was specifically mentioned in the documentation. To do this required making three separate steps: you had to introduce some A, then define some B in terms of A, and finally define A in terms of B. Anybody who thinks they are in danger of doing this accidentally really should be working in another field.  Certainly none of our existing users were affected when we tightened up our checks. Nobody had made this mistake.</p>\n<p>The reason I keep stressing this point is that I regularly see work where the definitions don’t make any sense, even though they are noncircular. It is very easy to do. You verify some mechanism and you include some well-definedness predicate on states that can never be satisfied. Then you prove “WD(x) ==&gt; P(x)\". Ph.D. supervisors and referees do to overlook such things, even when they are blatant. And then it is necessary to argue with the referees because “the proof has been checked by machine”.</p>\n<p>I am sure that this type definition problem will be fixed in time for the next release. I’m not sure whether the other problem will be fixed.</p>\n<p>Larry Paulson</p>",
        "id": 294655375,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167818
    },
    {
        "content": "<p>From: Ramana Kumar &lt;<a href=\"mailto:rk436@cam.ac.uk\">rk436@cam.ac.uk</a>&gt;<br>\nDear Larry,</p>\n<p>Thank you for the clarification. I agree that you are making an important<br>\npoint.</p>\n<p>I’m not sure whether the other problem will be fixed.<br>\n&gt;</p>\n<p>One might be tempted to throw up hands and proclaim that the theorem prover<br>\ncannot be expected to check that your definitions actually make sense; at<br>\nbest it can check that they are consistent. However, thinking about this<br>\nproblem just now, I realised that something similar to the existing<br>\nAutoQuickcheck could be helpful: something that says \"you seem to be trying<br>\nto prove this the hard way, but it's actually very simple because your<br>\nassumptions imply False!\".</p>\n<p>Ramana</p>",
        "id": 294655398,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167824
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nOn 17/09/2015 13:56, Larry Paulson wrote:</p>\n<blockquote>\n<p>Thanks for giving this example.</p>\n<p>As people seem to have misunderstood my position, let me try again, because important points are being overlooked.</p>\n<p>Of course I think that this circularity check ought to be made. I was under the impression that this patch had been made already. Nevertheless, I do not believe that it poses any immediate problem for users.</p>\n<p>Over the whole of the 1990s, it was possible to introduce cyclic definitions in Isabelle, and this possibility was specifically mentioned in the documentation. To do this required making three separate steps: you had to introduce some A, then define some B in terms of A, and finally define A in terms of B. Anybody who thinks they are in danger of doing this accidentally really should be working in another field.  Certainly none of our existing users were affected when we tightened up our checks. Nobody had made this mistake.</p>\n<p>The reason I keep stressing this point is that I regularly see work where the definitions don’t make any sense, even though they are noncircular. It is very easy to do. You verify some mechanism and you include some well-definedness predicate on states that can never be satisfied. Then you prove “WD(x) ==&gt; P(x)\". Ph.D. supervisors and referees do to overlook such things, even when they are blatant. And then it is necessary to argue with the referees because “the proof has been checked by machine”.</p>\n</blockquote>\n<p>In the model checking community this is known as the vacuity problem and it has <br>\nreceived a certain amount of attention.</p>\n<p>Tobias</p>\n<blockquote>\n<p>I am sure that this type definition problem will be fixed in time for the next release. I’m not sure whether the other problem will be fixed.</p>\n<p>Larry Paulson</p>\n<p>On 17 Sep 2015, at 07:14, Holger Blasum &lt;<a href=\"mailto:hbl@sysgo.com\">hbl@sysgo.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hello Larry, list,<br>\n</p>\n</blockquote>\n<p>On 09-16, Larry Paulson wrote:</p>\n<blockquote>\n<blockquote>\n<p>It would be interesting to find out how these problems were identified: whether they were looked for out of curiosity, or whether on the other hand they manifested themselves in the course of an actual proof.</p>\n</blockquote>\n<p>I can give more detail for the case of EURO-MILS: We were made aware of<br>\n\"Isabelle Isar-Reference Manual (Version 2013-2, pp. 103): \"It is at<br>\nthe discretion of the user to avoid malformed theory specifications!\"[1]<br>\nHence first attempt was to rule out use of \"consts\"[2].<br>\nThis resulted in people even becoming more curious and playing<br>\nwith Kuncar/Popescu.</p>\n</blockquote>\n<p><a href=\"/user_uploads/14278/BvnhL6EMUPkMuk14NMgzMaqn/smime.p7s\">smime.p7s</a></p>\n</blockquote>",
        "id": 294655425,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167837
    },
    {
        "content": "<p>From: Johannes Hölzl &lt;<a href=\"mailto:hoelzl@in.tum.de\">hoelzl@in.tum.de</a>&gt;<br>\nAm Donnerstag, den 17.09.2015, 12:56 +0100 schrieb Larry Paulson:<br>\n[..]</p>\n<blockquote>\n<p>Over the whole of the 1990s, it was possible to introduce cyclic<br>\ndefinitions in Isabelle, and this possibility was specifically<br>\nmentioned in the documentation. To do this required making three<br>\nseparate steps: you had to introduce some A, then define some B in<br>\nterms of A, and finally define A in terms of B. Anybody who thinks<br>\nthey are in danger of doing this accidentally really should be working<br>\nin another field.  Certainly none of our existing users were affected<br>\nwhen we tightened up our checks. Nobody had made this mistake.</p>\n</blockquote>\n<p>If such a circle happens in the _one_ theory file and is as obvious as<br>\nthis one, maybe the developer should be working in another field. But we<br>\nget a bigger and bigger type class hierarchy and we started a couple of<br>\nyears ago to use type classes in type definitions. I work a lot with the<br>\ntype class hierarchy but some parts are still blurry to me. The last<br>\ntime Florian printed it out, it was a huge poster!</p>\n<p>For large developments in Isabelle, one imports a lot of theories and<br>\nuses a lot of automatic proof methods. What happens if my definitions<br>\nare completely fine, but a freak combination of theories I import allows<br>\nSledgehammer to prove false?</p>\n<ul>\n<li>Johannes</li>\n</ul>\n<blockquote>\n<p>The reason I keep stressing this point is that I regularly see work<br>\nwhere the definitions don’t make any sense, even though they are<br>\nnoncircular. It is very easy to do. You verify some mechanism and you<br>\ninclude some well-definedness predicate on states that can never be<br>\nsatisfied. Then you prove “WD(x) ==&gt; P(x)\". Ph.D. supervisors and<br>\nreferees do to overlook such things, even when they are blatant. And<br>\nthen it is necessary to argue with the referees because “the proof has<br>\nbeen checked by machine”.</p>\n<p>I am sure that this type definition problem will be fixed in time for<br>\nthe next release. I’m not sure whether the other problem will be<br>\nfixed.</p>\n<p>Larry Paulson</p>\n<p>On 17 Sep 2015, at 07:14, Holger Blasum &lt;<a href=\"mailto:hbl@sysgo.com\">hbl@sysgo.com</a>&gt; wrote:</p>\n<blockquote>\n<p>Hello Larry, list,<br>\n</p>\n</blockquote>\n<p>On 09-16, Larry Paulson wrote:</p>\n<blockquote>\n<blockquote>\n<p>It would be interesting to find out how these problems were<br>\nidentified: whether they were looked for out of curiosity, or whether<br>\non the other hand they manifested themselves in the course of an<br>\nactual proof.</p>\n</blockquote>\n<p>I can give more detail for the case of EURO-MILS: We were made aware<br>\nof <br>\n\"Isabelle Isar-Reference Manual (Version 2013-2, pp. 103): \"It is at<br>\nthe discretion of the user to avoid malformed theory<br>\nspecifications!\"[1]<br>\nHence first attempt was to rule out use of \"consts\"[2].<br>\nThis resulted in people even becoming more curious and playing <br>\nwith Kuncar/Popescu.</p>\n</blockquote>\n</blockquote>",
        "id": 294655436,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167843
    },
    {
        "content": "<p>From: Burkhart Wolff &lt;<a href=\"mailto:Burkhart.Wolff@lri.fr\">Burkhart.Wolff@lri.fr</a>&gt;<br>\nDear Larry,</p>\n<p>I respectfully disagree.<br>\nIt poses an immediate problem for users who have to argue in front of<br>\ncertification authorities why using Isabelle may guarantee absolute certainty<br>\n(within a given frame of an underlying logic and model). And this might be an<br>\nimportant business case for the entire community.</p>\n<p>Why Isabelle, if I could also apply Bachblütentherapie to improve software quality ? </p>\n<p>If a definition makes SENSE (that is, in my view, indeed users responsibility) is just <br>\nanother issue than that it makes an underlying theory inconsistent, which should<br>\nbe Isabelle’s responsibility if methodologically correctly used.</p>\n<p>By the way, I support the proposal earlier made in this thread to have a<br>\n“safe_use_flag” which restricts a session to constructs that we have reasons<br>\nto believe that they are conservative.</p>\n<p>Best</p>\n<p>bu</p>",
        "id": 294655448,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167849
    },
    {
        "content": "<p>From: Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nSledgehammer is also useful here, because generally you get to see exactly which facts have been used to prove the theorem. Sometimes you may see a fact being used there doesn’t appear to be relevant. It’s always worth checking to see what is going on.</p>\n<p>Larry</p>",
        "id": 294655460,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167855
    },
    {
        "content": "<p>From: Lars Noschinski &lt;<a href=\"mailto:noschinl@in.tum.de\">noschinl@in.tum.de</a>&gt;<br>\nI am not aware of anyone doing that. As far as I can tell, we only ever<br>\nbuild Main with proof terms, and even that breaks frequently (by hitting<br>\nsome resource limit).</p>\n<p>-- Lars</p>",
        "id": 294655478,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167861
    },
    {
        "content": "<p>From: David Cock &lt;<a href=\"mailto:david.cock@inf.ethz.ch\">david.cock@inf.ethz.ch</a>&gt;<br>\nWe tried it once on seL4.  We ran out of memory (192GB, from memory) <br>\n<em>very</em> quickly.  It's currently impractical.  A streaming approach might <br>\nbe better i.e. have the proof checker run simultaneously with Isabelle, <br>\nand check every step taken by the kernel as it's made, without ever <br>\nhaving to actually construct the whole proof term.</p>\n<p>David</p>",
        "id": 294655502,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167871
    },
    {
        "content": "<p>From: Larry Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nDear Burkhart,</p>\n<p>I sympathise with you, but you go too far.</p>\n<p>We do want tools such as Isabelle to be trusted by regulators and authorities. and so we do need to address every issue of this sort that comes along. Nevertheless, we should not be guaranteeing absolute certainty to anybody. If we oversell what is achievable, we risk a backlash.</p>\n<p>It is true that it is now realistic to imagine fully verified proof checkers, the compilation to machine code also verified, running on a verified operating system and on verified hardware. Nevertheless, all of this involves using verification technology to verify itself. And there are innumerable other ways in which errors can creep in. Your “within a given model” is a huge qualification on \"absolute certainty\".</p>\n<p>Avra Cohn’s 1989 essay on the subject remains topical:</p>\n<p><a href=\"http://www.cl.cam.ac.uk/~mjcg/papers/AvraProofPaper.pdf\">http://www.cl.cam.ac.uk/~mjcg/papers/AvraProofPaper.pdf</a><br>\n<a href=\"http://link.springer.com/article/10.1007%2FBF00243000\">http://link.springer.com/article/10.1007%2FBF00243000</a></p>\n<p>There are any number of papers that report some of the gains that can be realised using verification tools, without making unrealistic promises.</p>\n<p>Larry</p>",
        "id": 294655507,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167873
    },
    {
        "content": "<p>From: Burkhart Wolff &lt;<a href=\"mailto:Burkhart.Wolff@lri.fr\">Burkhart.Wolff@lri.fr</a>&gt;<br>\nDear Larry,</p>\n<p>I was talking here about </p>\n<ul>\n<li>(relative) consistency of the logic</li>\n<li>and it's safe extension schemes.<br>\nShort term goal: an agreement on the safe core (I e : kernel PLUS extension schemes) and on the methodological issues.</li>\n</ul>\n<p>Formal proofs for that are challenging, but nowadays perfectly feasible. </p>\n<p>I was NOT talking about implementation correctness of Isabelle \"as is\", I am perfectly aware <br>\nOf the quite monstrous proof task and the principle limits of such an approach (it's always going to be based on models ... Of the machine,<br>\nThe compiler, etc.)</p>\n<p>Still, On the long run, relative<br>\nSolutions along this line of research <br>\nwill and should come even for implementation correctness of Isabelle.</p>\n<p>Bu</p>\n<p>Von meinem iPhone gesendet</p>",
        "id": 294655526,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661167880
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThis is an important point that is rarely explored systematically.  From <br>\nmy own experience in the past 10-15 years:</p>\n<p>* \"synthetic problems\" of the first kind are encountered about 2 times<br>\n     per year; typical changes are ff75ed08b3fb (2001) or ccbf9379e355<br>\n     (2015)</p>\n<p>* \"practical problems\", i.e. those encountered in actual applications<br>\n     are encountered every 2-3 years</p>\n<p>What happens all the time are misunderstandings by users about concrete <br>\nsyntax or concrete syntax that is actually wrong.  Nobody is worried about <br>\nthat as a custom.</p>\n<p>Makarius</p>",
        "id": 294657237,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661168535
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nHere is the missing entry:</p>\n<p><strong> HOL Zero </strong></p>\n<p>Minimalistic re-implementation of HOL, designed with trustworthiness as <br>\nits top priority.</p>\n<p>[small]      +++<br>\n   [ML]         ++<br>\n   [thm]        +++<br>\n   [defs]       +++<br>\n   [context]    0<br>\n   [logic]      ++<br>\n   [formalized] 0</p>\n<p>[ML] Unlike HOL-Light there are explicit provisions to avoid unsafe <br>\naspects of OCaml. Architectural weaknesses remain, since user ML scripts <br>\noperate directly on the OCaml toplevel.</p>\n<p>[small], [thm], [defs], [context], [logic] similar to HOL Light.</p>\n<p>I.e. it is mostly like HOL Light, but [ML] gets ++ (like HOL4 with its SML <br>\nbasis), because extra care is taken to avoid weaknesses of OCaml.</p>\n<p>A fully managed ML environment as in Isabelle would get +++.</p>\n<p>Makarius</p>",
        "id": 294657245,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661168542
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nIndeed.  All of this mostly talks about the \"logical core\", whatever its <br>\ninternal structure is precisely.</p>\n<p>Around the core there are many more aspects, where users can do non-sense, <br>\nor the system could be wrong.</p>\n<p>Makarius</p>",
        "id": 294657255,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661168548
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThat is definitely interesting work.  I had some discussions about it with <br>\nAli Assaf in October 2013, IIRC.</p>\n<p>What is also remarkable in the above paper: the \"HOL family\" only covers <br>\nthe actual HOL systems, while Isabelle/HOL falls into the category of <br>\n\"other systems\" (like Coq, Nuprl).</p>\n<p>Thus the HOL family proper is defined as the systems with full <br>\nimport/export wrt. OpenTheory.</p>\n<p>Makarius</p>",
        "id": 294657262,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661168554
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nInteresting paper.  Here are some notes, after skimming through it.</p>\n<ul>\n<li>\n<p>The term \"LCF approach\" is used in the tradition of HOL88 to include<br>\n   definitional principles, but LCF (and Isabelle) did not have that from<br>\n   the outset.  For papers that talk about trustworthyness of provers, the<br>\n   distinction of [thm] vs. [theory] -- according to my earlier<br>\n   categorization -- to avoid great confusion.</p>\n</li>\n<li>\n<p>Concerning ML (SML or OCaml) as \"system implementation language\" and<br>\n   weaknesses coming from exposing that to the user: LCF did not have this<br>\n   problem, the LISP core was clearly separated from ML.  The HOL family<br>\n   after HOL88 collapsed everything to one ML toplevel.  Isabelle is closer<br>\n   to original LCF by running user-code in a managed Isabelle/ML<br>\n   environment that is not the same as the underlying SML.</p>\n</li>\n<li>\n<p>Isabelle does not have \"proof scripts\". The proper terminology is \"proof<br>\n   texts\" or \"proof documents\". The point is that there is more structural<br>\n   integrity enforced by the system, on some controlled language that is<br>\n   not just the implementation language of the prover.</p>\n</li>\n<li>\n<p>\"Allow uncontrolled adaption to the way formulae are displayed\": cf.<br>\n   check/uncheck phases in Isabelle, which admit arbitrary non-sense on<br>\n   input and output of terms, without any formal barriers.  These are<br>\n   official programming interfaces, not back-doors.</p>\n</li>\n<li>\n<p>3.2.1 interesting notes about HOL Light, including a special<br>\n   (non-)treatment of typedefs as implicit pre-requisites to proven<br>\n   theorems.  Such a formal record of dependencies (or \"proof digest\"  in<br>\n   Isabelle terminology) was excluded from the discussion so far.  The<br>\n   question is how \"holes\" in the reasoning are tracked (non-definitional<br>\n   axioms, oracles).  I think that HOL4 is doing this most thoroughly.<br>\n   Isabelle only half-thoroughly.</p>\n</li>\n</ul>\n<p>I liked the general approach to port formalizations to other systems for <br>\nindependent checking.  I think the main weakness of the bigger systems <br>\n(Coq, Isabelle) is that they have grown into large islands of their own, <br>\nislands that could be mistaken as continents.  It would be exceedingly <br>\nnice to see full OpenTheory connectivity for Isabelle/HOL, although the <br>\naddition of overloaded type constructors to the standard portfolio has <br>\nmoved us one more step away from it.</p>\n<p>Makarius</p>",
        "id": 294657274,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661168560
    }
]