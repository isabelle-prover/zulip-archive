[
    {
        "content": "<p>From: grechukbogdan &lt;<a href=\"mailto:grechukbogdan@yandex.ru\">grechukbogdan@yandex.ru</a>&gt;<br>\nDear Professir Nipkov<br>\nDear Isabelle Users</p>\n<p>Thank you for the intensive discussion of the suggestions. Here I want to clarify some issues.</p>\n<p>1.Proof stability</p>\n<p>1.1  Feasibility<br>\nYes, of course,  the “proof certificate” should include the proof s of required lemmas <br>\nonly once, as described by Pater Lammich. Writing “the proofs of intermediate lemmas will also be unpacked”,  I mean that proof certificate should include such a proofs, not just refer to Isabelle library.  What I want, it should be independent from the library,  and every line should be a simple corollary from previous lines (in other words, previous lemmas), and thus the proof can be checked by verifier which is 1) simple 2) independent from version of Isabelle, ideally independent from Isabelle itself.</p>\n<p>1.2  Readability</p>\n<blockquote>\n<blockquote>\n<p>And you would have lost the readable version.<br>\nClearly, I am not proposing to delete all usual readable proofs in Isabelle after implementing “proof certificates”, so the readable non-stable version will not be lost. But may be in the future we will have so many theorems in Isabelle, that it will be just impossible to fix all the broken proof scripts. In this case we would at least have proof certificates which guarantee correctness. Moreover, may be it will be possible to create a readable tactic-based proof back from proof certificate. But for now, I would like to have usual readable proof in Isabelle, and in parallel I want to have a possibility to get a stable universal proof certificate for any theorem I have proved.</p>\n</blockquote>\n</blockquote>\n<p>1.3. Stability</p>\n<blockquote>\n<blockquote>\n<p>And if one day the format for primitive proofs changes...<br>\nFirst, in this case I will have proof certificate and verifier for the old format, which is already a good guaranty for correctness. Second, there is a hope that fully automatic importer from the old format to a new one will be developed (in contrast, I do not believe that fully automated corrector for fixing broken proof scripts with methods like auto will ever be developed). Third, I see no reasons to change (at least often change)  the primitive Isabelle-independent logic-based format.</p>\n</blockquote>\n</blockquote>\n<p>1.4 Usability<br>\nBut the main concern is – do we actually need such “proof certificates”.</p>\n<blockquote>\n<blockquote>\n<p>It is like packaging every library your program needs with that program (in binary) and freezing the program at that point. It may have its uses, but it is not recommended as a general<br>\nprogram development  method.<br>\nProof certificates will not be used as some “general development method”. I would imagine some “export” button which would allow me to get it for any of my theorems, check (with simple Isabelle-independent verifier), and save on disk. Now:<br>\n1.4.1. I have “proof” of my result which is valid “ones and forever”.<br>\n1.4.2. I can convince other mathematicians, which do not know Isabelle. Imagine that Flyspeck project is finished – what we will have? Extremely long proof, which is impossible to understand and check for human, which uses tactics like “auto”, and some complicated provers like Isabelle claim that it is correct. Is this absolutely convincing? In contrast, imagine the “proof certificate” which is even much longer, but every line is a direct corollary from the previous ones, and there exist a very simple verifier for it. For me, now it is absolutely convincing. <br>\n1.4.3. It can be huge amount of other applications in proof analysis, proof simplification, importing proofs from one provers to another ones, etc.</p>\n</blockquote>\n</blockquote>\n<p>1.5. Is it realistic for realization?<br>\nI hope so. As I understand, many similar work was done for other provers, in Isabelle there are “proof  terms” which is an important step. Finally,  I just have a feeling that such “unpacking” should not be too hard for realization. Am I wrong?</p>\n<p>2.Proof by analogy</p>\n<p>2.1. Affine dimension vs dimension</p>\n<blockquote>\n<blockquote>\n<p>Since this was not just a general hypothetical question, but a very concrete one, and since Bogdan is in contact with the author of the (ported) library, I was suggesting that they might generalize that part of the library.<br>\nThis was a very concrete example, when the suggested new proof method would be extremely useful. In this particular case, if we would want to rewrite the existing library, would be better not to use locale to generalize both theories, but just replace existing “dimension” by affine one, which is just more general and correct definition. But I have already succeed  to derive main results about affine dimension using existing results without too much repetition, so this is not necessary anymore. On the other hand, it was not easy, and any alternative variant (for example, with locale) also would  be not easy. The suggested method would solve the problem in one line.  </p>\n</blockquote>\n</blockquote>\n<p>2.2. Proof by analogy vs locale (is it always relevant?) <br>\nIn general, there are huge amount of proofs “by analogy” in any book. Sometimes this means that we indeed deal with two special cases of some general concept, and in this case using locales is relevant. But sometimes there is no abstract concept in mathematics such that generalizes two cases, and introducing it is somewhat artificial. Also, very often we just consider two similar cases like “a&gt;b” and “a&lt;b” (see “Without loss of generality”, John Harrison). Moreover, sometimes we intentionally consider some special case because its proof  is easier to understand, and then generalize it “by analogy”. The point is that using locales is not always appropriate and corresponds to mathematical intuition.   </p>\n<p>2.3. Proof by analogy vs locale (is it always possible?)<br>\nBut even if it is relevant, the user usually cannot change Isabelle library,  and does not want to do this, he (she) wants just use it to derive some lemma, spending not too much time and efforts. If user spend a month to formalize something big and interesting, this is ok, but if a mathematician spend a month do derive an intuitively easy result, may be he (she) will not want to use Isabelle anymore. In many cases the result is “intuitively easy” namely because it is analogous to one which is already proved. The suggested method  allow us to derive such results in one line. </p>\n<p>2.4. Proof by analogy – what if it is not completely analogous<br>\nIf we have a feeling  that proof is 90% similar, but not exactly the same, but do not know exactly where is the difference, it is hard to use locale. “Analogy” method should tell us what exactly the problem is, we should be able to prove this part “by hand” and then finish the proof by analogy.</p>\n<p>2.5. Proof by analogy – what if it does not work at all.<br>\nImagine that we had an impression that the result is completely analogous, but it is not. Imagine that we tried to use locale, spend a week to rewrite everything, and then at the very last stage discover that it does not work. Having “analogy” method,  we would try to use it, and in one minute would see that it does not work and why.      </p>\n<p>2.6. Again, is it realistic for realization?<br>\nIn my original letter, I describe an algorithm for realization. Also,  the realization may be similar to \"theory morphism\". This gives a hope that it may be realistic.</p>\n<p>Sincerely,<br>\nBogdan Grechuk.</p>",
        "id": 294104748,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834865
    },
    {
        "content": "<p>From: \"<a href=\"mailto:steven@obua.de\">steven@obua.de</a>\" &lt;<a href=\"mailto:steven@obua.de\">steven@obua.de</a>&gt;<br>\nActually I have been thinking about these kinds of problems for a while. IMHO,<br>\nyou can choose between two options here:</p>\n<p>a) Do it how Isabelle (and the AFP) does it currently: When the Isabelle system<br>\nchanges, change all proofs and theorems and so on to become up-to-date.</p>\n<p>b) Develop a versioning system that not only manages source code (like it is<br>\ncurrently done) but also content (theories, theorems, proofs, and so on). Part<br>\nof this versioning system is also a mechanism on how to transfer content from<br>\none version to another (most of the time nothing has to be done here; for<br>\nexample for a minimal implementation of such a versioning system there is most<br>\nof the time no need to transfer proofs, but only theorems). And yes, this means<br>\nthat at least a part of the versioning system becomes part of the trusted kernel<br>\nof the proof assistant.</p>\n<p>I think of those two options only option b) scales to hundreds of thousands of<br>\nconcurrent users. A working versioning system like proposed in b) does not<br>\nexclude a): You can still do refactoring, to use newer proof methods for<br>\nexample. But you don't have to.</p>\n<p>By the way, can anyone here provide pointers to previous work that goes in the<br>\ndirection of b) ?</p>\n<ul>\n<li>Steven</li>\n</ul>",
        "id": 294104757,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834869
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nProof stability is an interesting topic to discuss, but the tenor of the discussion may give a misleading impression. Proof stability is chiefly an issue for the Isabelle developers. We have over 600,000 lines of proof scripts to maintain, about half in Isabelle/HOL and half in the AFP. Many of these proof scripts are over 10 years old and refer to numerous deprecated features. They can be a nightmare to maintain.</p>\n<p>I would be surprised if proof stability was the leading issue with users. I certainly do not recall losing much time in the course of a proof development to patching up failing proofs, even though (unlike most ordinary users surely) I invariably use potentially unstable development snapshots. The simplest way to achieve proof stability, as advocated particularly by some Coq users, is to avoid automation altogether. The problem with that approach is that it takes much longer to prove anything.</p>\n<p>Larry Paulson</p>",
        "id": 294104774,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834873
    },
    {
        "content": "<p>From: Brian Huffman &lt;<a href=\"mailto:brianh@cs.pdx.edu\">brianh@cs.pdx.edu</a>&gt;<br>\nOn Thu, Apr 29, 2010 at 5:46 AM, <a href=\"mailto:steven@obua.de\">steven@obua.de</a> &lt;<a href=\"mailto:steven@obua.de\">steven@obua.de</a>&gt; wrote:</p>\n<blockquote>\n<p>b) Develop a versioning system that not only manages source code (like it is<br>\ncurrently done) but also content (theories, theorems, proofs, and so on). Part<br>\nof this versioning system is also a mechanism on how to transfer content from<br>\none version to another</p>\n</blockquote>\n<p>\"Transferring content\" is exactly what an external representation of<br>\nproof objects would allow you to do. A format like Joe Hurd's<br>\nOpenTheory is designed primarily for transferring theorems between<br>\ncompletely different theorem provers, but the same idea could also be<br>\nuseful for transferring theorems between different versions of the<br>\n<em>same</em> theorem prover.</p>\n<blockquote>\n<p>And yes, this means<br>\nthat at least a part of the versioning system becomes part of the trusted kernel<br>\nof the proof assistant.</p>\n</blockquote>\n<p>The great thing about using proof objects is that you don't need to<br>\ntrust any new code.</p>\n<ul>\n<li>Brian</li>\n</ul>",
        "id": 294104787,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834877
    },
    {
        "content": "<p>From: Brian Huffman &lt;<a href=\"mailto:brianh@cs.pdx.edu\">brianh@cs.pdx.edu</a>&gt;<br>\nI would suggest that using incremental development snapshots actually<br>\nmakes patching up your proofs <em>easier</em>.</p>\n<p>On occasion I have had significant amounts of trouble getting old<br>\nproof scripts to work again. The process is most difficult with<br>\ntheories that were developed for older versions of Isabelle: Porting a<br>\nproof directly from Isabelle 2005 to 2009 can be much more difficult<br>\nthan continuously adapting the same proof to a series of development<br>\nsnapshots. I would suspect that most users have to deal with these<br>\nlarge version-jumps more often than the developers do.</p>\n<ul>\n<li>Brian</li>\n</ul>",
        "id": 294104813,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834886
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nJumping over several Isabelle releases at the same time is indeed very <br>\nhard.  Users can avoid that by following the official release schedule -- <br>\nthe distances between Isabelle2007 -- Isabelle2008 -- Isabelle2009 -- <br>\nIsabelle2009-1 are not too big.</p>\n<p>Isabelle2005 -- Isabelle2007 is in fact a counter example, with 25 months <br>\nbetween the releases and the result being rather unstable.  At that time <br>\nit was not completely clear if we would ever recover from a continously <br>\n\"intermediate\" state, and join the fate of notorious projects such as <br>\nSML/NJ or the STIX fonts.</p>\n<p>Anyway, one should distinguish between really large libraries and the <br>\nunderlying system infrastructure.  A library could well be developed in a <br>\nWikipedia style, and people in Nijmegen are working on that, for example.</p>\n<p>Makarius</p>",
        "id": 294104834,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834892
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nWhile Isabelle is a very complex system, internally everything is reduced <br>\nto basic principles, and run through an LCF-style inference kernel.  The <br>\nkernel can also produce explicit proof objects as a backup, although this <br>\ndegrades performance greatly.  Even without proof terms, the type-safety <br>\nof Standard ML gives certain static guarantees (in contrast to OCaml, or <br>\nother much less rigid languages).</p>\n<p>This does not mean that the system only produces ethernally true results <br>\n-- there are other influences beyond a certain architecture and properties <br>\nof the implementation languages.</p>\n<p>Nonetheless, I would characterize our tradition of theorem proving as <br>\n\"fundamentalist\" in the sense that everything is based on proper <br>\ndefinitions and proofs.</p>\n<p>Makarius</p>",
        "id": 294104853,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834896
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nHere is a minimal example:</p>\n<p>ML \"proofs := 2\"</p>\n<p>lemma a: \"A --&gt; A\" by auto</p>\n<p>prf a<br>\n   full_prf a</p>\n<p>Proof General also privides a menu item for setting \"Full Proofs\" -- it <br>\nswitches between \"proofs := 0\" and \"proofs := 2\".</p>\n<p>If the system complains about \"minimal proof object\" you refer to lemmas within <br>\na proof that do not carry a full proof object themselves.  The download image <br>\nfor Isabelle/HOL from the official Isabelle2009-1 distribution contains full <br>\nproof objects for everything, but the flag is disabled in the very end, in <br>\norder not to degrade user performance by default.</p>\n<p>A nicer proof of \"A --&gt; A\" can be produced like this:</p>\n<p>lemma b: \"A --&gt; A\" ..</p>\n<p>prf b<br>\n   full_prf b</p>\n<p>This also works for less trivial structered proofs, e.g. see the proofs in <br>\nsrc/HOL/Isar_Examples/Knaster_Tarski.thy -- the proof terms still make sense. <br>\nThe Isar proof language does not involve any \"magic\" by itself, but allows to <br>\nappeal to arbitrary complex proof tools in clearly isolated positions, e.g. the <br>\n\"by auto\" above.</p>\n<p>Makarius</p>",
        "id": 294104878,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834902
    },
    {
        "content": "<p>From: Steven Obua &lt;<a href=\"mailto:steven@obua.de\">steven@obua.de</a>&gt;<br>\nI think these issues should be transparent for the end user of the  <br>\nproof assistant. It is maybe a good idea to use proof objects for  <br>\nimplementing the versioning system, but special cases like a change in  <br>\nthe proof object format (and there will be changes, trust me) and so  <br>\non must then be handled transparently by the system, otherwise it  <br>\nbecomes a pain for the user. Also proof objects are big and slow; most  <br>\nusers are willing to trade a vastly improved user experience for a  <br>\nlittle bit of trust ...</p>\n<p>My point is just that earlier snapshots of the theory development  of  <br>\na theorem prover should be accessible from the current theory  <br>\ndevelopment, no matter how that is implemented exactly. As an example,  <br>\ntake the theory of the real numbers.</p>\n<p>A simple way of approaching this is to first introduce the natural  <br>\nnumbers, then rational numbers, then the real numbers. Later on we  <br>\nintroduce new natural numbers, new rational numbers and so on, so that  <br>\nthey are now subsets of each other. Actually, there is no need now any  <br>\nmore for the original natural numbers and so on. With a versioning  <br>\nsystem we can throw them out of our newest version. In our newest  <br>\nversion, we can axiomatically introduce the real numbers (and  <br>\njustifying this by pointing to the definition in an earlier  version).  <br>\nAlso, there are several ways of introducing the real numbers. This is  <br>\nno problem in our system, each way could belong to a different version.</p>\n<p>So for the user, stuff that has been done 10 years ago, is still  <br>\nthere, unchanged, and it is accessible from the  newest version of the  <br>\nsystem.  It is important that the versioning system is elegant and  <br>\neasy to understand. It provides the high-level view of how the user  <br>\nthinks about the system.</p>\n<ul>\n<li>Steven</li>\n</ul>",
        "id": 294104921,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834915
    },
    {
        "content": "<p>From: Dave Thayer &lt;<a href=\"mailto:dathayer@microsoft.com\">dathayer@microsoft.com</a>&gt;<br>\nI think an important aspect of this topic is the issue of legal liability.  <br>\nIf you use a theorem prover to prove a theorem, that is used to create a query into a medical ontology,<br>\n which is then used in the diagnostic train for determining a patients treatment protocol you better <br>\nbe able to stand up in court and defend it.  I would not want to tell a judge: \"at this step we invoke <br>\nthe magic word 'auto' which does 'something unknown' and then we went on from there'.</p>\n<p>David<br>\nJumping over several Isabelle releases at the same time is indeed very <br>\nhard.  Users can avoid that by following the official release schedule -- <br>\nthe distances between Isabelle2007 -- Isabelle2008 -- Isabelle2009 -- <br>\nIsabelle2009-1 are not too big.</p>\n<p>Isabelle2005 -- Isabelle2007 is in fact a counter example, with 25 months <br>\nbetween the releases and the result being rather unstable.  At that time <br>\nit was not completely clear if we would ever recover from a continously <br>\n\"intermediate\" state, and join the fate of notorious projects such as <br>\nSML/NJ or the STIX fonts.</p>\n<p>Anyway, one should distinguish between really large libraries and the <br>\nunderlying system infrastructure.  A library could well be developed in a <br>\nWikipedia style, and people in Nijmegen are working on that, for example.</p>\n<p>Makarius</p>",
        "id": 294105000,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834928
    },
    {
        "content": "<p>From: Dave Thayer &lt;<a href=\"mailto:dathayer@microsoft.com\">dathayer@microsoft.com</a>&gt;<br>\nWhat is the correct invocation to produce such a proof object?</p>\n<p>While Isabelle is a very complex system, internally everything is reduced <br>\nto basic principles, and run through an LCF-style inference kernel.  The <br>\nkernel can also produce explicit proof objects as a backup, although this <br>\ndegrades performance greatly.  Even without proof terms, the type-safety <br>\nof Standard ML gives certain static guarantees (in contrast to OCaml, or <br>\nother much less rigid languages).</p>\n<p>This does not mean that the system only produces ethernally true results <br>\n-- there are other influences beyond a certain architecture and properties <br>\nof the implementation languages.</p>\n<p>Nonetheless, I would characterize our tradition of theorem proving as <br>\n\"fundamentalist\" in the sense that everything is based on proper <br>\ndefinitions and proofs.</p>\n<p>Makarius</p>",
        "id": 294105032,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660834935
    },
    {
        "content": "<p>From: grechukbogdan &lt;<a href=\"mailto:grechukbogdan@yandex.ru\">grechukbogdan@yandex.ru</a>&gt;<br>\nDear Isabelle Users, </p>\n<p>I am working on project, which includes providing feedback about Isabelle, including comments and suggestions. Here is my second feedback letter, mostly about proof by analogy and proof stability in Isabelle. </p>\n<p>First, I discuss my suggestions from the previous letter. </p>\n<p>Suggestion 1. The message like “The current goal could be solved directly with...” should appear not only after I formulate the existing result as a lemma, but also when I formulate it inside the proof, say <br>\nafter have. <br>\nSuggestion 2: It should be a possibility to run Sledgehammer in the background automatically, every time when I formulate a lemma or “have” statement . </p>\n<p>As pointed out by Prof. Makarius, Sledgehammer and lemma suggestion mechanism temporarily works in the crude asynchronous mode, such that user has to wait for it. In this case I agree that Sledgehammer should not work at the background. But I would say that lemma suggestion mechanism works very fast, and I personally would found it very <br>\nhelpful, if it works as described in Suggestion 1. In any case, it should be an option in the menu, so that if somebody does not like this, he could turn it off. And, of course, I will be very happy when this temporarily difficulties will be solved and I will be able to run Sledgehammer at the background (Suggestion 2). </p>\n<p>Suggestion 4: There should be a simple way to see the definition of any object in Isabelle, even if I do not know in advance if it is a lemma, method, term, abbreviation, notation, or something else. </p>\n<p>I was happy ho hear from Prof. Makarius that a universal markup mechanism already works internally, and only the front-ends are still lacking. Hope for more to come here soon. </p>\n<p>Next, I want to discuss proof by analogy and proof stability in Isabelle. </p>\n<p>Recently, I needed to prove the following lemma </p>\n<p>lemma 1: <br>\nfixes S :: \"(real^'n) set\" <br>\nassumes \"aff_dim S = CARD('n)\" <br>\nshows \"affine hull S = (UNIV :: (real^'n) set)\" </p>\n<p>The definition of affine dimension is similar to the definition of dimension in Isabelle (“dim”), the difference is that “aff_dim” uses affine hull in the definition, while “dim” uses subspace hull. And the corresponding lemma is true for “dim” </p>\n<p>lemma 2: <br>\nfixes S :: \"(real^'n) set\" <br>\nassumes \"dim S = CARD('n)\" <br>\nshows \"subspace hull S = (UNIV :: (real^'n) set)\" </p>\n<p>The proof of lemma 2 is very simple to proof, because a lot of machinery for “dim” is developed in Isabelle library. To prove lemma 1, I could just copy all these results (about 50 lemmas, some of them long!) about dim with proofs to my theory, search and replace dim by aff_dim, subspace by affine, span (which is subspace hull) by affine hull, add <br>\n“aff” to every lemma name and again search and replace for lemmas, etc. There is a lot of mechanical work here, and I would get 20 pages of  theory which is basically a repetition of the existing one (which is looks very bed for me). So I just found a tricky way to derive lemma 1 from lemma 2 using some special connection between these dimensions, but it took me a long time to do this. </p>\n<p>After this, I am thinking about some automatic method for proving by analogy, which would look something like <br>\nlemma 1 by analogy[ with lemma 2 replacing dim by aff_dim, subspace by affine, span by affine hull] <br>\nHere “analogy” is new automatic method, “with” and “replacing” are attributes of this method. First, the method should check if lemma 2 <br>\nformally become lemma 1 after such replacing. If no, the error is given. If yes, it just tries to repeat the proof of lemma 2 for lemma 1 <br>\nwith such a replacing. If the proof uses some lemma, it should try to find the corresponding lemma for aff_dim, and if it exists, substitute it, and if it does not, try to prove such a lemma by analogy. The method is either successful, or should give an error like this “can not prove lemma aff_dim S &gt;= 0, which is the analogy for lemma dim S &gt;= 0”. After <br>\nthis, the user can prove such a “hard” part by hand, and then repeat the attempt. If the analogy is complete (like in my case) the proof will be fully automated (as it should be in this case). If there are some lemmas whose analogy are not trivial, the user will need to prove them separately, I e will need to do only nontrivial, interesting work (again, as it should be). </p>\n<p>Such a method would be extremely useful. For example, it would help to perform proofs by symmetry, discussed in the resent Hohn Harrison's paper “without loss of generality” (but it would give us much more – there is no symmetry in my example with dimensions). Also, user could avoid creation of a huge amount of analogous lemmas in copy-paste style. On the other hand, this method looks for me to be relatively straightforward for realization, because there is a clear and simple algorithm for it. </p>\n<p>Next, I will discuss proof stability in Isabelle. </p>\n<p>I was in USA recently, installed the same version of Isabelle there, and tried to compile my theory. In three places the compilation fails, because “auto” did not perform the job for some reason. I fix this by adding a little bit more explanation, but it may be not so simple next time. As a mathematician, I know that if I prove something, this is <br>\nproved forever. For this reason I would prefer to have a proof which is extremely stable, even if non-readable. </p>\n<p>What is proof “by auto”? This is a sequence of some logical steps, which should be (I am sure) easy to unpack. Can I, after proving some lemma, get a fully unpacked version of proof, which is non-readable for human, <br>\nbut will be compiled in any version of Isabelle? Moreover, if the proofs of intermediate lemmas will also be unpacked, this proof would remain correct even if some intermediate lemmas disappear in the new version! If I will spend 5-6 month to prove a major result, I want to have such a proof for it, save it on my computer, and this would be like <br>\na “proof certificate”, extremely stable and valid forever (I know that if I submit the proof to Isabelle archive then somebody will take care, but this do not make me completely happy). Moreover, I need such a low-level proof for some other reasons, connected with proof analysis, and ideas about translation between different theorem provers. So, the question is, can I get somehow such a low-level stable proof of my lemmas? If yes, how? If no, the suggestion is to provide users with such a possibility. </p>\n<p>Finally, I have one question. All the work about convex analysis which I am doing in Isabelle is already formalized in HOL-Light, and this is a very sad situation. It is extremely important to develop automatic translators, and I know that everybody understand this. My question is, what is the state of the art in this area? What are the main reasons for <br>\nsuch translators do not exists by now, even between Isabelle and HOL Light which uses the same logic (HOL)? </p>\n<p>Sincerely, <br>\nBogdan.</p>",
        "id": 294106661,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835417
    },
    {
        "content": "<p>From: Brian Huffman &lt;<a href=\"mailto:brianh@cs.pdx.edu\">brianh@cs.pdx.edu</a>&gt;<br>\nHi Bogdan,</p>\n<p>You make some good points here. I will try to address a few of them.</p>\n<p>On Tue, Apr 27, 2010 at 10:39 AM, grechukbogdan &lt;<a href=\"mailto:grechukbogdan@yandex.ru\">grechukbogdan@yandex.ru</a>&gt; wrote:</p>\n<blockquote>\n<p>Next, I want to discuss proof by analogy and proof stability in Isabelle.</p>\n<p>Recently, I needed to prove the following lemma</p>\n<p>lemma 1:<br>\nfixes S :: \"(real^'n) set\"<br>\nassumes \"aff_dim S = CARD('n)\"<br>\nshows \"affine hull S = (UNIV :: (real^'n) set)\"</p>\n<p>The definition of affine dimension is similar to the definition of dimension in Isabelle (“dim”), the difference is that “aff_dim” uses affine hull in the definition, while “dim” uses subspace hull. And the corresponding lemma is true for “dim”</p>\n<p>lemma 2:<br>\nfixes S :: \"(real^'n) set\"<br>\nassumes \"dim S = CARD('n)\"<br>\nshows \"subspace hull S = (UNIV :: (real^'n) set)\"</p>\n<p>The proof of lemma 2 is very simple to proof, because a lot of machinery for “dim” is developed in Isabelle library. To prove lemma 1, I could just copy all these results (about 50 lemmas, some of them long!) about dim with proofs to my theory, search and replace dim by aff_dim, subspace by affine, span (which is subspace hull) by affine hull, add<br>\n“aff” to every lemma name and again search and replace for lemmas, etc. There is a lot of mechanical work here, and I would get 20 pages of  theory which is basically a repetition of the existing one (which is looks very bed for me). So I just found a tricky way to derive lemma 1 from lemma 2 using some special connection between these dimensions, but it took me a long time to do this.</p>\n</blockquote>\n<p>This process seems very similar to the idea of \"theory morphism\" that<br>\nI learned about from Christoph Lüth a few years ago. There is a 2006<br>\npaper about this called \"Structured Formal Development in Isabelle\":</p>\n<p><a href=\"http://informatik.uni-bremen.de/~cxl/papers/njc06.ps.gz\">informatik.uni-bremen.de/~cxl/papers/njc06.ps.gz</a></p>\n<p>They also implemented a tool that implements theory morphisms for<br>\nIsabelle. To use it, you specify a mapping for types, a mapping for<br>\nterms, and a mapping from axioms in the original theory to theorems in<br>\nthe new theory. It will then reconstruct proofs of derived lemmas by<br>\ntransforming the recorded proof objects.</p>\n<p>It seems that their tool is not <em>exactly</em> what you want, since it<br>\ntranslates everything all the way down to the axioms. In your case,<br>\n\"dim\" is not defined axiomatically, so a mapping from axioms to<br>\ntheorems doesn't help. You would want to give a mapping from<br>\n<em>theorems</em> about \"dim\" to analogous theorems about \"aff_dim\". Then any<br>\nproof about \"dim\" built up from those basic theorems could be<br>\ntranslated to \"aff_dim\".</p>\n<p>There is a potential limitation, though. I suppose your theorem<br>\nmapping would map many abstract properties about \"subspace\" to lemmas<br>\nabout \"affine\". But this would not include the actual <em>definition</em> of<br>\n\"subspace\". Any lemma about \"subspace\" or \"dim\" whose proof used only<br>\nthe abstract properties could be translated automatically, but if its<br>\nproof mentioned the actual definition of \"subspace\", the translation<br>\nwouldn't work.</p>\n<blockquote>\n<p>Next, I will discuss proof stability in Isabelle.</p>\n<p>I was in USA recently, installed the same version of Isabelle there, and tried to compile my theory. In three places the compilation fails, because “auto” did not perform the job for some reason. I fix this by adding a little bit more explanation, but it may be not so simple next time. As a mathematician, I know that if I prove something, this is<br>\nproved forever. For this reason I would prefer to have a proof which is extremely stable, even if non-readable.</p>\n</blockquote>\n<p>Yes, it is troubling that Isabelle does not really provide any kind of<br>\nbackward compatibility for proof scripts. As someone who has spent a<br>\nlot of time fixing broken proof scripts, this is an important concern<br>\nfor me.</p>\n<p>At the very least, it should be safe for you to assume that tactics<br>\nlike auto are \"monotonic\" with respect to versions, i.e. any subgoal<br>\nthat can be solved in one step by \"auto\" in Isabelle2008 should also<br>\nbe solved in one step by \"auto\" in Isabelle2009. Of course, it is also<br>\nlikely (and generally desirable!) that 2009's \"auto\" will solve some<br>\nsubgoals that 2008's \"auto\" could not.</p>\n<p>Robust proof scripts need to keep this \"monotonicity\" property in<br>\nmind. Here's an example of a proof script that is NOT robust:</p>\n<p>apply (rule foo)<br>\napply auto<br>\napply (rule bar)<br>\napply auto<br>\napply (rule ...)<br>\napply auto<br>\n...</p>\n<p>Proof scripts like this are a nightmare to fix when they go wrong. The<br>\nproblem is that there are applications of \"auto\" that don't solve<br>\nsubgoals completely, but leave a bunch of leftover subgoals behind.<br>\nThe rest of the proof script relies on the leftover junk being in a<br>\nvery particular shape. If in a later version of Isabelle, auto leaves<br>\na slightly smaller pile of leftovers, then the proof will break.</p>\n<p>So here is my advice for writing robust proof scripts:</p>\n<ul>\n<li>\n<p>One-step proofs like \"by auto\" should always be OK (You should be<br>\nable to rely on the developers to ensure \"monotonicity\" of future<br>\nversions.)</p>\n</li>\n<li>\n<p>Tactics that leave other subgoals behind are OK if and only if they<br>\nhave predictable behavior (this includes tactics like \"rule\",<br>\n\"clarify\", \"intro\", and \"safe\"; but NOT \"auto\".)</p>\n</li>\n</ul>\n<blockquote>\n<p>What is proof “by auto”? This is a sequence of some logical steps, which should be (I am sure) easy to unpack. Can I, after proving some lemma, get a fully unpacked version of proof, which is non-readable for human,<br>\nbut will be compiled in any version of Isabelle? Moreover, if the proofs of intermediate lemmas will also be unpacked, this proof would remain correct even if some intermediate lemmas disappear in the new version! If I will spend 5-6 month to prove a major result, I want to have such a proof for it, save it on my computer, and this would be like<br>\na “proof certificate”, extremely stable and valid forever (I know that if I submit the proof to Isabelle archive then somebody will take care, but this do not make me completely happy). Moreover, I need such a low-level proof for some other reasons, connected with proof analysis, and ideas about translation between different theorem provers. So, the question is, can I get somehow such a low-level stable proof of my lemmas? If yes, how? If no, the suggestion is to provide users with such a possibility.</p>\n</blockquote>\n<p>Isabelle does have a notion of \"proof terms\" that (when enabled)<br>\nrecord all the low-level details of proofs, including all the steps<br>\ndone by a tactic like \"auto\". Most of the work on this has been done<br>\nby Stefan Berghofer; you can find some publications about it on his<br>\nhomepage:</p>\n<p><a href=\"http://www.in.tum.de/~berghofe/\">http://www.in.tum.de/~berghofe/</a></p>\n<p>When proof terms are enabled in Isabelle, they are available at<br>\nruntime as values on the ML heap. Thus they can be saved in heap<br>\nimages, to be used for later sessions of the same version of Isabelle.<br>\nBut as far as I know, there is no other \"external\" representation of<br>\nIsabelle proof terms, so I'm not sure how easy it would be to transfer<br>\na proof term between different versions of Isabelle.</p>\n<blockquote>\n<p>Finally, I have one question. All the work about convex analysis which I am doing in Isabelle is already formalized in HOL-Light, and this is a very sad situation. It is extremely important to develop automatic translators, and I know that everybody understand this. My question is, what is the state of the art in this area? What are the main reasons for<br>\nsuch translators do not exists by now, even between Isabelle and HOL Light which uses the same logic (HOL)?</p>\n</blockquote>\n<p>One bit of recent work in this area that I know about is the<br>\nOpenTheory project. Joe Hurd published a paper on this work last year;<br>\nyou can find it at the project website:</p>\n<p><a href=\"http://www.gilith.com/research/opentheory/\">http://www.gilith.com/research/opentheory/</a></p>\n<p>The tools are currently targeting HOL4, ProofPower, and HOL Light.<br>\nIsabelle/HOL has not been included yet because its logic is actually<br>\nslightly different from the others: Isabelle supports type classes and<br>\noverloaded constant definitions, but none of the others do. It would<br>\nprobably be straightforward to implement a tool for Isabelle to<br>\n<em>import</em> theorems from OpenTheory files, but <em>exporting</em> would be much<br>\nmore difficult, since type classes would have to be translated away<br>\nsomehow.</p>\n<blockquote>\n<p>Sincerely,<br>\nBogdan.</p>\n</blockquote>\n<p>Hope this helps,</p>\n<ul>\n<li>Brian</li>\n</ul>",
        "id": 294106679,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835424
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nThanks for tackling those questions. You make some good points about stability of proofs, but somehow you've omitted the most important one: structured proofs are inherently much more robust, because if something does fail then you know exactly which part of the proof is affected; you never get leftover subgoals being given to tactics that were intended to perform a separate part of the proof.</p>\n<p>Another small point: if you use sledgehammer to generate metis calls, these will be stable, because they explicitly list all the theorems involved. The only modification to Isabelle that could affect a metis call would be a change to metis itself.</p>\n<p>Larry Paulson</p>",
        "id": 294106696,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835430
    },
    {
        "content": "<p>From: Alexander Krauss &lt;<a href=\"mailto:krauss@in.tum.de\">krauss@in.tum.de</a>&gt;<br>\nLawrence Paulson wrote:<br>\nBut even metis calls can break when the library changes under your feet. :-/</p>\n<p>Alex</p>",
        "id": 294106716,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835437
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nProof by analogy: I wondered if locales would have helped to generalize<br>\nthe dim/aff_dim lemmas, obtaining both by an interpretation?</p>\n<p>Tobias</p>\n<p>Brian Huffman schrieb:</p>",
        "id": 294106743,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835445
    },
    {
        "content": "<p>From: Brian Huffman &lt;<a href=\"mailto:brianh@cs.pdx.edu\">brianh@cs.pdx.edu</a>&gt;<br>\nMaybe they could have, but that kind of misses the point: Writing<br>\nlibraries using locales means that the library writer needs to know in<br>\nadvance exactly how it might be generalized in the future. The problem<br>\nwe are trying to solve is when person A writes a library, and person B<br>\nwants to re-use the proofs in a more general setting - without<br>\nmodifying the original library, or cutting-and-pasting the proofs.</p>\n<p>I might summarize it this way: Locale interpretation transforms a<br>\ngeneric theory into a concrete one. What we're looking for is a way to<br>\ntransform a <em>concrete</em> theory into a <em>different</em> concrete one (or a<br>\nnew generic one, as the case may be).</p>\n<ul>\n<li>Brian</li>\n</ul>",
        "id": 294106749,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835448
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nSince this was not just a general hypothetical question, but a very<br>\nconcrete one, and since Bogdan is in contact with the author of the<br>\n(ported) library, I was suggesting that they might generalize that part<br>\nof the library.</p>\n<p>@Bogdan: Out of intererst: how does John Harrison deal with this<br>\nduplication in the original library?</p>\n<p>Tobias</p>\n<p>Brian Huffman schrieb:</p>",
        "id": 294106763,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835454
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;</p>\n<blockquote>\n<p>Next, I will discuss proof stability in Isabelle. </p>\n<p>I was in USA recently, installed the same version of Isabelle there, and tried to compile my theory. In three places the compilation fails, because “auto” did not perform the job for some reason. I fix this by adding a little bit more explanation, but it may be not so simple next time. As a mathematician, I know that if I prove something, this is <br>\nproved forever. For this reason I would prefer to have a proof which is extremely stable, even if non-readable. </p>\n</blockquote>\n<p>Auto is deterministic and insensitive to the country it is run in. It is<br>\nsensitive to the version of Isabelle and the theories you run your<br>\ntheories on top of.</p>\n<blockquote>\n<p>What is proof “by auto”? This is a sequence of some logical steps, which should be (I am sure) easy to unpack. Can I, after proving some lemma, get a fully unpacked version of proof, which is non-readable for human, <br>\nbut will be compiled in any version of Isabelle? Moreover, if the proofs of intermediate lemmas will also be unpacked, this proof would remain correct even if some intermediate lemmas disappear in the new version! If I will spend 5-6 month to prove a major result, I want to have such a proof for it, save it on my computer, and this would be like <br>\na “proof certificate”, extremely stable and valid forever (I know that if I submit the proof to Isabelle archive then somebody will take care, but this do not make me completely happy). Moreover, I need such a low-level proof for some other reasons, connected with proof analysis, and ideas about translation between different theorem provers. So, the question is, can I get somehow such a low-level stable proof of my lemmas? If yes, how? If no, the suggestion is to provide users with such a possibility. </p>\n</blockquote>\n<p>Such an approach is feasible only in principle. You could write all the<br>\nproof objects out to a file, expanding all proofs of lemmas used.<br>\nIsabelle's proof terms even have a concrete syntax for that. This would<br>\ngive you a stable but gigantic proof. The requirements in terms of time<br>\nand space would make it impossible to process these proofs effectively.<br>\nAnd you would have lost the readable version.</p>\n<p>Tobias</p>",
        "id": 294106793,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835466
    },
    {
        "content": "<p>From: grechukbogdan &lt;<a href=\"mailto:grechukbogdan@yandex.ru\">grechukbogdan@yandex.ru</a>&gt;<br>\nHi Brian,</p>\n<p>Thank you very much for your letter.<br>\nI wanted to formulate suggestions which would make Isabelle much more attractive for mathematicians, and at the same time which would be realistic for realization. Your letter confirms my impression that these suggestions are indeed realistic.</p>\n<blockquote>\n<p>This process seems very similar to the idea of \"theory morphism\" that I learned about from Christoph Lüth a few years ago.... It seems that their tool is not <em>exactly</em> what you want, since it translates everything all the way down to the axioms.</p>\n</blockquote>\n<p>Excellent. This \"theory morphism\" is indeed not what I want, in sense that it is hard (or impossible) to use it to prove my theorem and many similar results. But I have an impression that the realization should be similar, which confirms my hope that my “analogy” method is realistic for realization.</p>\n<blockquote>\n<p>There is a potential limitation, though. I suppose your theorem mapping would map many abstract properties about \"subspace\" to lemmas about \"affine\". But this would not include the actual <em>definition</em> of \"subspace\". Any lemma about \"subspace\" or \"dim\" whose proof used only the abstract properties could be translated automatically, but if its proof mentioned the actual definition of \"subspace\", the translation wouldn't work.</p>\n</blockquote>\n<p>Exactly! If a lemma uses actual definition of subspace, or any other specific properties of subspaces, which have no analogy for affine sets, it will not be translated automatically, because this would mean that the proof is not actually analogous! My point is that we should be able to prove in one line completely analogous facts. Another crucial point is that, if proof is not completely analogous, the analogous part should be done automatically, and only “interesting” part (often very small) should be left for the user.</p>\n<blockquote>\n<p>Yes, it is troubling that Isabelle does not really provide any kind of backward compatibility for proof scripts. As someone who has spent a lot of time fixing broken proof scripts, this is an important concern for me.</p>\n</blockquote>\n<p>Thank you for advice for writing robust proof scripts. But, again, the final goal is to make Isabelle attractive for the whole mathematical community. If thousands of mathematicians start to formalize their results in Isabelle, relatively small Isabelle team will not be able to fix all broken proof scripts. It is necessary to have absolutely stable low-level “proof certificate”, and it should do only very primitive steps, such that the proof can be verified by extremely simple Isabelle-independent checker. Again, I am glad to hear that the first step (Isabelle proof terms) is done already, and now it seems that the \"external\" representation of them should be the next step.</p>\n<blockquote>\n<p>It would probably be straightforward to implement a tool for Isabelle to <em>import</em> theorems from OpenTheory files, but <em>exporting</em> would be much more difficult, since type classes would have to be translated away somehow.</p>\n</blockquote>\n<p>Again, good news, I would be happy to see at least exporting program, which, together with the existing importing from HOL-Light, would help me to translate, say, convex analysis theory from HOL Light, and see how it looks. Meanwhile, I have found folder “import” among Isabelle src files, containing translated theory HOLLight.thy, which is probably based on the work of Steven Obua and Sebastian Skalberg (2006). But, first, I do not know how to get similar automatic translation for convex analysis theory, and second, HOLLight.thy contains no definitions, and some of lemmas are absolutely non-readable. Probably, it would be better to have a parallel tree of definitions (which would make lemmas simpler), and then prove equivalence of these definitions. May be, import from OpenTheory would help with the first step?</p>\n<p>Sincerely,<br>\nBogdan.</p>\n<p>28.04.10, 09:45, \"Brian Huffman\" &lt;<a href=\"mailto:brianh@cs.pdx.edu\">brianh@cs.pdx.edu</a>&gt;:</p>\n<blockquote>\n<p>Hi Bogdan,</p>\n<p>You make some good points here. I will try to address a few of them.</p>\n<p>On Tue, Apr 27, 2010 at 10:39 AM, grechukbogdan  wrote:</p>\n<blockquote>\n<p>Next, I want to discuss proof by analogy and proof stability in Isabelle.</p>\n<p>Recently, I needed to prove the following lemma</p>\n<p>lemma 1:<br>\nfixes S :: \"(real^'n) set\"<br>\nassumes \"aff_dim S = CARD('n)\"<br>\nshows \"affine hull S = (UNIV :: (real^'n) set)\"</p>\n<p>The definition of affine dimension is similar to the definition of dimension in Isabelle (“dim”), the difference is that “aff_dim” uses affine hull in the definition, while “dim” uses subspace hull. And the corresponding lemma is true for “dim”</p>\n<p>lemma 2:<br>\nfixes S :: \"(real^'n) set\"<br>\nassumes \"dim S = CARD('n)\"<br>\nshows \"subspace hull S = (UNIV :: (real^'n) set)\"</p>\n<p>The proof of lemma 2 is very simple to proof, because a lot of machinery for “dim” is developed in Isabelle library. To prove lemma 1, I could just copy all these results (about 50 lemmas, some of them long!) about dim with proofs to my theory, search and replace dim by aff_dim, subspace by affine, span (which is subspace hull) by affine hull, add<br>\n“aff” to every lemma name and again search and replace for lemmas, etc. There is a lot of mechanical work here, and I would get 20 pages of  theory which is basically a repetition of the existing one (which is looks very bed for me). So I just found a tricky way to derive lemma 1 from lemma 2 using some special connection between these dimensions, but it took me a long time to do this.</p>\n</blockquote>\n<p>This process seems very similar to the idea of \"theory morphism\" that<br>\n I learned about from Christoph Lüth a few years ago. There is a 2006<br>\n paper about this called \"Structured Formal Development in Isabelle\":</p>\n<p><a href=\"http://informatik.uni-bremen.de/~cxl/papers/njc06.ps.gz\">informatik.uni-bremen.de/~cxl/papers/njc06.ps.gz</a></p>\n<p>They also implemented a tool that implements theory morphisms for<br>\n Isabelle. To use it, you specify a mapping for types, a mapping for<br>\n terms, and a mapping from axioms in the original theory to theorems in<br>\n the new theory. It will then reconstruct proofs of derived lemmas by<br>\n transforming the recorded proof objects.</p>\n<p>It seems that their tool is not <em>exactly</em> what you want, since it<br>\n translates everything all the way down to the axioms. In your case,<br>\n \"dim\" is not defined axiomatically, so a mapping from axioms to<br>\n theorems doesn't help. You would want to give a mapping from<br>\n<em>theorems</em> about \"dim\" to analogous theorems about \"aff_dim\". Then any<br>\n proof about \"dim\" built up from those basic theorems could be<br>\n translated to \"aff_dim\".</p>\n<p>There is a potential limitation, though. I suppose your theorem<br>\n mapping would map many abstract properties about \"subspace\" to lemmas<br>\n about \"affine\". But this would not include the actual <em>definition</em> of<br>\n \"subspace\". Any lemma about \"subspace\" or \"dim\" whose proof used only<br>\n the abstract properties could be translated automatically, but if its<br>\n proof mentioned the actual definition of \"subspace\", the translation<br>\n wouldn't work.</p>\n<blockquote>\n<p>Next, I will discuss proof stability in Isabelle.</p>\n<p>I was in USA recently, installed the same version of Isabelle there, and tried to compile my theory. In three places the compilation fails, because “auto” did not perform the job for some reason. I fix this by adding a little bit more explanation, but it may be not so simple next time. As a mathematician, I know that if I prove something, this is<br>\nproved forever. For this reason I would prefer to have a proof which is extremely stable, even if non-readable.</p>\n</blockquote>\n<p>Yes, it is troubling that Isabelle does not really provide any kind of<br>\n backward compatibility for proof scripts. As someone who has spent a<br>\n lot of time fixing broken proof scripts, this is an important concern<br>\n for me.</p>\n<p>At the very least, it should be safe for you to assume that tactics<br>\n like auto are \"monotonic\" with respect to versions, i.e. any subgoal<br>\n that can be solved in one step by \"auto\" in Isabelle2008 should also<br>\n be solved in one step by \"auto\" in Isabelle2009. Of course, it is also<br>\n likely (and generally desirable!) that 2009's \"auto\" will solve some<br>\n subgoals that 2008's \"auto\" could not.</p>\n<p>Robust proof scripts need to keep this \"monotonicity\" property in<br>\n mind. Here's an example of a proof script that is NOT robust:</p>\n<p>apply (rule foo)<br>\n apply auto<br>\n apply (rule bar)<br>\n apply auto<br>\n apply (rule ...)<br>\n apply auto<br>\n ...</p>\n<p>Proof scripts like this are a nightmare to fix when they go wrong. The<br>\n problem is that there are applications of \"auto\" that don't solve<br>\n subgoals completely, but leave a bunch of leftover subgoals behind.<br>\n The rest of the proof script relies on the leftover junk being in a<br>\n very particular shape. If in a later version of Isabelle, auto leaves<br>\n a slightly smaller pile of leftovers, then the proof will break.</p>\n<p>So here is my advice for writing robust proof scripts:</p>\n<ul>\n<li>\n<p>One-step proofs like \"by auto\" should always be OK (You should be<br>\n able to rely on the developers to ensure \"monotonicity\" of future<br>\n versions.)</p>\n</li>\n<li>\n<p>Tactics that leave other subgoals behind are OK if and only if they<br>\n have predictable behavior (this includes tactics like \"rule\",<br>\n \"clarify\", \"intro\", and \"safe\"; but NOT \"auto\".)</p>\n</li>\n</ul>\n<blockquote>\n<p>What is proof “by auto”? This is a sequence of some logical steps, which should be (I am sure) easy to unpack. Can I, after proving some lemma, get a fully unpacked version of proof, which is non-readable for human,<br>\nbut will be compiled in any version of Isabelle? Moreover, if the proofs of intermediate lemmas will also be unpacked, this proof would remain correct even if some intermediate lemmas disappear in the new version! If I will spend 5-6 month to prove a major result, I want to have such a proof for it, save it on my computer, and this would be like<br>\na “proof certificate”, extremely stable and valid forever (I know that if I submit the proof to Isabelle archive then somebody will take ca<br>\n[message truncated]</p>\n</blockquote>\n</blockquote>",
        "id": 294106844,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835480
    },
    {
        "content": "<p>From: Steven Obua &lt;<a href=\"mailto:steven@obua.de\">steven@obua.de</a>&gt;<br>\nIt seems to me the way mathematics usually works is to take the  <br>\nconcrete, abstract it, and THEN ONLY apply it to something different  <br>\nconcrete.</p>\n<ul>\n<li>Steven</li>\n</ul>",
        "id": 294106854,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835487
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nThis is the killer, I believe:</p>\n<p>\"Moreover, if the proofs of intermediate lemmas will also be unpacked,<br>\nthis proof would remain correct even if some intermediate lemmas<br>\ndisappear in the new version!\"</p>\n<p>Otherwise replaying proofs is uncritical.</p>\n<p>Tobias</p>\n<p>Paul Jackson wrote:</p>",
        "id": 294106867,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835491
    },
    {
        "content": "<p>From: Peter Lammich &lt;<a href=\"mailto:peter.lammich@uni-muenster.de\">peter.lammich@uni-muenster.de</a>&gt;<br>\nTobias Nipkow schrieb:<br>\nA possibility would also be to include the concept of lemma that can be <br>\nreferenced into the<br>\nunpacked proof certificate, and include the proofs of required lemmas <br>\nonly once. This<br>\nwould make this certificate format slightly more complex, but avoid <br>\nexplosion of the certificate<br>\nby preserving the modularity of the original proof.</p>",
        "id": 294106882,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835497
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:webertj@in.tum.de\">webertj@in.tum.de</a>&gt;<br>\nI briefly discuss an implementation of this idea in Section 5.5 of my<br>\ndissertation<br>\n(<a href=\"http://www.cl.cam.ac.uk/~tw333/publications/weber08satbased.html\">http://www.cl.cam.ac.uk/~tw333/publications/weber08satbased.html</a>). My<br>\nmotivation at the time was to achieve stability across different<br>\nIsabelle installations in the presence of external provers (which might<br>\nbe available on one machine, but not on another).</p>\n<p>In theory, proof objects could become gigantic, but for Isabelle/HOL the<br>\napproach seemed to work reasonably well.  I don't think there is<br>\nsufficient experimental data to dismiss it as infeasible in practice.</p>\n<p>Of course, proofs of lemmas must not be expanded inline, but referenced<br>\n(as suggested by Peter).  This is already supported by Stefan's proof<br>\nobjects.</p>\n<p>Tjark</p>",
        "id": 294106889,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835503
    },
    {
        "content": "<p>From: Tobias Nipkow &lt;<a href=\"mailto:nipkow@in.tum.de\">nipkow@in.tum.de</a>&gt;<br>\nWe have to distinguish two applications of proof objects: to speed up<br>\nthe loading of theories, where they are fine, and as a means of<br>\nproducing stable proofs, where I maintain they are problematic (and I am<br>\nnot aware of any system that supports it). If you want to protect your<br>\nproof against a changing basis, you have to include the whole basis into<br>\nyour proof object. It is not infeasible, but it means you are locked<br>\ninto this one version of your proofs. And if one day the format for<br>\nprimitive proofs changes... It is like packaging every library your<br>\nprogram needs with that program (in binary) and freezing the program at<br>\nthat point. It may have its uses, but it is not recommended as a general<br>\nprogram development method.</p>\n<p>Tobias</p>\n<p>Tjark Weber wrote:</p>",
        "id": 294106900,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835510
    },
    {
        "content": "<p>From: John Matthews &lt;<a href=\"mailto:matthews@galois.com\">matthews@galois.com</a>&gt;<br>\nJoe Hurd's OpenTheory project may be relevant here:</p>\n<p><a href=\"http://www.gilith.com/research/opentheory\">http://www.gilith.com/research/opentheory</a></p>\n<p>It is designed to provide a standard for sharing theory developments  <br>\nacross higher order logic theorem provers. It doesn't support  <br>\nIsabelle's type classes, however Alexander Krauss' and Andreas  <br>\nSchropp's work on translating away typeclasses (Sections 5.1 and 5.2  <br>\nof the online paper below) might be used to overcome this:</p>\n<p><a href=\"http://www4.in.tum.de/~krauss/holzf\">http://www4.in.tum.de/~krauss/holzf</a></p>\n<p>-john<br>\n<a href=\"/user_uploads/14278/7734Apz0hkpl_Tb_uOFNxgsL/smime.p7s\">smime.p7s</a></p>",
        "id": 294106931,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835519
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:tjark.weber@gmx.de\">tjark.weber@gmx.de</a>&gt;<br>\nOn Thu, 2010-04-29 at 14:17 +0200, Tobias Nipkow wrote:</p>\n<blockquote>\n<p>We have to distinguish two applications of proof objects: to speed up<br>\nthe loading of theories, where they are fine,</p>\n</blockquote>\n<p>If I recall correctly, Makarius and Stefan conducted a few experiments<br>\nsome years ago and concluded that checking proof objects was typically<br>\nnot faster than re-playing proof scripts in Isabelle.</p>\n<blockquote>\n<p>and as a means of<br>\nproducing stable proofs, where I maintain they are problematic (and I am<br>\nnot aware of any system that supports it). If you want to protect your<br>\nproof against a changing basis, you have to include the whole basis into<br>\nyour proof object. It is not infeasible, but it means you are locked<br>\ninto this one version of your proofs. And if one day the format for<br>\nprimitive proofs changes...</p>\n</blockquote>\n<p>Well, being locked into a particular version of Isabelle's proof checker<br>\nstill seems much better than being locked into a particular version of<br>\nIsabelle (and worse, being locked into a particular system configuration<br>\nwhen external provers are used).</p>\n<p>Of course proof objects are not the answer to life, the universe and<br>\neverything.  Size is one issue; the lack of readability is another.  But<br>\nin terms of stability across Isabelle versions and platforms, proof<br>\nobjects beat proof scripts (and even well-written Isar proofs) by a wide<br>\nmargin.  The interface is just a lot simpler.</p>\n<blockquote>\n<p>It is like packaging every library your<br>\nprogram needs with that program (in binary) and freezing the program at<br>\nthat point. It may have its uses, but it is not recommended as a general<br>\nprogram development method.</p>\n</blockquote>\n<p>Proof objects can refer to lemmas, so one isn't forced to freeze the<br>\nlibrary.  Of course changes to the library may cause proof checking to<br>\nfail then, but at least changes to tactics still won't.</p>\n<p>Shipping libraries in binary form is actually quite common, isn't it?<br>\nMaybe we need an equivalent for Isabelle theories.</p>\n<p>Tjark</p>",
        "id": 294106938,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835521
    },
    {
        "content": "<p>From: Lucas Dixon &lt;<a href=\"mailto:ldixon@inf.ed.ac.uk\">ldixon@inf.ed.ac.uk</a>&gt;<br>\nI just noticed that STIX have released version 1 of their fonts (May <br>\n24th 2010); does anyone have experience with using them for Isabelle?</p>\n<p>I would be particularly interested to know if it was possible to get a <br>\nfixed-width version of the font. I don't anything about font-design, is <br>\nthis a very hard thing to do?</p>\n<p>best,<br>\nlucas</p>",
        "id": 294107041,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835552
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Sat, 29 May 2010, Lucas Dixon wrote:</p>\n<blockquote>\n<p>On 30/04/2010 16:09, Makarius wrote:</p>\n<blockquote>\n<p>Isabelle2005 -- Isabelle2007 is in fact a counter example, with 25<br>\nmonths between the releases and the result being rather unstable. At<br>\nthat time it was not completely clear if we would ever recover from a<br>\ncontinously \"intermediate\" state, and join the fate of notorious<br>\nprojects such as SML/NJ or the STIX fonts.</p>\n</blockquote>\n<p>I just noticed that STIX have released version 1 of their fonts (May 24th <br>\n2010); does anyone have experience with using them for Isabelle?</p>\n</blockquote>\n<p>I've tried it just a few hours after it came out.  My impression is that <br>\nthe quality as a screen font is not ideal, but this might be due to my <br>\nhomegrown conversion from OpenType to TrueType via fontforge.  The latter <br>\ndoes not treat all details of the hinting according to its author.  Does <br>\nanybody have a high quality font converter?</p>\n<blockquote>\n<p>I would be particularly interested to know if it was possible to get a <br>\nfixed-width version of the font. I don't anything about font-design, is <br>\nthis a very hard thing to do?</p>\n</blockquote>\n<p>The STIX people spent the first half of all these years counting only <br>\nglyph coverage.  Then they noticed that the spacing between glyhps is just <br>\nas hard, and spent five more years on it.</p>\n<p>Anyway, the last time when Isabelle symbol fonts were discussed on the <br>\nlist I promised not to get involved in it again.  But after projecting the <br>\nexpected quality of STIX on the JVM -- which is particularly bad -- I've <br>\nhad another go at it some months ago.  The resulting IsabelleText font is <br>\nactually quite nice as a pseudo-fixed width screen font and will be <br>\nshipped with the next Isabelle release, i.e. within the next few weeks.</p>\n<p>Makarius</p>",
        "id": 294107072,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660835562
    }
]