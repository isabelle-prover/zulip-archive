[
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:gerwin.klein@nicta.com.au\">gerwin.klein@nicta.com.au</a>&gt;<br>\nThat is probably the best solution. It only works for polyml, but JinjaThreads won't work in smlnj anyway.</p>\n<p>When I made multiple images for Jinja (to speed up development, not so much because of memory problems), we had exactly the problem that there was no one document any more and we introduced a separate session just to build the document. That would defeat the point here, of course.</p>\n<p>Cheers,<br>\nGerwin</p>",
        "id": 294147058,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660847893
    },
    {
        "content": "<p>From: Andreas Lochbihler &lt;<a href=\"mailto:andreas.lochbihler@kit.edu\">andreas.lochbihler@kit.edu</a>&gt;<br>\nFlorian suggested to split JinjaThreads in the AFP into multiple sessions. He <br>\nhopes that this will reduce the overall memory consumption because Isabelle <br>\nforces PolyML to share objects on the heap only when the image is written. I am <br>\ncurrently testing whether this is a promising way. However, I am wondering how <br>\nmultiple sessions would fit in with the proof document and proof outline in the <br>\nAFP. Ideally, there would be one document each that covers all JinjaThreads <br>\ntheories although they are processed in different sessions. Is there any support <br>\nfor this?</p>\n<p>I guess that I could dump the generated files of all sessions in some directory <br>\nand appropriately string them together in root.tex, but that only gives me the <br>\nproof document. How can I get to the sources for proof outline?</p>\n<p>Cheers,<br>\nAndreas</p>",
        "id": 294148146,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660848279
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nI can't say anyting specific about the intention of the AFP setup, <br>\nalthough I remember a time when there was a 500MB heap limit (in Poly/ML <br>\n4.x) and Gerwin split up the original Jinja session to get the compaction <br>\neffect when heaps are dumped and reloaded.</p>\n<p>In Poly/ML 5.x the compaction phase has become available separately, <br>\nwithout dumping.  So in principle you could just split the invocations of <br>\nuse_thys in ROOT.ML and make an intermediate share_common_data() in raw ML <br>\nin between.</p>\n<p>I have already experimented with this occasionally.  It basically works <br>\n(reducing heap size at runtime from several GB to a few 100 MB).  It also <br>\nhas some limitations: doing it too aggressively can make the process dump <br>\ncore.</p>\n<p>Makarius</p>",
        "id": 294148322,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660848347
    }
]