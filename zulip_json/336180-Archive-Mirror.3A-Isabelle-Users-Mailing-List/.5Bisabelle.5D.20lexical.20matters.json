[
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 19/1/11 3:25 AM, Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<p>On 19/01/11 14:04, <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> wrote:</p>\n<blockquote>\n<p>I never thought that advocating a trustworthy pretty printer would be so<br>\ncontroversial!!!</p>\n</blockquote>\n<p>It's just not an interesting problem.  We can solve it trivially by<br>\nwriting<br>\neverything out in sexp-like notation.  ACL2 is demonstrably an acceptable<br>\nformat for security-critical validation, and this is all the<br>\npretty-printing<br>\nthey have.</p>\n</blockquote>\n<p>Not sure what you mean here.  You seem to be saying that low-tech printers<br>\nare the way forward, which again seems to be suggesting that good concrete<br>\nsyntax printers do not help human readability.</p>\n<blockquote>\n<p>Moreover, with proof terms (in Isabelle) and things like OpenTheory for<br>\nthe<br>\n3 HOLs, we can avoid having to look at clients' ML code.</p>\n</blockquote>\n<p>I am also advocating proof porting.  With proof porting, however, we have<br>\nthe same problem - in the target system, we still need to know that the<br>\nported theorem is the right one and that the ported definitions are right.</p>\n<p>All of the \"3 HOLs\" (presumably you are not including HOL Zero in the 3 HOLs<br>\n:) have problems with printing irregular names, and all of them have<br>\nproblems coping with overloaded variables.</p>\n<p>Mark.</p>",
        "id": 294125542,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841182
    },
    {
        "content": "<p>From: Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt;<br>\nOn 19/01/11 14:36, <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> wrote:</p>\n<blockquote>\n<p>on 19/1/11 3:25 AM, Michael Norrish&lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt;  wrote:</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>It's just not an interesting problem.  We can solve it trivially by writing<br>\neverything out in sexp-like notation.  ACL2 is demonstrably an acceptable<br>\nformat for security-critical validation, and this is all the pretty-printing<br>\nthey have.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>Not sure what you mean here.  You seem to be saying that low-tech<br>\nprinters are the way forward, which again seems to be suggesting<br>\nthat good concrete syntax printers do not help human readability.</p>\n</blockquote>\n<p>Of course they do.  We also know that in our day-to-day use of our systems, the pretty-printer is not a cause of problems, so we can use the nice readability-enhancing features of these systems.  On the other hand, if there is a worry about malicious attacks (as in the validated work scenario) then people concerned about these things can print the terms in question using sexp-syntax, which we know to be adequate.</p>\n<blockquote>\n<blockquote>\n<p>Moreover, with proof terms (in Isabelle) and things like OpenTheory for the<br>\n3 HOLs, we can avoid having to look at clients' ML code.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>I am also advocating proof porting.  With proof porting, however, we have<br>\nthe same problem - in the target system, we still need to know that the<br>\nported theorem is the right one and that the ported definitions are right.</p>\n</blockquote>\n<p>Right, which is why we have the pretty-printing solution of my paragraph above.</p>\n<blockquote>\n<p>All of the \"3 HOLs\" (presumably you are not including HOL Zero in the 3 HOLs<br>\n:) have problems with printing irregular names, and all of them have<br>\nproblems coping with overloaded variables.</p>\n</blockquote>\n<p>I guess you mean overloaded constants.  My thought-experiment sexp-syntax would raise an exception if it encountered variable or constant names that were lexically bad.  Overloads would not be printed at all.  Instead, you'd get things like</p>\n<p>(= (integer$+ (integer$int_of_num x) (integer$int_of_num y))<br>\n      (integer$int_of_num (arithmetic$+ x y)))</p>\n<p>Michael</p>",
        "id": 294125561,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841189
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:gerwin.klein@nicta.com.au\">gerwin.klein@nicta.com.au</a>&gt;<br>\nOn 19/01/2011, at 1:50 PM, &lt;<a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a>&gt; &lt;<a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a>&gt; wrote:</p>\n<blockquote>\n<p>on 18/1/11 10:22 PM, Gerwin Klein &lt;<a href=\"mailto:gerwin.klein@nicta.com.au\">gerwin.klein@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<blockquote>\n<p>We should remember that at the moment it is very easy for someone to<br>\nmaliciously produce what appears to be a formal proof of some statement<br>\n...</p>\n</blockquote>\n<p>I don't think this is a problem in practice. Theorem provers are already<br>\nused in big certification projects. The evaluators in such projects<br>\nusually<br>\nknow what they are doing,</p>\n</blockquote>\n<p>How can you be so confident about this?</p>\n</blockquote>\n<p>Talking to some of them. I'm sure this is not the case for all evaluators, but there are people in that business that have used Isabelle for longer than most of the current developers.</p>\n<blockquote>\n<p>In the large, safety-critical<br>\ncertification projects I have been involved with, the evaluators do the best<br>\nthey can with the tools they have available.  Proof checkers with readable<br>\nand highly trustworthy output is a luxury not available to them.</p>\n</blockquote>\n<p>Depends on the project, of course, and what level of certification. Currently not that many certifications with interactive formal proof exist, but some do (ACL2 has been used quite a bit). As you say, evaluators need to take the best that is available. LCF provers are a long way ahead of what they usually have to deal with. That's why I don't think it's a problem in practice.</p>\n<blockquote>\n<blockquote>\n<p>at least up to the level where they would easily<br>\nbe able to spot attempts to make syntactically misleading proof<br>\nstatements.<br>\nIt's easy enough to scan for ML blocks or similar in theory files, spot<br>\nduplicate identifiers, etc, and demand good explanations for their<br>\npresence<br>\n(or just forbid them). And the threat of just using a proof checker is<br>\nalways there, so why try to cheat on syntax?</p>\n</blockquote>\n<p>The input in this process is the full power of an ML program.  We all know<br>\nthat it is possible to hide incredibly subtle things in huge programs.  Are<br>\nwe to ban non-trivial ML in the process of producing a proof?</p>\n</blockquote>\n<p>If you're really concerned about malicious users, why not? Usual Isabelle interaction makes no use of ML. Very few of the AFP entries, many of them substantial, do anything remotely like that. </p>\n<blockquote>\n<p>This would be<br>\nforcing contractors to do their work with one hand tied behind their back.<br>\nThe contracted, safety-critical proof work I have been involved with would<br>\ncertainly have been completely infeasible without writing large amounts of<br>\nML program to support my proof work.</p>\n</blockquote>\n<p>In Isabelle? HOL4 or HOL-light, sure, that's their main interaction mode, but Isabelle hasn't had the ML-as-user-interface paradigm for quite a few years.</p>\n<p>I'm not saying that you'll never want to use any ML for bigger advanced projects, but these ML bits are a far way off from complex ML programs. Compared to the effort that should go into validating models and statements, checking small amounts of proof method ML code for pretty printing cheat attempts would be trivial (there's no reason to have any pretty printing code there at all). There's no reason evaluators should have to accept huge amounts of complex ML code.</p>\n<blockquote>\n<p>It is far better for the auditor if they can treat the ML code that<br>\nestablishes the final theorem as some sort of black box.  To do this the<br>\ntheorem prover needs certain basic properties, including a trustworthy<br>\nprinter.</p>\n</blockquote>\n<p>Well, there is one, you just don't seem to like it: inspecting the term on the ML level. As Michael says, it's as least as good as Lisp s-expressions. </p>\n<p>There's a difference between accidentally creating something misleading (reasonably hard to do if you use the normal interface) and a malicious user with motivation and criminal energy. If you want to guard against the latter, low-tech plain terms and external proof checking surely brings more assurance than further infrastructure.</p>\n<blockquote>\n<blockquote>\n<p>I'm with Larry on this: the much bigger problem is to convince yourself<br>\nthat<br>\nthe model and final theorem are in any way useful or right. This is where<br>\ncheating will happen much earlier.</p>\n</blockquote>\n<p>I did not say that this was not a problem!  This is the big problem!  </p>\n</blockquote>\n<p>I guess we're all mostly of the same opinion fundamentally anyway, just different views on where to put resources and emphasis.</p>\n<blockquote>\n<p>And<br>\nthis is the problem that I am advocating needs a tool that properly supports<br>\nthe process - the process of determining that the model and final theorem<br>\nare right (as well as that the final theorem has actually been proved).<br>\nThis process involves using the pretty printer.</p>\n</blockquote>\n<p>Checking that the proof shows what you think it does involves the pretty printer only at a very shallow level. It's not the case that we can't trust the Isabelle pretty printer to support development and that it will magically show us wrong terms. </p>\n<p>I've often seen and written theorems that didn't mean what I thought they meant. It's so far never been the fault of the pretty printer. It can be, because you'd  be able to trick it with some effort, but getting rid of that possibility is about assurance, not about finding the right proof statement. It can have different solutions.</p>\n<p>Cheers,<br>\nGerwin</p>",
        "id": 294125572,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841195
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 19/1/11 3:51 AM, Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<p>...</p>\n<blockquote>\n<p>Not sure what you mean here.  You seem to be saying that low-tech<br>\nprinters are the way forward, which again seems to be suggesting<br>\nthat good concrete syntax printers do not help human readability.</p>\n</blockquote>\n<p>Of course they do.  We also know that in our day-to-day use of our<br>\nsystems,<br>\nthe pretty-printer is not a cause of problems, so we can use the nice<br>\nreadability-enhancing features of these systems.  On the other hand, if<br>\nthere is a worry about malicious attacks (as in the validated work<br>\nscenario)<br>\nthen people concerned about these things can print the terms in question<br>\nusing sexp-syntax, which we know to be adequate.</p>\n</blockquote>\n<p>So if you recognise that good concrete-syntax pretty printers are generally<br>\ngood for human readability, then this is also true for the proof auditor.<br>\nIf we could have a trusted system that supports proof auditing AND has a<br>\ngood trustworthy concrete-syntax printer, then isn't that the best of both<br>\nworlds?</p>\n<blockquote>\n<blockquote>\n<p>All of the \"3 HOLs\" (presumably you are not including HOL Zero in the 3<br>\nHOLs :) have problems with printing irregular names, and all of them<br>\nhave problems coping with overloaded variables.</p>\n</blockquote>\n<p>I guess you mean overloaded constants....</p>\n</blockquote>\n<p>No, I mean variables that are overloaded with other variables.  The sort of<br>\nthing that basic Hindley-Milner type inference cannot deal with (but this is<br>\nfor parsing so let's not get distracted by this).  Apart from HOL Zero, no<br>\nother system is capable of printing (or parsing, as it happens) an<br>\nexpression with overloaded variables.</p>\n<p>I suppose your low-tech s-exp printer would throw these out too.  It's<br>\nstarting to be less trivial than originally envisaged.  Isn't it just best<br>\nto have a good trustworthy concrete-syntax printer?</p>\n<p>Mark.</p>",
        "id": 294125590,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841200
    },
    {
        "content": "<p>From: Konrad Slind &lt;<a href=\"mailto:konrad.slind@gmail.com\">konrad.slind@gmail.com</a>&gt;<br>\nIf a trusted prettyprinter is deemed to be important tool for the auditor,<br>\nthen<br>\nthe auditor can code one up, or look over your shoulder while you code it.<br>\nIt's a fairly simple task. Of course, for the paranoid, this just means<br>\nthat<br>\nsomething else will emerge to be anxious about.</p>\n<p>Konrad.</p>",
        "id": 294125606,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841206
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 19/1/11 4:02 AM, Gerwin Klein &lt;<a href=\"mailto:gerwin.klein@nicta.com.au\">gerwin.klein@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<blockquote>\n<p>In the large, safety-critical certification projects I have been involved<br>\nwith,<br>\nthe evaluators do the best<br>\nthey can with the tools they have available.  Proof checkers with<br>\nreadable<br>\nand highly trustworthy output is a luxury not available to them.</p>\n</blockquote>\n<p>Depends on the project, of course, and what level of certification.<br>\nCurrently not that many certifications with interactive formal proof<br>\nexist,<br>\nbut some do (ACL2 has been used quite a bit). As you say, evaluators need<br>\nto<br>\ntake the best that is available. LCF provers are a long way ahead of what<br>\nthey usually have to deal with. That's why I don't think it's a problem in<br>\npractice.</p>\n</blockquote>\n<p>So it's ok because LCF systems don't tend to get used!  I'm trying to enable<br>\nLCF system to get used in practice.  This can potentially greatly increase<br>\nthe assurance in the project.</p>\n<blockquote>\n<blockquote>\n<p>Are we to ban non-trivial ML in the process of producing a proof?</p>\n</blockquote>\n</blockquote>\n<p>This reduces what can be done in the project.</p>\n<blockquote>\n<p>If you're really concerned about malicious users, why not? Usual Isabelle<br>\ninteraction makes no use of ML. Very few of the AFP entries, many of them<br>\nsubstantial, do anything remotely like that.</p>\n</blockquote>\n<p>Yes, but I've been involved in large safety-critical projects where use of<br>\nML has been a practical necessity.  Formal methods is generally currently<br>\nextremely expensive if it involves formal proof (but not in the projects<br>\nwhere I have been involved with).</p>\n<blockquote>\n<blockquote>\n<p>The contracted, safety-critical proof work I have been involved with<br>\nwould<br>\ncertainly have been completely infeasible without writing large amounts<br>\nof<br>\nML program to support my proof work.</p>\n</blockquote>\n<p>In Isabelle? HOL4 or HOL-light, sure, that's their main interaction mode,<br>\nbut Isabelle hasn't had the ML-as-user-interface paradigm for quite a few<br>\nyears.</p>\n</blockquote>\n<p>Yes, so Isabelle would be safer in this respect because the proof scripts<br>\naren't even in ML.  But to enable cost-effective large formal verification<br>\nprojects involving formal proof, I think allowing the contractor to use the<br>\npower of ML to overcome practical problems, specific to the particular<br>\nproject, would be an extremely useful thing.  I'm talking about bespoke<br>\nautomation and bespoke semi-automation.  Now it's always possible to do a<br>\nbit of bespoke pre-processing and still use a restricted, non-ML paradigm,<br>\nbut this will often have its own integrity risks and is in any case is<br>\nfundamentally limited.  We need to give contractors the full power of ML to<br>\nget the costs of full formal verification down.  But we shouldn't trust them<br>\nnot to be malicious!</p>\n<blockquote>\n<p>I'm not saying that you'll never want to use any ML for bigger advanced<br>\nprojects, but these ML bits are a far way off from complex ML programs.<br>\nCompared to the effort that should go into validating models and<br>\nstatements,<br>\nchecking small amounts of proof method ML code for pretty printing cheat<br>\nattempts would be trivial (there's no reason to have any pretty printing<br>\ncode there at all). There's no reason evaluators should have to accept<br>\nhuge<br>\namounts of complex ML code.</p>\n</blockquote>\n<p>I've been involved with large safety-critical projects that use 20,000 lines<br>\nof bespoke ML.</p>\n<blockquote>\n<blockquote>\n<p>It is far better for the auditor if they can treat the ML code that<br>\nestablishes the final theorem as some sort of black box.  To do this the<br>\ntheorem prover needs certain basic properties, including a trustworthy<br>\nprinter.</p>\n</blockquote>\n<p>Well, there is one, you just don't seem to like it: inspecting the term on<br>\nthe ML level. As Michael says, it's as least as good as Lisp<br>\ns-expressions.</p>\n</blockquote>\n<p>Good concrete-syntax printers make it much easier to read.  When hundreds of<br>\nlines of specification need to be reviewed, concrete syntax is a practical<br>\nnecessity.</p>\n<blockquote>\n<p>There's a difference between accidentally creating something misleading<br>\n(reasonably hard to do if you use the normal interface) and a malicious<br>\nuser<br>\nwith motivation and criminal energy. If you want to guard against the<br>\nlatter, low-tech plain terms and external proof checking surely brings<br>\nmore<br>\nassurance than further infrastructure.</p>\n</blockquote>\n<p>I find that analysts just make mistakes, especially when things are being<br>\ndone on the industrial scale,  and especially when there is a team of<br>\nanalysts.  Now occasionally these mistakes will surface in really bizarre<br>\nways, and things that one would think \"this would never happen in practice\"<br>\nactually do happen.  I regret not keeping a careful log of strange problems.<br>\n But problems with the pretty printer have certainly caused all sorts of<br>\nproblems, and, I think, some connected with the soundness of the analysis<br>\nbeing undertaken.  These problems have often been quite subtle.</p>\n<blockquote>\n<p>I guess we're all mostly of the same opinion fundamentally anyway, just<br>\ndifferent views on where to put resources and emphasis.</p>\n</blockquote>\n<p>Absolutely.</p>\n<blockquote>\n<blockquote>\n<p>And this is the problem that I am advocating needs a tool that properly<br>\nsupports<br>\nthe process - the process of determining that the model and final theorem<br>\nare right (as well as that the final theorem has actually been proved).<br>\nThis process involves using the pretty printer.</p>\n</blockquote>\n<p>Checking that the proof shows what you think it does involves the pretty<br>\nprinter only at a very shallow level. It's not the case that we can't<br>\ntrust<br>\nthe Isabelle pretty printer to support development and that it will<br>\nmagically show us wrong terms.</p>\n</blockquote>\n<p>The complex Isabelle derived code, outside the relatively small core of code<br>\nimplementing crucial trusted components such as the inference kernel and the<br>\npretty printer, may be susceptible to constructing expressions that end up<br>\nexploiting problems with Isabelle's pretty printer.  I have found that such<br>\nthings are easy to subtly create maliciously (but of course if the user<br>\ncannot use ML, I think we can assume the developers won't do this).  But I<br>\nhave also found that in practice on large projects, subtle problems with<br>\ntools, including theorem provers, just happen accidentally.</p>\n<p>For example (forgive me if my lack of deep understanding of the Isabelle<br>\ncore means I am wrong here), but presumably it is quite feasible, in<br>\nprinciple, that some complex bit of derived Isablle code occasionally<br>\nconstructs terms that involve overloaded variables.  This is certainly true<br>\nin the \"3 HOL\" systems (i.e. the 4 HOL systems minus HOL Zero :).  So nasty<br>\nterms that involve overloaded varaibles could \"magically\" get innocently<br>\nconstructed by well-meaning source code developed by well-meaning Isabelle<br>\ndevelopers.</p>\n<blockquote>\n<p>I've often seen and written theorems that didn't mean what I thought they<br>\nmeant. It's so far never been the fault of the pretty printer. It can be,<br>\nbecause you'd  be able to trick it with some effort, but getting rid of<br>\nthat<br>\npossibility is about assurance, not about finding the right proof<br>\nstatement.<br>\nIt can have different solutions.</p>\n</blockquote>\n<p>Yes, the risk is that the wrong theorems are being proved or that things are<br>\nbeing given the wrong definitions, and this is why we need proof auditing,<br>\nand this is why we need good concrete-syntax pretty printers, to enable the<br>\nauditor to effectively review things.  But I find I'm repeating myself<br>\nhere...</p>\n<p>Mark.</p>",
        "id": 294125624,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841213
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 19/1/11 5:22 AM, Konrad Slind &lt;<a href=\"mailto:konrad.slind@gmail.com\">konrad.slind@gmail.com</a>&gt; wrote:</p>\n<p>Not so simple that existing theorem provers have trusted pretty printers<br>\n(other than HOL Zero)....</p>\n<p>I think it would be an excellent use of formal methods to formally verify a<br>\ntrusted pretty printer (such as HOL Zero's).  And, no, I'm wouldn't get<br>\nparanoid about how we trust the theorem prover used to do this.</p>\n<p>Mark.</p>",
        "id": 294125635,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841219
    },
    {
        "content": "<p>From: Alexander Krauss &lt;<a href=\"mailto:krauss@in.tum.de\">krauss@in.tum.de</a>&gt;<br>\nHi Mark,</p>\n<p>This discussion is a bit strange. It seems this is mostly due to a <br>\nconflation of at least three very different functionalities that you <br>\nexpect from a \"theorem prover\":</p>\n<p>(a) Checking Proofs -- This requires a trusted inference kernel only, <br>\nbased on abstract syntax. No interesting parsing or pretty printing <br>\nhere. Challenges: Logical complexities, Performance, Keeping code simple <br>\nand understandable.</p>\n<p>(b) Developing Proofs -- This requires flexibility and automation, <br>\nsupport for arbitrary user-level code, and a way to reduce everything to <br>\nkernel-level inferences. Trusted pretty printing is not an issue here <br>\neither. Instead I want as powerful tools as possible.</p>\n<p>(c) Auditing Definitions and Theorem Statements -- This is mainly an <br>\ninterface problem of the auditor trying to understand what has been <br>\nproved. Pretty printing plays a role here, but there are many other <br>\nthings. But note that proofs play no role here. This is just about <br>\ndefinitions and theorem statements.</p>\n<p>I hereby make the bold claim that any system trying to do any two of <br>\nthese things at the same time is bound to make some lousy compromises <br>\nthat aren't acceptable if you are really serious.</p>\n<p>It happens that LCF-style provers traditionally try to do both (a) and <br>\n(b), and they do make compromises. Bringing (c) into the picture and <br>\ntrying to add it into one of those systems would probably make the <br>\nsituation worse, not better. This is just an argument for a separate <br>\ntool, which could be HOL0. I have the impression though that you are <br>\ntrying to address both (a) and (c) at the same time, which may lead to <br>\nnew lousy compromises.</p>\n<p>The issues about someone maliciously attacking the kernel etc. are <br>\northogonal and probably have standard solutions. Operating systems and <br>\nsecurity people can solve this as soon as it is important enough for <br>\nsomeone to pay the price. But logicians are not the right people to do this.</p>\n<blockquote>\n<blockquote>\n<p>If a trusted prettyprinter is deemed to be important tool for the auditor,<br>\nthen the auditor can code one up, or look over your shoulder while<br>\nyou code it.  It's a fairly simple task.</p>\n</blockquote>\n<p>Mark Adams wrote:<br>\nNot so simple that existing theorem provers have trusted pretty printers<br>\n(other than HOL Zero)....</p>\n</blockquote>\n<p>previously, Mark Adams wrote:</p>\n<blockquote>\n<p>but just<br>\na healthy degree of concern, especially when the problems can be easily<br>\naddressed.</p>\n</blockquote>\n<p>So are you claiming that is it easily addressed or that it isn't??? <br>\nMaybe your reasoning needs to be checked by a trusted kernel?</p>\n<p>Anyway, what properties must a pretty printer have in order to be <br>\ntrustworthy? Is there anything formal to be said here apart from Freek <br>\nWiedijk's Pollack-consistency? Or is it just defined in terms of the <br>\nattacks you happen to imagine right now? It would be interesting to read <br>\nsome details here instead of just a claim of how important it is.</p>\n<p>Alex</p>",
        "id": 294125751,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841257
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\nHi everyone, shall we make this the last e-mail on this subject open to the<br>\nlist?  I understand that this thread is perhaps not of the question/answer<br>\ntype that most Isabelle users would be interested in.  Why don't people<br>\ne-mail me if they want to see or participate in any of the continuations and<br>\nwe'll keep it private.  Unless there are lots of objections to keeping it<br>\nprivate that is...</p>\n<p>on 19/1/11 9:56 AM, Alexander Krauss &lt;<a href=\"mailto:krauss@in.tum.de\">krauss@in.tum.de</a>&gt; wrote:</p>\n<blockquote>\n<p>Hi Mark,</p>\n<p>This discussion is a bit strange. It seems this is mostly due to a<br>\nconflation of at least three very different functionalities that you<br>\nexpect from a \"theorem prover\":</p>\n<p>(a) Checking Proofs -- ...</p>\n<p>(b) Developing Proofs -- ...</p>\n<p>(c) Auditing Definitions and Theorem Statements -- ...</p>\n<p>I hereby make the bold claim that any system trying to do any two of<br>\nthese things at the same time is bound to make some lousy compromises<br>\nthat aren't acceptable if you are really serious.</p>\n<p>...</p>\n</blockquote>\n<p>I think it's helpful to the discussion to break it down into different<br>\nactivities like you have.  You are right to differentiate between checking<br>\nproofs and developing proofs.  I have always viewed auditing definitions and<br>\ntheorem statements as part of the process of checking proofs, but I suppose<br>\nyou could split it off as a different activity.</p>\n<p>But I would say that there is absolutely no conflict in practice in catering<br>\nfor (a) and (c) together in the same system, and furthermore that they<br>\nnaturally go hand-in-hand.  The inference kernel does (a), and is<br>\narchitecturally separate from the pretty printer which supports (c).  Both<br>\nhave trustworthiness as their top priority.</p>\n<p>There is some conflict between (a)/(c) and (b).  So both (a) and (c) ideally<br>\ninvolve using a system where trustworthiness is the top priority, together<br>\nwith sufficient efficiency to enable (a) and with certain aspects of<br>\nusability to support doing (c) effectively (such as good pretty-printing of<br>\ndefinitions and theorems, and good user feedback for certain basic<br>\noperations).  To achieve the trustworthiness, the source code for the<br>\ntrusted parts is ideally written with the utmost simplicity and clarity.<br>\nBut for (b), its top priorities are general usability and efficiency, with<br>\ntrustworthiness having less importance.  There is a conflict between general<br>\nusability and clarity of the inference kernel, because things like<br>\nhierarchical theories, for example, can help usability but (at least<br>\ntraditionally) involve greatly complicating the inference kernel.  Also, to<br>\npursue efficiency for (b), the inference kernel is typically made<br>\nsignificantly bigger and more complicated.</p>\n<p>So yes, HOL Zero was written to support (a)/(c) and avoid the conflicts with<br>\n(b).  But no, I don't see there being any significant compromises in the HOL<br>\nZero implementation.  Take a look for yourself and see!  And then compare it<br>\nwith HOL4, ProofPower HOL and Isabelle.  (I can point out the equivalent<br>\nparts of each system if you are really interested in doing this.)</p>\n<p>HOL Light is an interesting case.  It's simplicity (and the simplicity of<br>\nit's embryonic forerunner - the GTT system implemented by Konrad and John)<br>\nis the inspiration for HOL Zero.  I would suggest that HOL Light sits<br>\nbetween (a) and (b) with some slightly uncomfortable compromises (its lack<br>\nof theory hierarchy, for example, arguably makes it less usable), but that<br>\nat the same time does a surprisingly good job.  The inference kernel has<br>\nonly 10 inference rules and is very simple, but it is not at all unusably<br>\nslow.  And Flyspeck is showing that HOL Light is up to the task of being<br>\nused on big projects.  But anyway, I saw HOL Light as still unsatisfactory,<br>\nif only due to its pretty printer making it inappropriate for the (c) role,<br>\nand reluctantly decided that a new system was required to fill the gap.</p>\n<p>I think HOL4, ProofPower and Isabelle are aiming for (b) and get the balance<br>\nabout right.  Their use of an LCF-style architecture gives good assurance<br>\nbut without conflicting with (b) in my opinion.  I think the balance is a<br>\nbit wrong as regards to their pretty printers (because the problems can be<br>\nrelatively easily addressed without compromising on (b), and furthermore<br>\nthis would actually help (b)), and this is what this thread has become<br>\nabout.</p>\n<blockquote>\n<p>The issues about someone maliciously attacking the kernel etc. are<br>\northogonal and probably have standard solutions. Operating systems and<br>\nsecurity people can solve this as soon as it is important enough for<br>\nsomeone to pay the price. But logicians are not the right people to do<br>\nthis.</p>\n</blockquote>\n<p>They are not orthogonal in my opinion, because the LCF-style architecture<br>\nitself delivers trustworthiness to protect against both the malicious and<br>\nthe accidental.  I think the orthogonality comes in when differentiating<br>\nbetween trustworthiness within the scope of the ML program implementing the<br>\ntheorem prover and trustworthiness outside its scope (e.g. bugs in the ML<br>\ninterpreter, operating system interrupts, etc, etc).  But I agree that we<br>\nshould get the security experts in to help with the latter.</p>\n<blockquote>\n<p>Mark Adams wrote:</p>\n<blockquote>\n<p>Not so simple that existing theorem provers have trusted pretty<br>\nprinters (other than HOL Zero)....</p>\n</blockquote>\n<p>previously, Mark Adams wrote:</p>\n<blockquote>\n<p>but just a healthy degree of concern, especially when the problems<br>\ncan be easily addressed.</p>\n</blockquote>\n<p>So are you claiming that is it easily addressed or that it isn't???<br>\nMaybe your reasoning needs to be checked by a trusted kernel?</p>\n</blockquote>\n<p>:-)</p>\n<p>I'm claiming that it's easy.  My suggestion that it was \"not so simple\" was<br>\njust to emphasise that nothing much has been done about these things until<br>\nnow.</p>\n<blockquote>\n<p>Anyway, what properties must a pretty printer have in order to be<br>\ntrustworthy? Is there anything formal to be said here apart from Freek<br>\nWiedijk's Pollack-consistency? Or is it just defined in terms of the<br>\nattacks you happen to imagine right now? It would be interesting to read<br>\nsome details here instead of just a claim of how important it is.</p>\n</blockquote>\n<p>I've spent a long time thinking about it and independently came up with the<br>\ntightest of Freek's \"Pollack consistency\" concepts.  I called it<br>\n\"parser/printer completeness\".  But there's more to this than Freek's paper<br>\nbecause he doesn't cover \"printing soundness\" - i.e. printing what the user<br>\nexpects (it's misleading to print an \"and\" when internally it's an \"or\").</p>\n<p>Mark.</p>",
        "id": 294125879,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841286
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nIt depends what you want to do in the end.  Generating sources that are <br>\nfed back into the system is inherently hard.  I have occasionally seen <br>\npeople doing it empirically, e.g. trying Syntax.read_term on some <br>\nidentifier and checking if they get a \"Free\" term -- but this does not <br>\nreally take the scoping rules of const vs. free vs. bound into account.</p>\n<p>Unless your output needs to be inspected directly by users it is easier to <br>\navoid generating sources altogether, and use the Isabelle/ML interfaces to <br>\nget logical content into the system.  This is the norml way in LCF-style <br>\nprovers.  Concrete syntax is just a superficial add-on for end-users.</p>\n<p>Makarius</p>",
        "id": 294127643,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841789
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\nOn a related topic, what does Isabelle do for parsing/printing irregular<br>\nvariable/constant names?  E.g. a variable with a space in its name.  Is it<br>\npossible to parse such a variable name, and, whether it is or not, what does<br>\nthe printer output?</p>\n<p>Mark</p>\n<p>on 16/1/11 12:45 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>",
        "id": 294127665,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841796
    },
    {
        "content": "<p>From: Matthias Schmalz &lt;<a href=\"mailto:Matthias.Schmalz@inf.ethz.ch\">Matthias.Schmalz@inf.ethz.ch</a>&gt;<br>\n-----BEGIN PGP SIGNED MESSAGE-----<br>\nHash: SHA1</p>\n<p>Mark,</p>\n<p>I think, I can answer that; other readers should feel free to correct me.</p>\n<p><a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> schrieb:</p>\n<blockquote>\n<p>On a related topic, what does Isabelle do for parsing/printing irregular<br>\nvariable/constant names?  E.g. a variable with a space in its name.  Is it<br>\npossible to parse such a variable name, </p>\n</blockquote>\n<p>No, as<br>\nterm \"a a\"<br>\nis rejected.</p>\n<blockquote>\n<p>and, whether it is or not, what does<br>\nthe printer output?</p>\n</blockquote>\n<p>If you create variables with irregular names using the ML<br>\ninfrastructure, the printer justs prints them:</p>\n<p>ML_val {*<br>\ncterm_of @{theory} (Free (\"a a\", @{typ bool}))<br>\n*}</p>\n<p>... prints<br>\nval it = \"a a\" : cterm</p>\n<ul>\n<li>-Matthias<br>\n-----BEGIN PGP SIGNATURE-----<br>\nVersion: GnuPG v1.4.6 (GNU/Linux)<br>\nComment: Using GnuPG with Mozilla - <a href=\"http://enigmail.mozdev.org\">http://enigmail.mozdev.org</a></li>\n</ul>\n<p>iD8DBQFNMx6UczhznXSdWggRAnCrAJwLsrSrcYzqATD6GF2MxiRTJ9o/qgCfd8Uq<br>\nr24zX3C4KVZvEN3aqTAY4Ks=<br>\n=4xpw<br>\n-----END PGP SIGNATURE-----</p>",
        "id": 294127681,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841802
    },
    {
        "content": "<p>From: Matthias Schmalz &lt;<a href=\"mailto:Matthias.Schmalz@inf.ethz.ch\">Matthias.Schmalz@inf.ethz.ch</a>&gt;<br>\n-----BEGIN PGP SIGNED MESSAGE-----<br>\nHash: SHA1</p>\n<blockquote>\n<p>It depends what you want to do in the end.  Generating sources that are<br>\nfed back into the system is inherently hard.  I have occasionally seen<br>\npeople doing it empirically, e.g. trying Syntax.read_term on some<br>\nidentifier and checking if they get a \"Free\" term -- but this does not<br>\nreally take the scoping rules of const vs. free vs. bound into account.</p>\n</blockquote>\n<p>For the moment, I need to generate sources. Heuristic solutions are<br>\nfine. Are you aware of other pitfalls than hitting reserved keywords,<br>\npredefined constants, and capturing?</p>\n<blockquote>\n<p>Unless your output needs to be inspected directly by users it is easier<br>\nto avoid generating sources altogether, and use the Isabelle/ML<br>\ninterfaces to get logical content into the system.  This is the norml<br>\nway in LCF-style provers.  Concrete syntax is just a superficial add-on<br>\nfor end-users.</p>\n</blockquote>\n<p>On the long run, I indeed intend to bypass the parser. I implement my<br>\ntool in Scala and would like to avoid writing my own Scala/ML linkup.<br>\nIs there a way of accessing the term datatype via the the Isabelle/Scala<br>\ninterface? Can I use Isabelle/Scala to access the Syntax.read_term function?</p>\n<p>Thanks,<br>\nMatthias</p>\n<p>-----BEGIN PGP SIGNATURE-----<br>\nVersion: GnuPG v1.4.6 (GNU/Linux)<br>\nComment: Using GnuPG with Mozilla - <a href=\"http://enigmail.mozdev.org\">http://enigmail.mozdev.org</a></p>\n<p>iD8DBQFNMyWEczhznXSdWggRAvr3AJ0eRIp9uf9kgwKUp04ezV8mv5WNjgCghaiE<br>\ni8BbcS+Rrm35tdaKS05fAys=<br>\n=SKRs<br>\n-----END PGP SIGNATURE-----</p>",
        "id": 294127735,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841820
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Sun, 16 Jan 2011, Matthias Schmalz wrote:</p>\n<blockquote>\n<p>-----BEGIN PGP SIGNED MESSAGE-----<br>\nHash: SHA1</p>\n<blockquote>\n<p>It depends what you want to do in the end.  Generating sources that are<br>\nfed back into the system is inherently hard.  I have occasionally seen<br>\npeople doing it empirically, e.g. trying Syntax.read_term on some<br>\nidentifier and checking if they get a \"Free\" term -- but this does not<br>\nreally take the scoping rules of const vs. free vs. bound into account.</p>\n</blockquote>\n<p>For the moment, I need to generate sources. Heuristic solutions are <br>\nfine. Are you aware of other pitfalls than hitting reserved keywords, <br>\npredefined constants, and capturing?</p>\n</blockquote>\n<p>This depends on various fine points of what you really need, i.e. just <br>\ndetect lexical identifiers or ensure that certain generated names are <br>\nresolved as free variables, not constants.</p>\n<p>The following example does the lexical check only, quite reliably in the <br>\nsense that I've studied the relevant Isabelle/Pure sources for 15min.</p>\n<p>ML {*</p>\n<p>fun is_syntax_ident ctxt s =<br>\n   Syntax.is_identifier s andalso<br>\n     not (can Name.dest_internal s) andalso<br>\n     not (Syntax.is_keyword (ProofContext.syn_of ctxt) s);</p>\n<p>*}</p>\n<p>locale test =<br>\n   fixes xxx (\"FOO\")<br>\nbegin</p>\n<p>lemma True<br>\nproof</p>\n<p>fix yyy (\"BAR\")</p>\n<p>ML_val {* is_syntax_ident @{context} \"FOO\" *}<br>\n   ML_val {* is_syntax_ident @{context} \"BAR\" *}<br>\n   ML_val {* is_syntax_ident @{context} \"True\" *}<br>\n   ML_val {* is_syntax_ident @{context} \"x\" *}<br>\n   ML_val {* is_syntax_ident @{context} \"x_\" *}</p>\n<p>qed</p>\n<p>end</p>\n<p>It is important to work with the proper local context.  In particular, a <br>\nbackground @{theory} is generally not sufficient.</p>\n<blockquote>\n<blockquote>\n<p>Unless your output needs to be inspected directly by users it is easier <br>\nto avoid generating sources altogether, and use the Isabelle/ML <br>\ninterfaces to get logical content into the system.  This is the norml <br>\nway in LCF-style provers.  Concrete syntax is just a superficial add-on <br>\nfor end-users.</p>\n</blockquote>\n<p>On the long run, I indeed intend to bypass the parser. I implement my <br>\ntool in Scala and would like to avoid writing my own Scala/ML linkup. Is <br>\nthere a way of accessing the term datatype via the the Isabelle/Scala <br>\ninterface? Can I use Isabelle/Scala to access the Syntax.read_term <br>\nfunction?</p>\n</blockquote>\n<p>Not yet, but this will come at some point.  There are some raw technical <br>\nissues, and some more profound questions concerning the formal context on <br>\nthe Isabelle/Scala side.  Some concrete applications will make this emerge <br>\nmore quickly :-)</p>\n<p>Makarius</p>",
        "id": 294127762,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841826
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nOn Sun, 16 Jan 2011, Matthias Schmalz wrote:</p>\n<blockquote>\n<p><a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> schrieb:</p>\n<blockquote>\n<p>On a related topic, what does Isabelle do for parsing/printing <br>\nirregular variable/constant names?  E.g. a variable with a space in its <br>\nname.  Is it possible to parse such a variable name,</p>\n</blockquote>\n<p>No, as<br>\nterm \"a a\"<br>\nis rejected.</p>\n</blockquote>\n<p>By extending the syntax in user space, you can easily inject odd strings <br>\ninto the term language, e.g. via something like</p>\n<p>FREE ''foo bar''</p>\n<p>with a grammar production for the \"FREE\" literal token and a suitable <br>\nparse translations.  See the existing CONST notation, although I do not <br>\nreally recommend to try this at home.</p>\n<blockquote>\n<p>If you create variables with irregular names using the ML <br>\ninfrastructure, the printer justs prints them:</p>\n<p>ML_val {*<br>\ncterm_of @{theory} (Free (\"a a\", @{typ bool}))<br>\n*}</p>\n<p>... prints<br>\nval it = \"a a\" : cterm</p>\n</blockquote>\n<p>This use of cterm_of reminds me of an old trick that has come out of use <br>\nsome years ago, because printing with the background theory certificate <br>\nlacks local syntax of the foreground context (local theory or proof body).</p>\n<p>Did you come up with idea yourself, or do we still have it in some old <br>\nmanual?</p>\n<p>Here is the localized version:</p>\n<p>ML_val {*<br>\n   writeln (Syntax.string_of_term @{context} (Free (\"a a\", @{typ bool})))<br>\n*}</p>\n<p>Makarius</p>",
        "id": 294127777,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841832
    },
    {
        "content": "<p>From: Matthias Schmalz &lt;<a href=\"mailto:Matthias.Schmalz@inf.ethz.ch\">Matthias.Schmalz@inf.ethz.ch</a>&gt;<br>\n-----BEGIN PGP SIGNED MESSAGE-----<br>\nHash: SHA1</p>\n<p>I made it up by myself, being unaware of Syntax.string_of_term. Don't<br>\nworry about the manuals.</p>\n<ul>\n<li>-Matthias<br>\n-----BEGIN PGP SIGNATURE-----<br>\nVersion: GnuPG v1.4.6 (GNU/Linux)<br>\nComment: Using GnuPG with Mozilla - <a href=\"http://enigmail.mozdev.org\">http://enigmail.mozdev.org</a></li>\n</ul>\n<p>iD8DBQFNM0l7czhznXSdWggRAusXAJ4qB/WlFBQUmfbfXywAVPsIHv8xuQCdGOqO<br>\nr6Rt5033J5jZhXciaOPRDek=<br>\n=DFfR<br>\n-----END PGP SIGNATURE-----</p>",
        "id": 294127795,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841838
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\nThanks for your answers, Matthias/Makarius.</p>\n<p>I have a follow-up question...  What about variables overloaded with other<br>\nvariables (i.e. same name but different type) or overloaded with constants<br>\n(same name, any type) - can terms with any such overloading be parsed, and<br>\nwhat happens when they are printed?</p>\n<p>Mark.</p>\n<p>on 16/1/11 7:21 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>",
        "id": 294127870,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841863
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nAs far as the kernel is concerned, the identity of atoms (variables, <br>\nconsts) consists of both the name and type, although \"overloading\" means <br>\nsomething different in Isabelle.</p>\n<p>In contrast, in the syntax layer (the so-called \"term check/uncheck\" <br>\nphase, which generalizes the idea of type-inference) variables are <br>\nexpected to be consistently typed: equal name imples equal type, and <br>\nscopes for variables vs. constants are resolved consistently.</p>\n<p>If you print a term that violates this, it might look \"funny\", or outright <br>\nmisleading.  This effect can already happen due to the customary omission <br>\nof type information for variables.</p>\n<p>Anyway, it also depends what is meant by \"printed\" exactly.  In Isabelle <br>\nthere is quite a bit of extra formal markup in the output, that is not <br>\nshown in plain text.  In Proof General you already get the typical <br>\nIsabelle color-code of blue/green/brown variables and black constants. <br>\nIn a Prover IDE like Isabelle/jEdit you could make even more out of that, <br>\ne.g. tell the user the full truth about term atoms via tooltips or popups.</p>\n<p>Makarius</p>",
        "id": 294128009,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841893
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\nI see.</p>\n<p>Is there a printing mode for type-annotating constants and/or variables with<br>\ntheir types (like in HOL4)?  I'm concerned about the risk of statements<br>\nbeing displayed in a misleading way.</p>\n<p>Mark</p>\n<p>on 17/1/11 7:40 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>",
        "id": 294128037,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841905
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nYou can implement your own in user space.  These things are not part of <br>\nthe kernel.  Even the ML toplevel pretty printer can be modified in user <br>\nspace.</p>\n<p>Anyway, do you now the funny paper about by Freek Wiedijk, UITP 2010?</p>\n<p>I've known this \"issue\" ever since I got exposed to Isabelle for the very <br>\nfirst time, in summer 1993.</p>\n<p>Makarius</p>",
        "id": 294128066,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841912
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThis was a copy-paste accident: Freek's paper is about <br>\n\"Pollack-inconsistency\".</p>\n<p>Makarius</p>",
        "id": 294128094,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841918
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a></p>\n<blockquote>\n<blockquote>\n<p>Is there a printing mode for type-annotating constants and/or variables<br>\nwith their types (like in HOL4)?  I'm concerned about the risk of<br>\nstatements being displayed in a misleading way.</p>\n</blockquote>\n<p>...<br>\nAnyway, do you now the funny paper about \"Pollack-inconsistency\" by Freek<br>\nWiedijk, UITP 2010?</p>\n</blockquote>\n<p>Yes thanks.  In fact my HOL system, HOL Zero<br>\n(<a href=\"http://proof-technologies.com/holzero.html\">http://proof-technologies.com/holzero.html</a>), deals with all these issues<br>\n(or so I claim - there is a $100 bounty for anyone that spots a problem).  I<br>\nwas wondering how well Isabelle fared.</p>\n<blockquote>\n<p>I've known this \"issue\" ever since I got exposed to Isabelle for the very<br>\nfirst time, in summer 1993.</p>\n</blockquote>\n<p>It puzzles me how little has been done about these things until now.  Are<br>\nnot people concerned that what is being displayed could be misleading?</p>\n<p>Mark.</p>",
        "id": 294128140,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841930
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThere are other, more pressing problems. Sitting at a bare-bones ML <br>\ntoplevel merely gives you an illusion of \"direct\" access to a system, but <br>\nthere are still many things that can go wrong.</p>\n<p>An LCF-style prover is reasonably correct by construction, independently <br>\nof concrete syntax input and output.  Errors in the <br>\ninternalization/externalization do not multiply as quickly as genuine <br>\nlogical errors.</p>\n<p>Makarius</p>",
        "id": 294128211,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841949
    },
    {
        "content": "<p>From: Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt;<br>\nNo.</p>\n<p>If one has reason to suspect that something funny might be going on, the terms in question can be examined using the primitive ML API.</p>\n<p>Alternatively, one can print the term out using a primitive pretty-printer that doesn't attempt to do anything \"fancy\".</p>\n<p>For example, in HOL4 one can use</p>\n<p>Parse.print_term_by_grammar min_grammars</p>\n<p>Michael</p>",
        "id": 294128236,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841955
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:webertj@in.tum.de\">webertj@in.tum.de</a>&gt;<br>\nWell, I for one think it's an unsatisfying design flaw in (some)<br>\nexisting provers that one cannot trust their output.</p>\n<p>In practice, however, this becomes a potential problem only when you<br>\nwant to check a proof from an untrustworthy source.  (Proof objects<br>\nprovide a partial solution here.)</p>\n<p>As long as you assume a non-malicious user who wants to create a valid<br>\nmachine-checked proof, it is not much of an issue.</p>\n<p>Kind regards,<br>\nTjark</p>",
        "id": 294128254,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841961
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nThis does not sound like you are speaking here about Isabelle at all. We <br>\ndo not assume a \"non-malicious\" user.  You can always inspect internal <br>\ncertificates, even before embarking on full proof terms.</p>\n<p>Makarius</p>",
        "id": 294128341,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841985
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 17/1/11 11:14 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>\n<blockquote>\n<p>There are other, more pressing problems.</p>\n</blockquote>\n<p>I think trustworthiness in theorem provers should always be a top priority.<br>\nAfter all, this is why we are using them in the first place.  So long as it<br>\ndoesn't have terrible consequences on other aspects of the theorem prover,<br>\nsuch as efficiency or usability, that is.</p>\n<blockquote>\n<p>Sitting at a bare-bones ML<br>\ntoplevel merely gives you an illusion of \"direct\" access to a system, but<br>\nthere are still many things that can go wrong.</p>\n</blockquote>\n<p>Yes, but I think it's helpful to divide up possible things that can go wrong<br>\ninto those that are due to the design or implementation of the ML program,<br>\nand those that are due to things largely outside the scope of the program<br>\n(e.g. bugs in the ML interpreter, OS events interfering with normal<br>\noperation, etc, etc).  The former is where all the problems arise in<br>\nreality, and is very much under within out capability to solve.  I may be<br>\nwrong, but you're presumably talking about the latter?</p>\n<blockquote>\n<p>An LCF-style prover is reasonably correct by construction, independently<br>\nof concrete syntax input and output.  Errors in the internalization/<br>\nexternalization do not multiply as quickly as genuine logical errors.</p>\n</blockquote>\n<p>Yes, I agree that the LCF style largely solves problems of trustworthiness,<br>\nand that the sort of problems it solves are the most serious.  But given<br>\nthat this has been solved (a long time ago), shouldn't we tackle the<br>\nremaining problems?</p>\n<p>Mark.</p>",
        "id": 294128377,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660841998
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 17/1/11 11:34 PM, Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<p>On 18/01/11 09:34, <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> wrote:</p>\n<blockquote>\n<p>It puzzles me how little has been done about these things until now.  Are<br>\nnot people concerned that what is being displayed could be misleading?</p>\n</blockquote>\n<p>No.</p>\n<p>If one has reason to suspect that something funny might be going on, the<br>\nterms in question can be examined using the primitive ML API.</p>\n</blockquote>\n<p>This relies on having a sharp-sighted user who can spot subtle strange<br>\nbehaviour (in addition to all the other demands on the attention of the poor<br>\ntheorem prover user).  And in any case, it will sometimes not be possible to<br>\nspot that something funny has happened, because it may appear to be behaving<br>\nprecisely as expected (even though it actually isn't).  Isn't it better to<br>\nhave tools that we can solidly rely on?</p>\n<p>But yes, I suppose terms can be examined in terms of their primitive syntax,<br>\nbut surely this is completely impractical for large industrial formal<br>\nmethods projects involving large formal specifications.  In practice, anyone<br>\nreviewing a large industrial proof will be using the normal pretty printer.<br>\nThat is, if anyone is actually bothering to do a reviewing exercise in the<br>\nfirst place...</p>\n<blockquote>\n<p>Alternatively, one can print the term out using a primitive pretty-printer<br>\nthat doesn't attempt to do anything \"fancy\".</p>\n<p>For example, in HOL4 one can use</p>\n<p>Parse.print_term_by_grammar min_grammars</p>\n</blockquote>\n<p>I don't think this particular command solves the irregular names problem, or<br>\nthe overloaded variables problem.  But I suppose if used in conjunction with<br>\nHOL4's optional type annotated output and the new facility for coloured<br>\nprinting of variables then it could help.</p>\n<p>Mark.</p>",
        "id": 294128425,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842003
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nTrustworthiness is just one of many problems, and we have been able to <br>\nincrease it in Isabelle gradually over the years.</p>\n<p>Apart from that efficiency, accessibility, usability etc. are of general <br>\nimportance to make our arcane provers acceptable to more people out there. <br>\nI often find myself in the situation of a formalistic fundamentalist when <br>\nspeaking to people outside our community.</p>\n<p>E.g. when you start moving towards serious Prover IDEs, what I've been <br>\ninvolved for quite some time now, you will find many more issues than the <br>\nrather trivial parse/print problem of the low-level term language.  Of <br>\ncourse, I always try to keep as much immediate reliability as possible. <br>\nBut I also feel one should separate concerns here: if you need extreme <br>\ntrustworthiness, then you should export full theory and proof content to <br>\nsome tiny external checker.  The latter does not even need concrete syntax <br>\nin the traditional sense.</p>\n<p>HOL0 could be one such checker, if it would be able to absorb huge <br>\ntheories and proofs (traces of inferences).  Then one could implement some <br>\n\"HOL0\" button in Isabelle.</p>\n<p>Makarius</p>",
        "id": 294128485,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842016
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nObviously trustworthiness is important. Nevertheless, a fixation on this one issue can be counter-productive. I'm not aware of a single piece of research that was invalidated due to bugs in theorem provers.</p>",
        "id": 294128504,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842024
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 12:12 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>\n<blockquote>\n<p>On Tue, 18 Jan 2011, <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> wrote:</p>\n<blockquote>\n<p>Yes, I agree that the LCF style largely solves problems of<br>\ntrustworthiness, and that the sort of problems it solves are the<br>\nmost serious.  But given that this has been solved (a long time<br>\nago), shouldn't we tackle the remaining problems?</p>\n</blockquote>\n<p>Trustworthiness is just one of many problems, and we have been<br>\nable to increase it in Isabelle gradually over the years.</p>\n<p>Apart from that efficiency, accessibility, usability etc. are of general<br>\nimportance to make our arcane provers acceptable to more people<br>\nout there.  I often find myself in the situation of a formalistic<br>\nfundamentalist when speaking to people outside our community.</p>\n</blockquote>\n<p>Yes, and I similarly.  There are people out there who simply don't want any<br>\ninvolvement with formal proof.  My fear is that, as we are trying to push<br>\ntheorem proving more towards mainstream usage, sceptics will emerge citing<br>\n\"well you can't even trust theorem provers anyway\".  There was that debate<br>\nin the 1970s...</p>\n<blockquote>\n<p>E.g. when you start moving towards serious Prover IDEs, what I've been<br>\ninvolved for quite some time now, you will find many more issues than the<br>\nrather trivial parse/print problem of the low-level term language.</p>\n</blockquote>\n<p>Yes, adding layers can present more problems, and I'm sure you have more<br>\nexperience in this than me.  But surely we should be addressing these<br>\nproblems as they arise, instead of brushing many of them under the carpet?<br>\nShouldn't there be some sort of research effort concentrating on this?</p>\n<blockquote>\n<p>Of course, I always try to keep as much immediate reliability as possible.<br>\nBut I also feel one should separate concerns here: if you need extreme<br>\ntrustworthiness, then you should export full theory and proof content to<br>\nsome tiny external checker.  The latter does not even need concrete syntax<br>\nin the traditional sense.</p>\n</blockquote>\n<p>Unfortunately, the external checker needs to have a trustworthy printer<br>\n(despite that this has not traditionally been expressed as a priority).  It<br>\nneeds to be able to print syntax in a highly readable way, so that a proof<br>\nauditor can effectively review exactly what the checker has checked.  A<br>\nlarge project involving formal proof might have hundreds of definitions that<br>\nneed reviewing, as well as the end-result theorems that use these<br>\ndefinitions.  Wading through primitive syntax makes this an almost<br>\nimpossible task.</p>\n<blockquote>\n<p>HOL0 could be one such checker, if it would be able to absorb huge<br>\ntheories and proofs (traces of inferences).  Then one could implement some<br>\n\"HOL0\" button in Isabelle.</p>\n</blockquote>\n<p>Well that's what I designed it for!  Being able to absorb huge theories is<br>\nof course crucial.  But also is being able to trust the inference kernel and<br>\nthe pretty printer.  The HOL Zero button already exists in a prototype HOL<br>\nLight variant I developed.  Not so easy for Isabelle HOL....</p>\n<p>Mark.</p>",
        "id": 294128521,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842029
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 12:38 PM, Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt; wrote:</p>\n<blockquote>\n<p>Obviously trustworthiness is important. Nevertheless, a fixation on this<br>\none<br>\nissue can be counter-productive. I'm not aware of a single piece of<br>\nresearch<br>\nthat was invalidated due to bugs in theorem provers.<br>\n On the other hand, I<br>\nhave seen a great many papers where the work was essentially worthless<br>\nbecause of inadequate modelling of the problem. Naturally, the theorem<br>\nprover cannot check that a model is realistic, but I frequently hear the<br>\nsuggestion that nothing can go wrong if you use a theorem prover. The<br>\ncommunity needs to focus more on ways of making models trustworthy. There<br>\nare probably quite a few interesting research topics along those lines.</p>\n</blockquote>\n<p>I agree that there are more important issues that require more attention.<br>\nI'm not advocating endless fixation with cosmic rays and the like, but just<br>\na healthy degree of concern, especially when the problems can be easily<br>\naddressed.</p>\n<p>We should remember that at the moment it is very easy for someone to<br>\nmaliciously produce what appears to be a formal proof of some statement but<br>\nis in fact something that takes advantage of the sorts of pretty printer<br>\nproblems I am talking about.  Now if theorem provers are ever going to make<br>\nit big, we are then in the situation where commercial pressures, etc, are<br>\npushing people to claim they have proved something when they have in fact<br>\nnot.  One of the important roles of a theorem prover should be as a highly<br>\ntrustworthy tool to support a human proof auditor checking that some huge<br>\n10,000 line proof of a theorem does indeed establish the theorem.</p>\n<p>Mark.</p>\n<blockquote>\n<p>Larry Paulson</p>\n<p>On 18 Jan 2011, at 11:55, &lt;<a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a>&gt; wrote:</p>\n<blockquote>\n<p>on 17/1/11 11:14 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>\n<blockquote>\n<p>There are other, more pressing problems.</p>\n</blockquote>\n<p>I think trustworthiness in theorem provers should always be a top<br>\npriority.<br>\nAfter all, this is why we are using them in the first place.  So long as<br>\nit<br>\ndoesn't have terrible consequences on other aspects of the theorem<br>\nprover,<br>\nsuch as efficiency or usability, that is.</p>\n</blockquote>\n</blockquote>",
        "id": 294128547,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842035
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 2:01 AM, Tjark Weber &lt;<a href=\"mailto:webertj@in.tum.de\">webertj@in.tum.de</a>&gt; wrote:</p>\n<blockquote>\n<p>As long as you assume a non-malicious user who wants to create a valid<br>\nmachine-checked proof, it is not much of an issue.</p>\n</blockquote>\n<p>Yes, but I don't think we can assume a non-malicious user!  What if someone<br>\nwants to claim they have proved something in order to get paid?<br>\nSubcontracting out proofs could be a serious business in the future.</p>\n<p>Mark.</p>",
        "id": 294128570,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842041
    },
    {
        "content": "<p>From: Tjark Weber &lt;<a href=\"mailto:webertj@in.tum.de\">webertj@in.tum.de</a>&gt;<br>\nAnd a malicious user, by misusing ML in Isabelle theory files, couldn't<br>\nreplace the functions that you would use to inspect internal<br>\ncertificates -- or the entire inference kernel; or even the entire<br>\nIsabelle process -- with his own implementation?</p>\n<p>Kind regards,<br>\nTjark</p>",
        "id": 294128591,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842047
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nYes, depending how much criminal energy you want to invest.</p>\n<p>Actually, this my favourite theoretical attack on LCF prover integrity. <br>\nAfter \"The Matrix\" it also has a name, see <br>\n<a href=\"http://en.wikipedia.org/wiki/Blue_Pill_%28malware%29\">http://en.wikipedia.org/wiki/Blue_Pill_%28malware%29</a></p>\n<p>We could harden Isabelle/ML against this, since the ML environment is <br>\nunder our control.  Since this has no practical relevance, though, it has <br>\nnot been done so far.  It is important to keep focused on real problems.</p>\n<p>Makarius</p>",
        "id": 294128607,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842053
    },
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nOnce you assume malicious users, you are turning theorem-proving software into security software. The time for this may come, but it will require a significant investment in security engineering. The first step would be to develop a realistic threat model. And this isn't really possible in the absence of actual attacks. It will be interesting to see if there are any over the coming years.</p>\n<p>Larry</p>",
        "id": 294128621,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842059
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 2:28 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>\n<blockquote>\n<p>On Tue, 18 Jan 2011, Tjark Weber wrote:</p>\n<blockquote>\n<p>...</p>\n<p>And a malicious user, by misusing ML in Isabelle theory files, couldn't<br>\nreplace the functions that you would use to inspect internal<br>\ncertificates -- or the entire inference kernel; or even the entire<br>\nIsabelle process -- with his own implementation?</p>\n</blockquote>\n<p>Yes, depending how much criminal energy you want to invest.</p>\n</blockquote>\n<p>Like the printer problems I mention, I also see these ML trojan horse issues<br>\nas important, easy-to-address and yet problems that have not yet been<br>\naddressed.  The ML interpreter should support being able to block<br>\noverwriting in some way or other.  E.g. supply the interpreter with a<br>\ndatatype or a function name that cannot be overwritten.  It isn't exactly<br>\nrocket science, and it removes a risk.  I just don't understand why nothing<br>\nhas been done about this.</p>\n<blockquote>\n<p>Actually, this my favourite theoretical attack on LCF prover integrity.<br>\nAfter \"The Matrix\" it also has a name, see<br>\n<a href=\"http://en.wikipedia.org/wiki/Blue_Pill_%28malware%29\">http://en.wikipedia.org/wiki/Blue_Pill_%28malware%29</a></p>\n<p>We could harden Isabelle/ML against this, since the ML environment is<br>\nunder our control.  Since this has no practical relevance, though, it has<br>\nnot been done so far.  It is important to keep focused on real problems.</p>\n</blockquote>\n<p>How could this be done?</p>\n<p>Mark.</p>",
        "id": 294128644,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842065
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nDvid Matthews kindly provides ways in Poly/ML to manage the whole <br>\ncompilation process in user space, including printing and binding of the <br>\nresults.  One would merely have to protect agains shadowing of certain <br>\nstructure names, say.</p>\n<p>When you've showed me an early version of HOL0 in Cambridge ITP 2009, I <br>\nhave already pointed out that OCaml is not the best platform for that (due <br>\nto its mutable strings and silently overflowing machine words called <br>\n\"int\").</p>\n<p>Makarius</p>",
        "id": 294128659,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842071
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 7:10 PM, Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt; wrote:</p>\n<blockquote>\n<p>....</p>\n<p>Dvid Matthews kindly provides ways in Poly/ML to manage the whole<br>\ncompilation process in user space, including printing and binding of the<br>\nresults.  One would merely have to protect agains shadowing of certain<br>\nstructure names, say.</p>\n</blockquote>\n<p>Oh good.  This is excellent news.  How long has this been available for?</p>\n<p>A related problem is overwriting a datatype's pretty printer.  Do you know<br>\nif Poly/ML can protect against this?</p>\n<blockquote>\n<p>When you've showed me an early version of HOL0 in Cambridge ITP 2009, I<br>\nhave already pointed out that OCaml is not the best platform for that (due<br>\nto its mutable strings and silently overflowing machine words called<br>\n\"int\").</p>\n</blockquote>\n<p>Yes you did (was it Montreal ITP 2008?).  HOL Zero uses a technique to avoid<br>\nproblems with mutable strings (unlike HOL Light) and doesn't use machine<br>\nwords for its representation of natural number numerals (like HOL Light).</p>\n<p>But you are right - OCaml is not the best language.  Larry convinced me a<br>\nfew months ago that SML is simply more well-defined.  I plan to port it to<br>\nSML as a priority as soon version 1.0 is out.  But this port might not be<br>\nuntil next year.</p>\n<p>Mark.</p>",
        "id": 294128698,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842083
    },
    {
        "content": "<p>From: Makarius &lt;<a href=\"mailto:makarius@sketis.net\">makarius@sketis.net</a>&gt;<br>\nMaybe 2 years.  It was one of the many improvements that David Matthews <br>\ndid for parallel ML and ML IDE support.</p>\n<p>This is where the Isabelle/ML compiler invocation happens: <br>\n<a href=\"http://isabelle.in.tum.de/repos/isabelle/file/Isabelle2009-2/src/Pure/ML/ml_compiler_polyml-5.3.ML\">http://isabelle.in.tum.de/repos/isabelle/file/Isabelle2009-2/src/Pure/ML/ml_compiler_polyml-5.3.ML</a> <br>\nIt is basically the Isabelle/Isar toplevel running ML, with toplevel name <br>\nspace management and pretty printing under our control. Without that <br>\nparallel Isabelle would hardly work in practice.</p>\n<p>Makarius</p>",
        "id": 294128709,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842090
    },
    {
        "content": "<p>From: Gerwin Klein &lt;<a href=\"mailto:gerwin.klein@nicta.com.au\">gerwin.klein@nicta.com.au</a>&gt;<br>\nI don't think this is a problem in practice. Theorem provers are already used in big certification projects. The evaluators in such projects usually know what they are doing, at least up to the level where they would easily be able to spot attempts to make syntactically misleading proof statements. It's easy enough to scan for ML blocks or similar in theory files, spot duplicate identifiers, etc, and demand good explanations for their presence (or just forbid them). And the threat of just using a proof checker is always there, so why try to cheat on syntax? </p>\n<p>I'm with Larry on this: the much bigger problem is to convince yourself that the model and final theorem are in any way useful or right. This is where cheating will happen much earlier. </p>\n<p>Cheers,<br>\nGerwin</p>",
        "id": 294128763,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842108
    },
    {
        "content": "<p>From: Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt;<br>\nIf the contractor's product is being audited sufficiently carefully, the auditor will notice the dubious calls to the pretty-printing/bare-ML infrastructure that were required to get the fake result looking acceptable.</p>\n<p>I really do not believe that this is an interesting issue.</p>\n<p>If the terms are really so large that printing them in \"raw\" form is likely to be a problem, then they will be just as incomprehensible in pretty form, and just as unreliable when checked by eye-balling.  In that situation, the client will presumably check their supplier's work by doing something like</p>\n<p>if aconv myterm (concl suppliers_thm) then print \"OK\"<br>\n   else print \"FAILURE\"</p>\n<p>And voil, the pretty-printing \"issue\" disappears.</p>\n<p>Michael</p>",
        "id": 294128787,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842114
    },
    {
        "content": "<p>From: Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt;<br>\nAnd the auditor failing to spot such malfeasance would be barely worth the name.</p>\n<p>Michael</p>",
        "id": 294128800,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842120
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 10:22 PM, Gerwin Klein &lt;<a href=\"mailto:gerwin.klein@nicta.com.au\">gerwin.klein@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<blockquote>\n<p>We should remember that at the moment it is very easy for someone to<br>\nmaliciously produce what appears to be a formal proof of some statement<br>\n...</p>\n</blockquote>\n<p>I don't think this is a problem in practice. Theorem provers are already<br>\nused in big certification projects. The evaluators in such projects<br>\nusually<br>\nknow what they are doing,</p>\n</blockquote>\n<p>How can you be so confident about this?  In the large, safety-critical<br>\ncertification projects I have been involved with, the evaluators do the best<br>\nthey can with the tools they have available.  Proof checkers with readable<br>\nand highly trustworthy output is a luxury not available to them.</p>\n<blockquote>\n<p>at least up to the level where they would easily<br>\nbe able to spot attempts to make syntactically misleading proof<br>\nstatements.<br>\nIt's easy enough to scan for ML blocks or similar in theory files, spot<br>\nduplicate identifiers, etc, and demand good explanations for their<br>\npresence<br>\n(or just forbid them). And the threat of just using a proof checker is<br>\nalways there, so why try to cheat on syntax?</p>\n</blockquote>\n<p>The input in this process is the full power of an ML program.  We all know<br>\nthat it is possible to hide incredibly subtle things in huge programs.  Are<br>\nwe to ban non-trivial ML in the process of producing a proof?  This would be<br>\nforcing contractors to do their work with one hand tied behind their back.<br>\nThe contracted, safety-critical proof work I have been involved with would<br>\ncertainly have been completely infeasible without writing large amounts of<br>\nML program to support my proof work.</p>\n<p>It is far better for the auditor if they can treat the ML code that<br>\nestablishes the final theorem as some sort of black box.  To do this the<br>\ntheorem prover needs certain basic properties, including a trustworthy<br>\nprinter.</p>\n<blockquote>\n<p>I'm with Larry on this: the much bigger problem is to convince yourself<br>\nthat<br>\nthe model and final theorem are in any way useful or right. This is where<br>\ncheating will happen much earlier.</p>\n</blockquote>\n<p>I did not say that this was not a problem!  This is the big problem!  And<br>\nthis is the problem that I am advocating needs a tool that properly supports<br>\nthe process - the process of determining that the model and final theorem<br>\nare right (as well as that the final theorem has actually been proved).<br>\nThis process involves using the pretty printer.</p>\n<p>Mark.</p>",
        "id": 294128868,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842126
    },
    {
        "content": "<p>From: <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a><br>\non 18/1/11 10:52 PM, Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt; wrote:</p>\n<blockquote>\n<p>On 19/01/11 00:11, <a href=\"mailto:mark@proof-technologies.com\">mark@proof-technologies.com</a> wrote:<br>\n...</p>\n<blockquote>\n<p>Yes, but I don't think we can assume a non-malicious user!  What if<br>\nsomeone wants to claim they have proved something in order to get<br>\npaid? Subcontracting out proofs could be a serious business in the<br>\nfuture.</p>\n</blockquote>\n<p>If the contractor's product is being audited sufficiently carefully, the<br>\nauditor will notice the dubious calls to the pretty-printing/bare-ML<br>\ninfrastructure that were required to get the fake result looking<br>\nacceptable.</p>\n</blockquote>\n<p>The input to the process is raw ML code, and huge amounts of it.  Almost<br>\nanything can be hidden in this, unless very strict coding standards are<br>\nenforced.  It is a far nicer situation for the auditor to be able to treat<br>\nthe ML code more-or-less as a black box, and review the state of the theorem<br>\nprover after it has supposedly established the end-result theorem.  I am<br>\nadvocating a tool that makes life for the auditor easier.  A tool with a<br>\npretty printer that can be trusted.</p>\n<blockquote>\n<p>If the terms are really so large that printing them in \"raw\" form is<br>\nlikely<br>\nto be a problem, then they will be just as incomprehensible in pretty<br>\nform,</p>\n</blockquote>\n<p>You appear to be claiming that concrete syntax printers are of no practical<br>\nuse to the human reader.</p>\n<blockquote>\n<p>and just as unreliable when checked by eye-balling.  In that situation,<br>\nthe<br>\nclient will presumably check their supplier's work by doing something like</p>\n<p>if aconv myterm (concl suppliers_thm) then print \"OK\"<br>\nelse print \"FAILURE\"</p>\n<p>And voil, the pretty-printing \"issue\" disappears.</p>\n</blockquote>\n<p>Let's assume we don't trust the parser.  How do we know that 'myterm' is<br>\ncorrect?  We need to review definitions and terms, and this is best done<br>\nusing a trustworthy pretty printer.</p>\n<p>I never thought that advocating a trustworthy pretty printer would be so<br>\ncontroversial!!!</p>\n<p>Mark.</p>",
        "id": 294128882,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842133
    },
    {
        "content": "<p>From: Michael Norrish &lt;<a href=\"mailto:Michael.Norrish@nicta.com.au\">Michael.Norrish@nicta.com.au</a>&gt;<br>\nIt's just not an interesting problem.  We can solve it trivially by writing everything out in sexp-like notation.  ACL2 is demonstrably an acceptable format for security-critical validation, and this is all the pretty-printing they have.</p>\n<p>Moreover, with proof terms (in Isabelle) and things like OpenTheory for the 3 HOLs, we can avoid having to look at clients' ML code.</p>\n<p>Michael</p>",
        "id": 294128907,
        "sender_full_name": "Email Gateway",
        "timestamp": 1660842139
    }
]