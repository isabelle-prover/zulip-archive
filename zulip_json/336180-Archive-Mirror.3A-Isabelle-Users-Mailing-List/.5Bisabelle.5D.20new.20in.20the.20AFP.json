[
    {
        "content": "<p>From: Lawrence Paulson &lt;<a href=\"mailto:lp15@cam.ac.uk\">lp15@cam.ac.uk</a>&gt;<br>\nIt never rains but it pours. Today we have two new entries, which are concerned with probability:</p>\n<p>Probabilistic Timed Automata<br>\nWe present a formalization of probabilistic timed automata (PTA) for which we try to follow the formula MDP + TA = PTA as far as possible: our work starts from our existing formalizations of Markov decision processes (MDP) and timed automata (TA) and combines them modularly. We prove the fundamental result for probabilistic timed automata: the region construction that is known from timed automata carries over to the probabilistic setting. In particular, this allows us to prove that minimum and maximum reachability probabilities can be computed via a reduction to MDP model checking, including the case where one wants to disregard unrealizable behavior. <br>\n<a href=\"https://www.isa-afp.org/entries/Probabilistic_Timed_Automata.html\">https://www.isa-afp.org/entries/Probabilistic_Timed_Automata.html</a></p>\n<p>Hidden Markov Models<br>\nThis entry contains a formalization of hidden Markov models [3] based on Johannes Hölzl's formalization of discrete time Markov chains [1]. The basic definitions are provided and the correctness of two main (dynamic programming) algorithms for hidden Markov models is proved: the forward algorithm for computing the likelihood of an observed sequence, and the Viterbi algorithm for decoding the most probable hidden state sequence. The Viterbi algorithm is made executable including memoization. Hidden markov models have various applications in natural language processing. <br>\n<a href=\"https://www.isa-afp.org/entries/Hidden_Markov_Models.html\">https://www.isa-afp.org/entries/Hidden_Markov_Models.html</a></p>\n<p>Many thanks to Simon Wimmer and Johannes Hölzl!</p>\n<p>Larry Paulson</p>",
        "id": 294733390,
        "sender_full_name": "Email Gateway",
        "timestamp": 1661188904
    }
]